{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcWPmrQYk4i5"
      },
      "source": [
        "# **LSTM Trained with a sample of lyrics from each decade**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQoOE5Ec24L"
      },
      "source": [
        "## **0.File Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMqTVkmgGSk"
      },
      "source": [
        "### **0.1 Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DoSHPrgEfJ",
        "outputId": "5919ccd4-2db5-488e-bb7b-97fca7345110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: laserembeddings in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.21.6)\n",
            "Requirement already satisfied: subword-nmt<0.4.0,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (0.3.8)\n",
            "Requirement already satisfied: transliterate==1.10.2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.10.2)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.11.0+cu113)\n",
            "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (0.0.35)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.15.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from subword-nmt<0.4.0,>=0.3.6->laserembeddings) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.2.0)\n",
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ]
        }
      ],
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzrJE1c_gP0i"
      },
      "source": [
        "### **0.2 Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-k-wVfCdBlc",
        "outputId": "001bbe95-cc8a-4a79-c460-fb5494b3e9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "\n",
        "#Shell command\n",
        "from IPython.display import JSON\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "#Text Processing\n",
        "import string\n",
        "import re\n",
        "\n",
        "#Modeling\n",
        "#from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Reshaping datasets to tensors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "#for Colab file dealing\n",
        "import glob\n",
        "#You can mount your Google Drive files by running the following code snippet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # Now all files in: /content/gdrive/My Drive/location_of_the_file\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnKduo33J5RC"
      },
      "outputs": [],
      "source": [
        "#Laser\n",
        "from laserembeddings import Laser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0JtAv0glFX"
      },
      "source": [
        "### **0.3 Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8T-f4KllIh7"
      },
      "source": [
        "#### **0.3.1 For Text Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C8ayV2QpLmq"
      },
      "outputs": [],
      "source": [
        "def lyrics_preprocessing(text_data):\n",
        "\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "      text = re.sub('\\[', '', text)\n",
        "      text = re.sub('\\]', '', text)\n",
        "      text = re.sub('\\_', ' ', text) # _\n",
        "      text = re.sub('\\!', ' ', text) # !\n",
        "      text = re.sub('\\?', ' ', text) # ?\n",
        "      text = re.sub('\\-', ' ', text) # -\n",
        "      text = re.sub(\"[\\[].*?\\]\", \"\", text)#delete everything between square brackets\n",
        "      \n",
        "      text = re.sub(\"EmbedShare URLCopyEmbedCopy\", '', text) #NOOO VA??????\n",
        "      text = re.sub(\"EmbedShareURLCopyEmbedCopy\", '', text) \n",
        "\n",
        "      preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8tmtMayqQK"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_preprocessed (Files, mypath, df):\n",
        "  #paragraphs \n",
        "  titles = []\n",
        "  paragraphs = []\n",
        "  for i in range(len(Files)):\n",
        "    f = open(mypath+'/'+Files[i], 'r')\n",
        "\n",
        "    data = f.read()\n",
        "    data_splited = data.split(\"\\n\\n\")\n",
        "    \n",
        "\n",
        "    for j in data_splited:\n",
        "      titles.append(Files[i])\n",
        "      unwanted = j.split(\"\\n\")\n",
        "      wanted = []\n",
        "      \n",
        "      if '[' in unwanted[0]:\n",
        "        wanted = unwanted[1:]\n",
        "        j = \"\\n\".join(wanted)\n",
        "\n",
        "      paragraphs.append(j)\n",
        "\n",
        "  df['title'] = titles\n",
        "  df['paragraph'] = paragraphs\n",
        "  \n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NwFoR7xlRwJ"
      },
      "source": [
        "#### **0.3.2 For Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky2zTKlflSUC"
      },
      "outputs": [],
      "source": [
        "# f1 evaluation\n",
        "def f1(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NecwZOArlX4z"
      },
      "source": [
        "#### **0.3.3 For Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjLfTrSClZW4"
      },
      "outputs": [],
      "source": [
        "def labeling (l_embeddings, df):\n",
        "  Xnew = tf.reshape(l_embeddings, [-1, 1, 1024])\n",
        "\n",
        "  probs=model.predict(Xnew) \n",
        "  #The first value of the prediction is for class 0 and the second for class 1 \n",
        "\n",
        "\n",
        "  ynew = []\n",
        "  probabilities = []\n",
        "  psxist = []\n",
        "  p_not_sxist = []\n",
        "  c=0\n",
        "  for item in probs:\n",
        "    if item[0][0]>item[0][1]:\n",
        "      y = 0\n",
        "      probability = item[0][0]  \n",
        "    else:\n",
        "      y = 1\n",
        "      probability = item[0][1]\n",
        "    p_not_sxist = np.append(p_not_sxist, item[0][0])\n",
        "    psxist = np.append(psxist, item[0][1])\n",
        "    c+=1\n",
        "    ynew = np.append(ynew, y)\n",
        "    probabilities = np.append(probabilities, probability)\n",
        "\n",
        "  df['label'] = ynew.astype('int')\n",
        "  df['label probability'] = probabilities\n",
        "  df['probability_sexist'] = psxist\n",
        "  df['probability_NOT_sexist'] = p_not_sxist\n",
        "  \n",
        "  df = df.sort_values('probability_sexist', ascending=False)\n",
        "  \n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1t9ZT8Zc8Kg"
      },
      "source": [
        "## **1. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "C3S3-7TQly-g",
        "outputId": "d3560cab-3019-4a13-ce0f-dbf59598e810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0                 lyricstxtBailemos_Dani Fernandez.txt   \n",
              "1    lyricstxtNathy Peluso Bzrp Music Sessions Vol....   \n",
              "2                       lyricstxtSafaera_Bad Bunny.txt   \n",
              "3                           lyricstxtIndeciso_Reik.txt   \n",
              "5                  lyricstxtLa Jeepeta _Nio Garcia.txt   \n",
              "..                                                 ...   \n",
              "760             lyricstxtbailamos_enrique iglesias.txt   \n",
              "761  lyricstxtanybody seen my baby_The rolling ston...   \n",
              "762                      lyricstxtCalma _Pedro Cap.txt   \n",
              "763    lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt   \n",
              "764                   lyricstxtHyper hyper_Scooter.txt   \n",
              "\n",
              "                                             paragraph  label  \\\n",
              "0    Bailaremos\\nBailaremos\\nBailemos\\nBailemos\\nBa...    1.0   \n",
              "1    Motherfuckin' ladies dancin'\\nMotherfu-Motherf...    1.0   \n",
              "2    Bla, bla, bla, bla, bla, bla\\nEy, yo', yo', yo...    1.0   \n",
              "3    Victoria ella no es un secreto\\nQue tú a mí me...    1.0   \n",
              "5    Arrebata'o, dando vuelta en la jeepeta (Dando ...    1.0   \n",
              "..                                                 ...    ...   \n",
              "760  Don't let the world in outside\\nDon't let a mo...    0.0   \n",
              "761  We came to rock for Brooklyn\\nAnd Queens\\nAnd ...    0.0   \n",
              "762  Desde la isla del encanto\\nFarru lanzai Pedro ...    0.0   \n",
              "763  Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...    0.0   \n",
              "764  We want to sing a big shout to U.S. and to all...    0.0   \n",
              "\n",
              "     true_label (0,1 or NA) racialized_person (0,1 or NA)  \\\n",
              "0                         0                             0   \n",
              "1                         1                             0   \n",
              "2                         0                             0   \n",
              "3                         1                             0   \n",
              "5                         1                             1   \n",
              "..                      ...                           ...   \n",
              "760                       0                             0   \n",
              "761                       0                             0   \n",
              "762                       0                             0   \n",
              "763                       0                             0   \n",
              "764                       0                             0   \n",
              "\n",
              "                              Reason      label probability  \\\n",
              "0                                NaN  9.897.588.491.439.810   \n",
              "1                 motherhood-related  9.618.873.596.191.400   \n",
              "2                                NaN  9.564.121.961.593.620   \n",
              "3                 hypersexualization  9.481.527.805.328.360   \n",
              "5    body shaming, sexual harassment  9.465.652.704.238.890   \n",
              "..                               ...                    ...   \n",
              "760                              NaN    998.933.732.509.613   \n",
              "761                              NaN  9.989.345.669.746.390   \n",
              "762                              NaN  9.989.352.822.303.770   \n",
              "763                              NaN  9.989.357.590.675.350   \n",
              "764                              NaN  9.989.377.856.254.570   \n",
              "\n",
              "         probability_sexist  probability_NOT_sexist  \n",
              "0     9.897.588.491.439.810  11.161.846.108.734.600  \n",
              "1     9.618.873.596.191.400   3.857.753.425.836.560  \n",
              "2     9.564.121.961.593.620   4.455.895.721.912.380  \n",
              "3     9.481.527.805.328.360   5.226.750.299.334.520  \n",
              "5     9.465.652.704.238.890  54.083.433.002.233.500  \n",
              "..                      ...                     ...  \n",
              "760  11.397.618.800.401.600     998.933.732.509.613  \n",
              "761  11.381.290.387.362.200   9.989.345.669.746.390  \n",
              "762  11.362.035.293.132.000   9.989.352.822.303.770  \n",
              "763   1.135.141.239.501.530   9.989.357.590.675.350  \n",
              "764  11.311.753.187.328.500   9.989.377.856.254.570  \n",
              "\n",
              "[1665 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c061526-22e4-4ea9-8219-5bc45ad758c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>true_label (0,1 or NA)</th>\n",
              "      <th>racialized_person (0,1 or NA)</th>\n",
              "      <th>Reason</th>\n",
              "      <th>label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtBailemos_Dani Fernandez.txt</td>\n",
              "      <td>Bailaremos\\nBailaremos\\nBailemos\\nBailemos\\nBa...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.897.588.491.439.810</td>\n",
              "      <td>9.897.588.491.439.810</td>\n",
              "      <td>11.161.846.108.734.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtNathy Peluso Bzrp Music Sessions Vol....</td>\n",
              "      <td>Motherfuckin' ladies dancin'\\nMotherfu-Motherf...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>motherhood-related</td>\n",
              "      <td>9.618.873.596.191.400</td>\n",
              "      <td>9.618.873.596.191.400</td>\n",
              "      <td>3.857.753.425.836.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtSafaera_Bad Bunny.txt</td>\n",
              "      <td>Bla, bla, bla, bla, bla, bla\\nEy, yo', yo', yo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.564.121.961.593.620</td>\n",
              "      <td>9.564.121.961.593.620</td>\n",
              "      <td>4.455.895.721.912.380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtIndeciso_Reik.txt</td>\n",
              "      <td>Victoria ella no es un secreto\\nQue tú a mí me...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>hypersexualization</td>\n",
              "      <td>9.481.527.805.328.360</td>\n",
              "      <td>9.481.527.805.328.360</td>\n",
              "      <td>5.226.750.299.334.520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lyricstxtLa Jeepeta _Nio Garcia.txt</td>\n",
              "      <td>Arrebata'o, dando vuelta en la jeepeta (Dando ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>body shaming, sexual harassment</td>\n",
              "      <td>9.465.652.704.238.890</td>\n",
              "      <td>9.465.652.704.238.890</td>\n",
              "      <td>54.083.433.002.233.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>lyricstxtbailamos_enrique iglesias.txt</td>\n",
              "      <td>Don't let the world in outside\\nDon't let a mo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "      <td>11.397.618.800.401.600</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>lyricstxtanybody seen my baby_The rolling ston...</td>\n",
              "      <td>We came to rock for Brooklyn\\nAnd Queens\\nAnd ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "      <td>11.381.290.387.362.200</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>lyricstxtCalma _Pedro Cap.txt</td>\n",
              "      <td>Desde la isla del encanto\\nFarru lanzai Pedro ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "      <td>11.362.035.293.132.000</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt</td>\n",
              "      <td>Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "      <td>1.135.141.239.501.530</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>lyricstxtHyper hyper_Scooter.txt</td>\n",
              "      <td>We want to sing a big shout to U.S. and to all...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "      <td>11.311.753.187.328.500</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1665 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c061526-22e4-4ea9-8219-5bc45ad758c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c061526-22e4-4ea9-8219-5bc45ad758c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c061526-22e4-4ea9-8219-5bc45ad758c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Pharagraphs to train and test \n",
        "labeled_2021 = '/content/gdrive/My Drive/predicted_2021.csv'\n",
        "labeled_60s = '/content/gdrive/My Drive/predicted_60s.csv' \n",
        "labeled_round2 = '/content/gdrive/My Drive/lyrics_Predicted_Round2.csv'\n",
        "\n",
        "l2021_df = pd.read_csv(labeled_2021)\n",
        "l60s_df = pd.read_csv(labeled_60s)\n",
        "lround2 = pd.read_csv(labeled_round2)\n",
        "lround2 = lround2.drop(columns=['decade'])\n",
        "\n",
        "#dataframe to be used\n",
        "tdf = pd.concat([l2021_df, l60s_df, lround2])\n",
        "tdf = tdf.dropna(subset=['true_label (0,1 or NA)'])\n",
        "tdf = tdf.replace([1.0, 0.0],[1,0])\n",
        "tdf = tdf[(tdf['true_label (0,1 or NA)'] != 'NAP')]\n",
        "pd.to_numeric(tdf['true_label (0,1 or NA)'], downcast = 'integer')\n",
        "tdf['true_label (0,1 or NA)']= pd.to_numeric(tdf['true_label (0,1 or NA)'])\n",
        "tdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KzVf7_Qzf1_I",
        "outputId": "d233896c-e7c9-4e2d-c2ad-60e23b22e084"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0               lyricstxtElla No Es Tuya _Rochy RD.txt   \n",
              "1               lyricstxtElla No Es Tuya _Rochy RD.txt   \n",
              "2                        lyricstxtAmanece_Anuel AA.txt   \n",
              "3                         lyricstxtMorado_J Balvin.txt   \n",
              "4                         lyricstxtMorado_J Balvin.txt   \n",
              "..                                                 ...   \n",
              "760             lyricstxtbailamos_enrique iglesias.txt   \n",
              "761  lyricstxtanybody seen my baby_The rolling ston...   \n",
              "762                      lyricstxtCalma _Pedro Cap.txt   \n",
              "763    lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt   \n",
              "764                   lyricstxtHyper hyper_Scooter.txt   \n",
              "\n",
              "                                             paragraph  label  \\\n",
              "0    Ella no e' tuya, te vendió sueño (Sí, porque c...    1.0   \n",
              "1    Ella no e' tuya, te vendió sueño\\nDice que no ...    1.0   \n",
              "2    Y como Karol G en mi cama (Cama)\\nComo Becky G...    1.0   \n",
              "3    Yo pedí un trago y ella la botella (Uh, uh, uh...    1.0   \n",
              "4    Yo pedí un trago y ella la botella (Ah-ah)\\nAb...    1.0   \n",
              "..                                                 ...    ...   \n",
              "760  Don't let the world in outside\\nDon't let a mo...    0.0   \n",
              "761  We came to rock for Brooklyn\\nAnd Queens\\nAnd ...    0.0   \n",
              "762  Desde la isla del encanto\\nFarru lanzai Pedro ...    0.0   \n",
              "763  Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...    0.0   \n",
              "764  We want to sing a big shout to U.S. and to all...    0.0   \n",
              "\n",
              "     true_label (0,1 or NA)  racialized_person (0,1 or NA)  \\\n",
              "0                       1.0                            0.0   \n",
              "1                       1.0                            0.0   \n",
              "2                       1.0                            0.0   \n",
              "3                       1.0                            0.0   \n",
              "4                       1.0                            0.0   \n",
              "..                      ...                            ...   \n",
              "760                     0.0                            0.0   \n",
              "761                     0.0                            0.0   \n",
              "762                     0.0                            0.0   \n",
              "763                     0.0                            0.0   \n",
              "764                     0.0                            0.0   \n",
              "\n",
              "                                                Reason      label probability  \\\n",
              "0                               attribute stereotyoing    995.332.658.290.863   \n",
              "1                               attribute stereotyoing  9.952.580.332.756.040   \n",
              "2    hypersexualization, paternalism, attribute ste...  9.944.848.418.235.770   \n",
              "3                                       victim blaming    993.961.751.461.029   \n",
              "4                                       victim blaming  9.939.129.948.616.020   \n",
              "..                                                 ...                    ...   \n",
              "760                                                NaN    998.933.732.509.613   \n",
              "761                                                NaN  9.989.345.669.746.390   \n",
              "762                                                NaN  9.989.352.822.303.770   \n",
              "763                                                NaN  9.989.357.590.675.350   \n",
              "764                                                NaN  9.989.377.856.254.570   \n",
              "\n",
              "         probability_sexist probability_NOT_sexist  \n",
              "0       995.332.658.290.863    479.504.419.490.695  \n",
              "1     9.952.580.332.756.040  4.873.421.508.818.860  \n",
              "2     9.944.848.418.235.770  5.661.717.616.021.630  \n",
              "3       993.961.751.461.029  6.203.438.155.353.060  \n",
              "4     9.939.129.948.616.020  6.251.112.557.947.630  \n",
              "..                      ...                    ...  \n",
              "760  11.397.618.800.401.600    998.933.732.509.613  \n",
              "761  11.381.290.387.362.200  9.989.345.669.746.390  \n",
              "762  11.362.035.293.132.000  9.989.352.822.303.770  \n",
              "763   1.135.141.239.501.530  9.989.357.590.675.350  \n",
              "764  11.311.753.187.328.500  9.989.377.856.254.570  \n",
              "\n",
              "[635 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56420e01-555d-4787-a897-279ad90cf578\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>true_label (0,1 or NA)</th>\n",
              "      <th>racialized_person (0,1 or NA)</th>\n",
              "      <th>Reason</th>\n",
              "      <th>label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtElla No Es Tuya _Rochy RD.txt</td>\n",
              "      <td>Ella no e' tuya, te vendió sueño (Sí, porque c...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>attribute stereotyoing</td>\n",
              "      <td>995.332.658.290.863</td>\n",
              "      <td>995.332.658.290.863</td>\n",
              "      <td>479.504.419.490.695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtElla No Es Tuya _Rochy RD.txt</td>\n",
              "      <td>Ella no e' tuya, te vendió sueño\\nDice que no ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>attribute stereotyoing</td>\n",
              "      <td>9.952.580.332.756.040</td>\n",
              "      <td>9.952.580.332.756.040</td>\n",
              "      <td>4.873.421.508.818.860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtAmanece_Anuel AA.txt</td>\n",
              "      <td>Y como Karol G en mi cama (Cama)\\nComo Becky G...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>hypersexualization, paternalism, attribute ste...</td>\n",
              "      <td>9.944.848.418.235.770</td>\n",
              "      <td>9.944.848.418.235.770</td>\n",
              "      <td>5.661.717.616.021.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtMorado_J Balvin.txt</td>\n",
              "      <td>Yo pedí un trago y ella la botella (Uh, uh, uh...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>victim blaming</td>\n",
              "      <td>993.961.751.461.029</td>\n",
              "      <td>993.961.751.461.029</td>\n",
              "      <td>6.203.438.155.353.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxtMorado_J Balvin.txt</td>\n",
              "      <td>Yo pedí un trago y ella la botella (Ah-ah)\\nAb...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>victim blaming</td>\n",
              "      <td>9.939.129.948.616.020</td>\n",
              "      <td>9.939.129.948.616.020</td>\n",
              "      <td>6.251.112.557.947.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>lyricstxtbailamos_enrique iglesias.txt</td>\n",
              "      <td>Don't let the world in outside\\nDon't let a mo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "      <td>11.397.618.800.401.600</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>lyricstxtanybody seen my baby_The rolling ston...</td>\n",
              "      <td>We came to rock for Brooklyn\\nAnd Queens\\nAnd ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "      <td>11.381.290.387.362.200</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>lyricstxtCalma _Pedro Cap.txt</td>\n",
              "      <td>Desde la isla del encanto\\nFarru lanzai Pedro ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "      <td>11.362.035.293.132.000</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt</td>\n",
              "      <td>Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "      <td>1.135.141.239.501.530</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>lyricstxtHyper hyper_Scooter.txt</td>\n",
              "      <td>We want to sing a big shout to U.S. and to all...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "      <td>11.311.753.187.328.500</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>635 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56420e01-555d-4787-a897-279ad90cf578')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56420e01-555d-4787-a897-279ad90cf578 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56420e01-555d-4787-a897-279ad90cf578');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#training = \"C:/Users/Lau/Desktop/TFG/LYRICS_TFG/training_dataset.csv\"\n",
        "training_df = lround2.copy()\n",
        "training_df = training_df.dropna(subset=['true_label (0,1 or NA)'])\n",
        "training_df = training_df.replace([1.0, 0.0],[1,0])\n",
        "pd.to_numeric(training_df['true_label (0,1 or NA)'], downcast = 'integer')\n",
        "training_df['true_label (0,1 or NA)']= pd.to_numeric(training_df['true_label (0,1 or NA)'])\n",
        "training_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-9eFc_df5Un"
      },
      "source": [
        "## **2. Lyrics to be Labeled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FZHXK5UWlhRT",
        "outputId": "c73247eb-28fd-4550-a4ee-24e1a48d7d7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0    lyricstxtA steel guitar and a glass of wine_Pa...   \n",
              "1    lyricstxtA steel guitar and a glass of wine_Pa...   \n",
              "2    lyricstxtA steel guitar and a glass of wine_Pa...   \n",
              "3    lyricstxtA steel guitar and a glass of wine_Pa...   \n",
              "4    lyricstxtA steel guitar and a glass of wine_Pa...   \n",
              "..                                                 ...   \n",
              "817              lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "818              lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "819              lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "820              lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "821              lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "\n",
              "                                             paragraph label  \n",
              "0    Just give me a steel guitar, a glass of wine\\n...   NaN  \n",
              "1    And bring me wine\\nAnd make the music mine\\nPl...   NaN  \n",
              "2    Mmm, bring me a steel guitar and a glass of wi...   NaN  \n",
              "3    And bring me wine\\nMake the music mine\\nPlay a...   NaN  \n",
              "4    And bring me a steel guitar and a glass of win...   NaN  \n",
              "..                                                 ...   ...  \n",
              "817  Colgando del cuello los juguete' (Del cuello l...   NaN  \n",
              "818  Somos dos cantantes como los de ante'\\nEl resp...   NaN  \n",
              "819  (Woh-oh, oh-oh)\\nY yo por ti, tú por mí, ¿quié...   NaN  \n",
              "820  Somos dos cantantes como los de ante'\\nEl resp...   NaN  \n",
              "821  La Rosalía\\nMira, ¿quién lo diría (¿Qué?), que...   NaN  \n",
              "\n",
              "[17407 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c2adbe9-4624-439e-8bad-28e8ed3d9ad8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtA steel guitar and a glass of wine_Pa...</td>\n",
              "      <td>Just give me a steel guitar, a glass of wine\\n...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtA steel guitar and a glass of wine_Pa...</td>\n",
              "      <td>And bring me wine\\nAnd make the music mine\\nPl...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtA steel guitar and a glass of wine_Pa...</td>\n",
              "      <td>Mmm, bring me a steel guitar and a glass of wi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtA steel guitar and a glass of wine_Pa...</td>\n",
              "      <td>And bring me wine\\nMake the music mine\\nPlay a...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxtA steel guitar and a glass of wine_Pa...</td>\n",
              "      <td>And bring me a steel guitar and a glass of win...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Colgando del cuello los juguete' (Del cuello l...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Somos dos cantantes como los de ante'\\nEl resp...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>(Woh-oh, oh-oh)\\nY yo por ti, tú por mí, ¿quié...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Somos dos cantantes como los de ante'\\nEl resp...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>821</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>La Rosalía\\nMira, ¿quién lo diría (¿Qué?), que...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17407 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c2adbe9-4624-439e-8bad-28e8ed3d9ad8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c2adbe9-4624-439e-8bad-28e8ed3d9ad8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c2adbe9-4624-439e-8bad-28e8ed3d9ad8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Lyrics to be labeled \n",
        "mypath60s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1960-1969'\n",
        "mypath70s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1970-1979'\n",
        "mypath80s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1980-1989'\n",
        "mypath90s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1990-1999'\n",
        "mypath00s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2000-2009'\n",
        "mypath10s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2010-2019'\n",
        "mypath20s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2020-2021'\n",
        "\n",
        "mypaths = [mypath60s, mypath70s, mypath80s, mypath90s, mypath00s, mypath10s, mypath20s]\n",
        "\n",
        "Files60s = [f for f in listdir(mypath60s) if isfile(join(mypath60s, f))]\n",
        "Files70s = [f for f in listdir(mypath70s) if isfile(join(mypath70s, f))]\n",
        "Files80s = [f for f in listdir(mypath80s) if isfile(join(mypath80s, f))]\n",
        "Files90s = [f for f in listdir(mypath90s) if isfile(join(mypath90s, f))]\n",
        "Files00s = [f for f in listdir(mypath00s) if isfile(join(mypath00s, f))]\n",
        "Files10s = [f for f in listdir(mypath10s) if isfile(join(mypath10s, f))]\n",
        "Files20s = [f for f in listdir(mypath20s) if isfile(join(mypath20s, f))]\n",
        "\n",
        "#Eliminate songs that are already labeled\n",
        "titles = tdf['title'].tolist()\n",
        "\n",
        "def del_labeled(list_files, list_titles):\n",
        "  for fl in list_files:\n",
        "    if fl in list_titles:\n",
        "      list_files.remove(fl)\n",
        "  return list_files\n",
        "\n",
        "Files = [Files60s, Files70s, Files80s, Files90s, Files00s, Files10s, Files20s]\n",
        "for i in Files: \n",
        "  i = del_labeled(i, titles)\n",
        "\n",
        "\n",
        "\n",
        "cols=['title', 'paragraph', 'label']\n",
        "lyfinal_df = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "i = 0\n",
        "lyrics_df_list = []\n",
        "for path in mypaths: \n",
        "  new_ly_df = pd.DataFrame(columns=cols)\n",
        "  ldf = get_paragraphs_preprocessed(Files[i], path, new_ly_df)\n",
        "  lyrics_df_list.append(ldf)\n",
        "  i+=1\n",
        "\n",
        "lyfinal_df = pd.concat(lyrics_df_list)\n",
        "\n",
        "lyfinal_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M627jdgcxIO"
      },
      "source": [
        "## **3. LSTM Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5jif2KuyI91"
      },
      "source": [
        "### **3.1 Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7c-p3iRrAte"
      },
      "outputs": [],
      "source": [
        "laser = Laser() # importing class for using embeddings extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqNmRDoGe_CM"
      },
      "outputs": [],
      "source": [
        "#Llegim el embedder fasttext\n",
        "with open(\"/content/gdrive/My Drive/embeddings-new_large-general_3B_fasttext.vec\") as f:\n",
        "    #Creem el diccionari on guardarem el embeder\n",
        "    fastText_dict = dict()\n",
        "    #Recorrem les linies que contenen, la paraula seguida del vector\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        #Agafem la paraula\n",
        "        word = values[0]\n",
        "        word = str(word)\n",
        "        #I el vector\n",
        "        vector = np.asarray(values[1:],'float32')\n",
        "        fastText_dict[word]=vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxQMFrO0j1W6"
      },
      "outputs": [],
      "source": [
        "#Aquesta funció la vaig fer jo per a INPL hauríem de mirar com millorarla o si tot s'entén\n",
        "def vec_sentence(sentence,emb_dict):\n",
        "    \"\"\"\n",
        "      Function that recives a sentence and the embeding dictionary and \n",
        "      Compute the average vector of the vectors of each word\n",
        "    \"\"\"\n",
        "    #We split the words after converting to lower letters and remove '?' simbol\n",
        "    words = sentence.lower().replace(\"?\", '').split(\" \")\n",
        "    iteration = 0\n",
        "    for word in words:\n",
        "        iteration += 1\n",
        "        if iteration == 1:\n",
        "            if word in emb_dict:\n",
        "                average = np.array(emb_dict[word])\n",
        "            else:\n",
        "                average = np.zeros(len(emb_dict[\"word\"]))\n",
        "        else:\n",
        "            if word in emb_dict:\n",
        "                average += emb_dict[word]\n",
        "    return average / len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2vuBSB6ydO2"
      },
      "outputs": [],
      "source": [
        "#processed dataframe\n",
        "X_tobe_processed = tdf['paragraph']\n",
        "\n",
        "X_processed = lyrics_preprocessing(X_tobe_processed)\n",
        "X_embeddings_las = laser.embed_sentences(X_processed, lang = 'es')\n",
        "\n",
        "y = tdf['true_label (0,1 or NA)']\n",
        "\n",
        "#LASER + FASTTEXT\n",
        "X_embeddings = X_embeddings_las\n",
        "sentences = []\n",
        "for i,text in enumerate(X_processed):\n",
        "  embed_vect = vec_sentence(text,fastText_dict)\n",
        "  aux = list(X_embeddings[i])\n",
        "  aux.extend(embed_vect)\n",
        "  sentences.append(np.array(aux))\n",
        "X_embeddings = np.array(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjlqlw3ffEib"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Oo-0NB8gmn"
      },
      "outputs": [],
      "source": [
        "lyfinal_df['paragraph'] = lyfinal_df['paragraph'].astype(str)\n",
        "lyrics_processed = lyrics_preprocessing(lyfinal_df['paragraph'])\n",
        "lyrics_embeddings = laser.embed_sentences(lyrics_processed, lang = 'es')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NulXGZKWq0",
        "outputId": "24d36edd-8b98-4f3f-8a6e-2547a3951065"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115, 1324)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oJCu3JLQiOz",
        "outputId": "fac84642-2413-4374-a592-aede91ad045f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtgGcWYsyPFl"
      },
      "source": [
        "### **3.2 Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Oh78kMTEVME",
        "outputId": "4f208de3-fde7-48f5-b0ab-2995a2e2cae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (1115, 1, 1324) (1115, 1, 2)\n",
            "Test data shapes: (550, 1, 1324) (550, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 8s 97ms/step - loss: 0.6574 - accuracy: 0.5659 - f1: 0.5542 - auc: 0.6305 - val_loss: 0.5895 - val_accuracy: 0.7036 - val_f1: 0.6370 - val_auc: 0.7835\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5791 - accuracy: 0.6762 - f1: 0.6211 - auc: 0.7624 - val_loss: 0.5683 - val_accuracy: 0.7036 - val_f1: 0.6065 - val_auc: 0.8169\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5565 - accuracy: 0.6753 - f1: 0.6267 - auc: 0.8001 - val_loss: 0.5479 - val_accuracy: 0.7164 - val_f1: 0.6415 - val_auc: 0.8257\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.5112 - accuracy: 0.7901 - f1: 0.6569 - auc: 0.8583 - val_loss: 0.4727 - val_accuracy: 0.8200 - val_f1: 0.6811 - val_auc: 0.8705\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4100 - accuracy: 0.8377 - f1: 0.7352 - auc: 0.8939 - val_loss: 0.3962 - val_accuracy: 0.8418 - val_f1: 0.7510 - val_auc: 0.8996\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3502 - accuracy: 0.8565 - f1: 0.7814 - auc: 0.9238 - val_loss: 0.3733 - val_accuracy: 0.8473 - val_f1: 0.7794 - val_auc: 0.9110\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3449 - accuracy: 0.8574 - f1: 0.7939 - auc: 0.9273 - val_loss: 0.3917 - val_accuracy: 0.8473 - val_f1: 0.7738 - val_auc: 0.9027\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3076 - accuracy: 0.8861 - f1: 0.7982 - auc: 0.9424 - val_loss: 0.3619 - val_accuracy: 0.8491 - val_f1: 0.7899 - val_auc: 0.9193\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2750 - accuracy: 0.8960 - f1: 0.8404 - auc: 0.9521 - val_loss: 0.3590 - val_accuracy: 0.8636 - val_f1: 0.7923 - val_auc: 0.9194\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2464 - accuracy: 0.9103 - f1: 0.8422 - auc: 0.9626 - val_loss: 0.3510 - val_accuracy: 0.8673 - val_f1: 0.8184 - val_auc: 0.9249\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2217 - accuracy: 0.9157 - f1: 0.8574 - auc: 0.9698 - val_loss: 0.3666 - val_accuracy: 0.8436 - val_f1: 0.8026 - val_auc: 0.9222\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2094 - accuracy: 0.9202 - f1: 0.8745 - auc: 0.9734 - val_loss: 0.3893 - val_accuracy: 0.8582 - val_f1: 0.8153 - val_auc: 0.9173\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1826 - accuracy: 0.9327 - f1: 0.8830 - auc: 0.9797 - val_loss: 0.3568 - val_accuracy: 0.8636 - val_f1: 0.8250 - val_auc: 0.9285\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1558 - accuracy: 0.9489 - f1: 0.9012 - auc: 0.9851 - val_loss: 0.3767 - val_accuracy: 0.8673 - val_f1: 0.8396 - val_auc: 0.9277\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1334 - accuracy: 0.9587 - f1: 0.9139 - auc: 0.9886 - val_loss: 0.4054 - val_accuracy: 0.8691 - val_f1: 0.8375 - val_auc: 0.9231\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1275 - accuracy: 0.9543 - f1: 0.9238 - auc: 0.9893 - val_loss: 0.4108 - val_accuracy: 0.8636 - val_f1: 0.8390 - val_auc: 0.9235\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1069 - accuracy: 0.9623 - f1: 0.9331 - auc: 0.9924 - val_loss: 0.4272 - val_accuracy: 0.8636 - val_f1: 0.8455 - val_auc: 0.9253\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1012 - accuracy: 0.9704 - f1: 0.9446 - auc: 0.9919 - val_loss: 0.4573 - val_accuracy: 0.8509 - val_f1: 0.8322 - val_auc: 0.9188\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0750 - accuracy: 0.9794 - f1: 0.9562 - auc: 0.9949 - val_loss: 0.4534 - val_accuracy: 0.8545 - val_f1: 0.8408 - val_auc: 0.9224\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0654 - accuracy: 0.9812 - f1: 0.9537 - auc: 0.9960 - val_loss: 0.4844 - val_accuracy: 0.8509 - val_f1: 0.8386 - val_auc: 0.9186\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 85.09%\n",
            "F1: 84.01%\n",
            "AUC: 91.86%\n",
            "Loss: 0.48%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 93ms/step - loss: 0.6166 - accuracy: 0.6762 - f1: 0.5720 - auc: 0.7248 - val_loss: 0.5631 - val_accuracy: 0.7036 - val_f1: 0.6171 - val_auc: 0.8203\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5561 - accuracy: 0.7049 - f1: 0.6271 - auc: 0.7862 - val_loss: 0.5232 - val_accuracy: 0.8036 - val_f1: 0.6543 - val_auc: 0.8545\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4785 - accuracy: 0.8179 - f1: 0.6723 - auc: 0.8740 - val_loss: 0.4601 - val_accuracy: 0.8000 - val_f1: 0.6748 - val_auc: 0.8760\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3977 - accuracy: 0.8386 - f1: 0.7306 - auc: 0.9034 - val_loss: 0.4269 - val_accuracy: 0.8436 - val_f1: 0.7710 - val_auc: 0.8905\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3620 - accuracy: 0.8493 - f1: 0.7906 - auc: 0.9184 - val_loss: 0.4399 - val_accuracy: 0.8291 - val_f1: 0.7758 - val_auc: 0.8900\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3319 - accuracy: 0.8628 - f1: 0.7888 - auc: 0.9315 - val_loss: 0.3746 - val_accuracy: 0.8509 - val_f1: 0.7869 - val_auc: 0.9122\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3012 - accuracy: 0.8735 - f1: 0.8123 - auc: 0.9445 - val_loss: 0.3631 - val_accuracy: 0.8455 - val_f1: 0.7800 - val_auc: 0.9187\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2615 - accuracy: 0.8996 - f1: 0.8334 - auc: 0.9591 - val_loss: 0.3731 - val_accuracy: 0.8345 - val_f1: 0.7800 - val_auc: 0.9153\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2469 - accuracy: 0.8987 - f1: 0.8491 - auc: 0.9636 - val_loss: 0.3638 - val_accuracy: 0.8545 - val_f1: 0.8089 - val_auc: 0.9222\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2183 - accuracy: 0.9157 - f1: 0.8685 - auc: 0.9712 - val_loss: 0.3897 - val_accuracy: 0.8564 - val_f1: 0.8189 - val_auc: 0.9175\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2049 - accuracy: 0.9166 - f1: 0.8731 - auc: 0.9735 - val_loss: 0.3699 - val_accuracy: 0.8545 - val_f1: 0.8232 - val_auc: 0.9242\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1730 - accuracy: 0.9336 - f1: 0.8912 - auc: 0.9816 - val_loss: 0.3800 - val_accuracy: 0.8600 - val_f1: 0.8176 - val_auc: 0.9229\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1550 - accuracy: 0.9381 - f1: 0.8978 - auc: 0.9848 - val_loss: 0.3992 - val_accuracy: 0.8582 - val_f1: 0.8343 - val_auc: 0.9220\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1481 - accuracy: 0.9408 - f1: 0.9070 - auc: 0.9867 - val_loss: 0.4118 - val_accuracy: 0.8509 - val_f1: 0.8149 - val_auc: 0.9168\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1130 - accuracy: 0.9650 - f1: 0.9279 - auc: 0.9913 - val_loss: 0.4132 - val_accuracy: 0.8400 - val_f1: 0.8237 - val_auc: 0.9209\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0925 - accuracy: 0.9749 - f1: 0.9385 - auc: 0.9941 - val_loss: 0.4281 - val_accuracy: 0.8582 - val_f1: 0.8391 - val_auc: 0.9222\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0813 - accuracy: 0.9785 - f1: 0.9495 - auc: 0.9947 - val_loss: 0.4906 - val_accuracy: 0.8327 - val_f1: 0.8205 - val_auc: 0.9103\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0663 - accuracy: 0.9848 - f1: 0.9538 - auc: 0.9963 - val_loss: 0.4857 - val_accuracy: 0.8491 - val_f1: 0.8372 - val_auc: 0.9176\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0602 - accuracy: 0.9830 - f1: 0.9641 - auc: 0.9961 - val_loss: 0.5047 - val_accuracy: 0.8564 - val_f1: 0.8457 - val_auc: 0.9165\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0626 - accuracy: 0.9740 - f1: 0.9626 - auc: 0.9961 - val_loss: 0.5348 - val_accuracy: 0.8564 - val_f1: 0.8539 - val_auc: 0.9161\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 85.64%\n",
            "F1: 85.69%\n",
            "AUC: 91.61%\n",
            "Loss: 0.53%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 97ms/step - loss: 0.6807 - accuracy: 0.5578 - f1: 0.5690 - auc: 0.6076 - val_loss: 0.6014 - val_accuracy: 0.7036 - val_f1: 0.6065 - val_auc: 0.7778\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5877 - accuracy: 0.6762 - f1: 0.5996 - auc: 0.7611 - val_loss: 0.5659 - val_accuracy: 0.7036 - val_f1: 0.6168 - val_auc: 0.8202\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5548 - accuracy: 0.6879 - f1: 0.6198 - auc: 0.8053 - val_loss: 0.5369 - val_accuracy: 0.7036 - val_f1: 0.6495 - val_auc: 0.8284\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5236 - accuracy: 0.7220 - f1: 0.6604 - auc: 0.8234 - val_loss: 0.5252 - val_accuracy: 0.7527 - val_f1: 0.6308 - val_auc: 0.8323\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4564 - accuracy: 0.8179 - f1: 0.6853 - auc: 0.8796 - val_loss: 0.4235 - val_accuracy: 0.8309 - val_f1: 0.7084 - val_auc: 0.8933\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3859 - accuracy: 0.8422 - f1: 0.7438 - auc: 0.9086 - val_loss: 0.4055 - val_accuracy: 0.8291 - val_f1: 0.7605 - val_auc: 0.8975\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3547 - accuracy: 0.8529 - f1: 0.7897 - auc: 0.9219 - val_loss: 0.3807 - val_accuracy: 0.8436 - val_f1: 0.7563 - val_auc: 0.9100\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3163 - accuracy: 0.8700 - f1: 0.7917 - auc: 0.9405 - val_loss: 0.3817 - val_accuracy: 0.8527 - val_f1: 0.7905 - val_auc: 0.9089\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3089 - accuracy: 0.8762 - f1: 0.8126 - auc: 0.9419 - val_loss: 0.3639 - val_accuracy: 0.8618 - val_f1: 0.7980 - val_auc: 0.9167\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2867 - accuracy: 0.8834 - f1: 0.8246 - auc: 0.9501 - val_loss: 0.3621 - val_accuracy: 0.8618 - val_f1: 0.8027 - val_auc: 0.9183\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2504 - accuracy: 0.9067 - f1: 0.8348 - auc: 0.9635 - val_loss: 0.3589 - val_accuracy: 0.8564 - val_f1: 0.8129 - val_auc: 0.9231\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2319 - accuracy: 0.9067 - f1: 0.8591 - auc: 0.9676 - val_loss: 0.3677 - val_accuracy: 0.8473 - val_f1: 0.8032 - val_auc: 0.9183\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2078 - accuracy: 0.9220 - f1: 0.8702 - auc: 0.9736 - val_loss: 0.3885 - val_accuracy: 0.8364 - val_f1: 0.8028 - val_auc: 0.9155\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2243 - accuracy: 0.9076 - f1: 0.8571 - auc: 0.9697 - val_loss: 0.3617 - val_accuracy: 0.8655 - val_f1: 0.8264 - val_auc: 0.9255\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2178 - accuracy: 0.9220 - f1: 0.8646 - auc: 0.9710 - val_loss: 0.3689 - val_accuracy: 0.8709 - val_f1: 0.8338 - val_auc: 0.9248\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1626 - accuracy: 0.9444 - f1: 0.8974 - auc: 0.9837 - val_loss: 0.3642 - val_accuracy: 0.8636 - val_f1: 0.8257 - val_auc: 0.9241\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1493 - accuracy: 0.9480 - f1: 0.9082 - auc: 0.9858 - val_loss: 0.3814 - val_accuracy: 0.8600 - val_f1: 0.8347 - val_auc: 0.9246\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1342 - accuracy: 0.9587 - f1: 0.9135 - auc: 0.9878 - val_loss: 0.3974 - val_accuracy: 0.8473 - val_f1: 0.8323 - val_auc: 0.9241\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1320 - accuracy: 0.9552 - f1: 0.9202 - auc: 0.9888 - val_loss: 0.3958 - val_accuracy: 0.8491 - val_f1: 0.8267 - val_auc: 0.9233\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1105 - accuracy: 0.9632 - f1: 0.9205 - auc: 0.9919 - val_loss: 0.5551 - val_accuracy: 0.7982 - val_f1: 0.7796 - val_auc: 0.8749\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 79.82%\n",
            "F1: 78.21%\n",
            "AUC: 87.49%\n",
            "Loss: 0.56%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 94ms/step - loss: 0.7788 - accuracy: 0.4915 - f1: 0.4336 - auc: 0.4891 - val_loss: 0.6289 - val_accuracy: 0.7036 - val_f1: 0.6459 - val_auc: 0.7580\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.6170 - accuracy: 0.6762 - f1: 0.6165 - auc: 0.7526 - val_loss: 0.5901 - val_accuracy: 0.7109 - val_f1: 0.5602 - val_auc: 0.8074\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5691 - accuracy: 0.7166 - f1: 0.5924 - auc: 0.8010 - val_loss: 0.5534 - val_accuracy: 0.7127 - val_f1: 0.6391 - val_auc: 0.8208\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5356 - accuracy: 0.7408 - f1: 0.6542 - auc: 0.8279 - val_loss: 0.5333 - val_accuracy: 0.7782 - val_f1: 0.6478 - val_auc: 0.8469\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5021 - accuracy: 0.8009 - f1: 0.6596 - auc: 0.8586 - val_loss: 0.4783 - val_accuracy: 0.8327 - val_f1: 0.6722 - val_auc: 0.8691\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.4299 - accuracy: 0.8413 - f1: 0.7102 - auc: 0.8924 - val_loss: 0.4208 - val_accuracy: 0.8436 - val_f1: 0.7339 - val_auc: 0.8890\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3728 - accuracy: 0.8448 - f1: 0.7516 - auc: 0.9133 - val_loss: 0.3908 - val_accuracy: 0.8364 - val_f1: 0.7577 - val_auc: 0.9033\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3376 - accuracy: 0.8628 - f1: 0.7799 - auc: 0.9300 - val_loss: 0.3824 - val_accuracy: 0.8309 - val_f1: 0.7640 - val_auc: 0.9089\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3333 - accuracy: 0.8664 - f1: 0.8034 - auc: 0.9316 - val_loss: 0.3729 - val_accuracy: 0.8418 - val_f1: 0.7687 - val_auc: 0.9138\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3046 - accuracy: 0.8744 - f1: 0.8055 - auc: 0.9456 - val_loss: 0.3686 - val_accuracy: 0.8327 - val_f1: 0.7708 - val_auc: 0.9166\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2869 - accuracy: 0.8951 - f1: 0.8189 - auc: 0.9491 - val_loss: 0.3920 - val_accuracy: 0.8236 - val_f1: 0.7689 - val_auc: 0.9077\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2728 - accuracy: 0.8906 - f1: 0.8216 - auc: 0.9551 - val_loss: 0.3568 - val_accuracy: 0.8582 - val_f1: 0.8064 - val_auc: 0.9224\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2469 - accuracy: 0.9103 - f1: 0.8403 - auc: 0.9619 - val_loss: 0.3610 - val_accuracy: 0.8491 - val_f1: 0.7923 - val_auc: 0.9208\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2227 - accuracy: 0.9157 - f1: 0.8563 - auc: 0.9717 - val_loss: 0.3646 - val_accuracy: 0.8636 - val_f1: 0.8126 - val_auc: 0.9224\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2039 - accuracy: 0.9229 - f1: 0.8758 - auc: 0.9742 - val_loss: 0.3957 - val_accuracy: 0.8509 - val_f1: 0.8089 - val_auc: 0.9150\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1936 - accuracy: 0.9291 - f1: 0.8735 - auc: 0.9761 - val_loss: 0.4217 - val_accuracy: 0.8182 - val_f1: 0.7939 - val_auc: 0.9056\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1902 - accuracy: 0.9274 - f1: 0.8815 - auc: 0.9777 - val_loss: 0.3845 - val_accuracy: 0.8600 - val_f1: 0.8280 - val_auc: 0.9216\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1931 - accuracy: 0.9336 - f1: 0.8985 - auc: 0.9754 - val_loss: 0.3762 - val_accuracy: 0.8509 - val_f1: 0.8153 - val_auc: 0.9217\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1532 - accuracy: 0.9498 - f1: 0.8979 - auc: 0.9850 - val_loss: 0.4118 - val_accuracy: 0.8582 - val_f1: 0.8359 - val_auc: 0.9210\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1515 - accuracy: 0.9543 - f1: 0.9071 - auc: 0.9840 - val_loss: 0.4045 - val_accuracy: 0.8527 - val_f1: 0.8198 - val_auc: 0.9197\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 85.27%\n",
            "F1: 82.28%\n",
            "AUC: 91.97%\n",
            "Loss: 0.40%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 3s 94ms/step - loss: 0.6501 - accuracy: 0.6762 - f1: 0.5333 - auc: 0.6940 - val_loss: 0.5806 - val_accuracy: 0.7036 - val_f1: 0.6259 - val_auc: 0.8004\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5727 - accuracy: 0.6762 - f1: 0.6093 - auc: 0.7716 - val_loss: 0.5622 - val_accuracy: 0.7036 - val_f1: 0.6272 - val_auc: 0.8194\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5430 - accuracy: 0.7193 - f1: 0.6448 - auc: 0.8149 - val_loss: 0.5153 - val_accuracy: 0.8018 - val_f1: 0.6621 - val_auc: 0.8550\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.4754 - accuracy: 0.8197 - f1: 0.6781 - auc: 0.8712 - val_loss: 0.4417 - val_accuracy: 0.8182 - val_f1: 0.7043 - val_auc: 0.8804\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3947 - accuracy: 0.8430 - f1: 0.7453 - auc: 0.9017 - val_loss: 0.4066 - val_accuracy: 0.8182 - val_f1: 0.7417 - val_auc: 0.8963\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3555 - accuracy: 0.8511 - f1: 0.7838 - auc: 0.9228 - val_loss: 0.3811 - val_accuracy: 0.8382 - val_f1: 0.7638 - val_auc: 0.9096\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3062 - accuracy: 0.8780 - f1: 0.8005 - auc: 0.9438 - val_loss: 0.3620 - val_accuracy: 0.8491 - val_f1: 0.7788 - val_auc: 0.9181\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2781 - accuracy: 0.8942 - f1: 0.8330 - auc: 0.9515 - val_loss: 0.3756 - val_accuracy: 0.8327 - val_f1: 0.7783 - val_auc: 0.9143\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2544 - accuracy: 0.9031 - f1: 0.8423 - auc: 0.9607 - val_loss: 0.4407 - val_accuracy: 0.8327 - val_f1: 0.8084 - val_auc: 0.9049\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2693 - accuracy: 0.8897 - f1: 0.8526 - auc: 0.9558 - val_loss: 0.3554 - val_accuracy: 0.8564 - val_f1: 0.8122 - val_auc: 0.9262\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2031 - accuracy: 0.9220 - f1: 0.8681 - auc: 0.9752 - val_loss: 0.3713 - val_accuracy: 0.8418 - val_f1: 0.8039 - val_auc: 0.9201\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1781 - accuracy: 0.9345 - f1: 0.8882 - auc: 0.9794 - val_loss: 0.3716 - val_accuracy: 0.8564 - val_f1: 0.8234 - val_auc: 0.9239\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1613 - accuracy: 0.9462 - f1: 0.9038 - auc: 0.9830 - val_loss: 0.4311 - val_accuracy: 0.8327 - val_f1: 0.8091 - val_auc: 0.9074\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1762 - accuracy: 0.9417 - f1: 0.8957 - auc: 0.9794 - val_loss: 0.4780 - val_accuracy: 0.8436 - val_f1: 0.8338 - val_auc: 0.9121\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2013 - accuracy: 0.9256 - f1: 0.8971 - auc: 0.9747 - val_loss: 0.5503 - val_accuracy: 0.7673 - val_f1: 0.7408 - val_auc: 0.8556\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1815 - accuracy: 0.9300 - f1: 0.8951 - auc: 0.9791 - val_loss: 0.3802 - val_accuracy: 0.8655 - val_f1: 0.8407 - val_auc: 0.9264\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1375 - accuracy: 0.9543 - f1: 0.9067 - auc: 0.9878 - val_loss: 0.4050 - val_accuracy: 0.8582 - val_f1: 0.8363 - val_auc: 0.9197\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1419 - accuracy: 0.9453 - f1: 0.9203 - auc: 0.9868 - val_loss: 0.4621 - val_accuracy: 0.8200 - val_f1: 0.7964 - val_auc: 0.8969\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1123 - accuracy: 0.9605 - f1: 0.9293 - auc: 0.9919 - val_loss: 0.4499 - val_accuracy: 0.8473 - val_f1: 0.8222 - val_auc: 0.9099\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0991 - accuracy: 0.9695 - f1: 0.9413 - auc: 0.9927 - val_loss: 0.4197 - val_accuracy: 0.8600 - val_f1: 0.8437 - val_auc: 0.9248\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 86.00%\n",
            "F1: 84.53%\n",
            "AUC: 92.48%\n",
            "Loss: 0.42%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 96ms/step - loss: 0.6285 - accuracy: 0.6762 - f1: 0.5672 - auc: 0.6961 - val_loss: 0.5746 - val_accuracy: 0.7036 - val_f1: 0.6096 - val_auc: 0.8157\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5715 - accuracy: 0.6771 - f1: 0.6195 - auc: 0.7745 - val_loss: 0.5563 - val_accuracy: 0.7836 - val_f1: 0.6251 - val_auc: 0.8422\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5247 - accuracy: 0.7937 - f1: 0.6468 - auc: 0.8527 - val_loss: 0.4998 - val_accuracy: 0.8018 - val_f1: 0.6561 - val_auc: 0.8643\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.4520 - accuracy: 0.8108 - f1: 0.6927 - auc: 0.8801 - val_loss: 0.4585 - val_accuracy: 0.7836 - val_f1: 0.6861 - val_auc: 0.8689\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3945 - accuracy: 0.8475 - f1: 0.7567 - auc: 0.9005 - val_loss: 0.3957 - val_accuracy: 0.8345 - val_f1: 0.7563 - val_auc: 0.9009\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3445 - accuracy: 0.8583 - f1: 0.7881 - auc: 0.9251 - val_loss: 0.4096 - val_accuracy: 0.8545 - val_f1: 0.7854 - val_auc: 0.8993\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3133 - accuracy: 0.8726 - f1: 0.8102 - auc: 0.9384 - val_loss: 0.3742 - val_accuracy: 0.8327 - val_f1: 0.7610 - val_auc: 0.9136\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2886 - accuracy: 0.8996 - f1: 0.8129 - auc: 0.9499 - val_loss: 0.3741 - val_accuracy: 0.8600 - val_f1: 0.8096 - val_auc: 0.9148\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2769 - accuracy: 0.8951 - f1: 0.8476 - auc: 0.9506 - val_loss: 0.3711 - val_accuracy: 0.8545 - val_f1: 0.7910 - val_auc: 0.9154\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2323 - accuracy: 0.9175 - f1: 0.8563 - auc: 0.9667 - val_loss: 0.3615 - val_accuracy: 0.8636 - val_f1: 0.8129 - val_auc: 0.9238\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2055 - accuracy: 0.9220 - f1: 0.8726 - auc: 0.9746 - val_loss: 0.3715 - val_accuracy: 0.8655 - val_f1: 0.8274 - val_auc: 0.9238\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1944 - accuracy: 0.9229 - f1: 0.8828 - auc: 0.9755 - val_loss: 0.3763 - val_accuracy: 0.8564 - val_f1: 0.8229 - val_auc: 0.9248\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1646 - accuracy: 0.9408 - f1: 0.8956 - auc: 0.9830 - val_loss: 0.4227 - val_accuracy: 0.8309 - val_f1: 0.8102 - val_auc: 0.9126\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1746 - accuracy: 0.9300 - f1: 0.8994 - auc: 0.9800 - val_loss: 0.3767 - val_accuracy: 0.8545 - val_f1: 0.8305 - val_auc: 0.9259\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1319 - accuracy: 0.9578 - f1: 0.9184 - auc: 0.9886 - val_loss: 0.3913 - val_accuracy: 0.8600 - val_f1: 0.8387 - val_auc: 0.9248\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1075 - accuracy: 0.9677 - f1: 0.9327 - auc: 0.9916 - val_loss: 0.4139 - val_accuracy: 0.8491 - val_f1: 0.8274 - val_auc: 0.9214\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0910 - accuracy: 0.9740 - f1: 0.9404 - auc: 0.9933 - val_loss: 0.4549 - val_accuracy: 0.8418 - val_f1: 0.8226 - val_auc: 0.9158\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1040 - accuracy: 0.9686 - f1: 0.9332 - auc: 0.9919 - val_loss: 0.4527 - val_accuracy: 0.8436 - val_f1: 0.8342 - val_auc: 0.9192\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0999 - accuracy: 0.9659 - f1: 0.9436 - auc: 0.9922 - val_loss: 0.4670 - val_accuracy: 0.8473 - val_f1: 0.8288 - val_auc: 0.9145\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0758 - accuracy: 0.9794 - f1: 0.9547 - auc: 0.9949 - val_loss: 0.4805 - val_accuracy: 0.8400 - val_f1: 0.8305 - val_auc: 0.9157\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 84.00%\n",
            "F1: 83.59%\n",
            "AUC: 91.57%\n",
            "Loss: 0.48%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 94ms/step - loss: 0.6218 - accuracy: 0.6762 - f1: 0.5576 - auc: 0.7181 - val_loss: 0.5671 - val_accuracy: 0.7036 - val_f1: 0.6250 - val_auc: 0.8132\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5635 - accuracy: 0.7022 - f1: 0.6234 - auc: 0.7769 - val_loss: 0.5504 - val_accuracy: 0.7564 - val_f1: 0.6278 - val_auc: 0.8382\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5122 - accuracy: 0.8081 - f1: 0.6604 - auc: 0.8563 - val_loss: 0.4776 - val_accuracy: 0.8236 - val_f1: 0.6743 - val_auc: 0.8737\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4187 - accuracy: 0.8386 - f1: 0.7155 - auc: 0.8968 - val_loss: 0.4150 - val_accuracy: 0.8436 - val_f1: 0.7377 - val_auc: 0.8902\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3796 - accuracy: 0.8377 - f1: 0.7648 - auc: 0.9101 - val_loss: 0.3936 - val_accuracy: 0.8455 - val_f1: 0.7771 - val_auc: 0.9018\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3362 - accuracy: 0.8610 - f1: 0.7870 - auc: 0.9302 - val_loss: 0.3705 - val_accuracy: 0.8564 - val_f1: 0.7756 - val_auc: 0.9131\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3362 - accuracy: 0.8717 - f1: 0.8092 - auc: 0.9289 - val_loss: 0.3937 - val_accuracy: 0.8509 - val_f1: 0.7899 - val_auc: 0.9055\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.2961 - accuracy: 0.8753 - f1: 0.8134 - auc: 0.9478 - val_loss: 0.4121 - val_accuracy: 0.8400 - val_f1: 0.7920 - val_auc: 0.9029\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3016 - accuracy: 0.8798 - f1: 0.8231 - auc: 0.9441 - val_loss: 0.3763 - val_accuracy: 0.8527 - val_f1: 0.8010 - val_auc: 0.9135\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2598 - accuracy: 0.9004 - f1: 0.8381 - auc: 0.9593 - val_loss: 0.3829 - val_accuracy: 0.8527 - val_f1: 0.8045 - val_auc: 0.9133\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2523 - accuracy: 0.8951 - f1: 0.8477 - auc: 0.9609 - val_loss: 0.3528 - val_accuracy: 0.8618 - val_f1: 0.8191 - val_auc: 0.9253\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2148 - accuracy: 0.9220 - f1: 0.8660 - auc: 0.9725 - val_loss: 0.3565 - val_accuracy: 0.8545 - val_f1: 0.8165 - val_auc: 0.9260\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1831 - accuracy: 0.9354 - f1: 0.8812 - auc: 0.9794 - val_loss: 0.3938 - val_accuracy: 0.8564 - val_f1: 0.8203 - val_auc: 0.9177\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1751 - accuracy: 0.9363 - f1: 0.8932 - auc: 0.9814 - val_loss: 0.3714 - val_accuracy: 0.8564 - val_f1: 0.8187 - val_auc: 0.9241\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1460 - accuracy: 0.9471 - f1: 0.8899 - auc: 0.9870 - val_loss: 0.4148 - val_accuracy: 0.8491 - val_f1: 0.8271 - val_auc: 0.9194\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1693 - accuracy: 0.9372 - f1: 0.8971 - auc: 0.9819 - val_loss: 0.3963 - val_accuracy: 0.8491 - val_f1: 0.8264 - val_auc: 0.9214\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1413 - accuracy: 0.9480 - f1: 0.9036 - auc: 0.9888 - val_loss: 0.4822 - val_accuracy: 0.8036 - val_f1: 0.7800 - val_auc: 0.8885\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1597 - accuracy: 0.9408 - f1: 0.8982 - auc: 0.9842 - val_loss: 0.3996 - val_accuracy: 0.8600 - val_f1: 0.8369 - val_auc: 0.9255\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1444 - accuracy: 0.9498 - f1: 0.9120 - auc: 0.9865 - val_loss: 0.3998 - val_accuracy: 0.8564 - val_f1: 0.8350 - val_auc: 0.9250\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0981 - accuracy: 0.9686 - f1: 0.9345 - auc: 0.9945 - val_loss: 0.4541 - val_accuracy: 0.8327 - val_f1: 0.8164 - val_auc: 0.9124\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 83.27%\n",
            "F1: 81.74%\n",
            "AUC: 91.24%\n",
            "Loss: 0.45%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 96ms/step - loss: 0.6331 - accuracy: 0.6762 - f1: 0.5907 - auc: 0.6941 - val_loss: 0.5736 - val_accuracy: 0.7036 - val_f1: 0.5933 - val_auc: 0.8081\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5611 - accuracy: 0.6942 - f1: 0.6189 - auc: 0.7852 - val_loss: 0.5414 - val_accuracy: 0.7764 - val_f1: 0.6457 - val_auc: 0.8439\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5090 - accuracy: 0.7964 - f1: 0.6515 - auc: 0.8524 - val_loss: 0.4861 - val_accuracy: 0.7945 - val_f1: 0.6619 - val_auc: 0.8624\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4508 - accuracy: 0.8197 - f1: 0.6875 - auc: 0.8741 - val_loss: 0.4230 - val_accuracy: 0.8164 - val_f1: 0.7174 - val_auc: 0.8886\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3749 - accuracy: 0.8556 - f1: 0.7486 - auc: 0.9137 - val_loss: 0.4032 - val_accuracy: 0.8382 - val_f1: 0.7544 - val_auc: 0.8967\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3551 - accuracy: 0.8538 - f1: 0.7789 - auc: 0.9222 - val_loss: 0.3792 - val_accuracy: 0.8473 - val_f1: 0.7792 - val_auc: 0.9084\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3171 - accuracy: 0.8717 - f1: 0.7987 - auc: 0.9378 - val_loss: 0.3642 - val_accuracy: 0.8382 - val_f1: 0.7748 - val_auc: 0.9167\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2926 - accuracy: 0.8852 - f1: 0.8149 - auc: 0.9495 - val_loss: 0.3711 - val_accuracy: 0.8582 - val_f1: 0.8032 - val_auc: 0.9160\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2744 - accuracy: 0.8924 - f1: 0.8401 - auc: 0.9525 - val_loss: 0.3747 - val_accuracy: 0.8582 - val_f1: 0.7891 - val_auc: 0.9129\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2369 - accuracy: 0.9130 - f1: 0.8519 - auc: 0.9663 - val_loss: 0.3860 - val_accuracy: 0.8600 - val_f1: 0.8241 - val_auc: 0.9187\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2293 - accuracy: 0.9157 - f1: 0.8618 - auc: 0.9667 - val_loss: 0.3825 - val_accuracy: 0.8327 - val_f1: 0.7983 - val_auc: 0.9172\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1873 - accuracy: 0.9336 - f1: 0.8766 - auc: 0.9790 - val_loss: 0.3865 - val_accuracy: 0.8582 - val_f1: 0.8242 - val_auc: 0.9199\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.2211 - accuracy: 0.9175 - f1: 0.8783 - auc: 0.9687 - val_loss: 0.3712 - val_accuracy: 0.8673 - val_f1: 0.8318 - val_auc: 0.9275\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.1677 - accuracy: 0.9372 - f1: 0.8921 - auc: 0.9837 - val_loss: 0.3813 - val_accuracy: 0.8491 - val_f1: 0.8088 - val_auc: 0.9190\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 0.1360 - accuracy: 0.9552 - f1: 0.9110 - auc: 0.9880 - val_loss: 0.4045 - val_accuracy: 0.8655 - val_f1: 0.8391 - val_auc: 0.9246\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 0.1370 - accuracy: 0.9507 - f1: 0.9145 - auc: 0.9877 - val_loss: 0.4249 - val_accuracy: 0.8618 - val_f1: 0.8444 - val_auc: 0.9217\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.1421 - accuracy: 0.9552 - f1: 0.9230 - auc: 0.9857 - val_loss: 0.4023 - val_accuracy: 0.8509 - val_f1: 0.8225 - val_auc: 0.9207\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.1234 - accuracy: 0.9578 - f1: 0.9259 - auc: 0.9908 - val_loss: 0.4570 - val_accuracy: 0.8309 - val_f1: 0.8139 - val_auc: 0.9088\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1138 - accuracy: 0.9623 - f1: 0.9295 - auc: 0.9911 - val_loss: 0.5038 - val_accuracy: 0.8164 - val_f1: 0.7996 - val_auc: 0.8932\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1130 - accuracy: 0.9605 - f1: 0.9271 - auc: 0.9926 - val_loss: 0.4181 - val_accuracy: 0.8655 - val_f1: 0.8401 - val_auc: 0.9246\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 86.55%\n",
            "F1: 84.27%\n",
            "AUC: 92.46%\n",
            "Loss: 0.42%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 96ms/step - loss: 0.6693 - accuracy: 0.5677 - f1: 0.5623 - auc: 0.6309 - val_loss: 0.5836 - val_accuracy: 0.7036 - val_f1: 0.6141 - val_auc: 0.7863\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5822 - accuracy: 0.6762 - f1: 0.5996 - auc: 0.7650 - val_loss: 0.5595 - val_accuracy: 0.7036 - val_f1: 0.6282 - val_auc: 0.8222\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.5468 - accuracy: 0.6780 - f1: 0.6358 - auc: 0.8128 - val_loss: 0.5292 - val_accuracy: 0.8109 - val_f1: 0.6373 - val_auc: 0.8545\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5089 - accuracy: 0.8135 - f1: 0.6404 - auc: 0.8639 - val_loss: 0.4750 - val_accuracy: 0.8273 - val_f1: 0.6791 - val_auc: 0.8684\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4103 - accuracy: 0.8466 - f1: 0.7197 - auc: 0.9008 - val_loss: 0.4038 - val_accuracy: 0.8236 - val_f1: 0.7449 - val_auc: 0.8968\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3552 - accuracy: 0.8511 - f1: 0.7805 - auc: 0.9208 - val_loss: 0.3869 - val_accuracy: 0.8218 - val_f1: 0.7635 - val_auc: 0.9068\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3425 - accuracy: 0.8556 - f1: 0.7934 - auc: 0.9272 - val_loss: 0.4095 - val_accuracy: 0.8145 - val_f1: 0.7418 - val_auc: 0.8966\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3046 - accuracy: 0.8843 - f1: 0.8073 - auc: 0.9439 - val_loss: 0.3849 - val_accuracy: 0.8273 - val_f1: 0.7612 - val_auc: 0.9093\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2718 - accuracy: 0.8978 - f1: 0.8256 - auc: 0.9554 - val_loss: 0.3580 - val_accuracy: 0.8545 - val_f1: 0.8013 - val_auc: 0.9210\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.2679 - accuracy: 0.8987 - f1: 0.8405 - auc: 0.9553 - val_loss: 0.3670 - val_accuracy: 0.8564 - val_f1: 0.8108 - val_auc: 0.9197\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2316 - accuracy: 0.9157 - f1: 0.8549 - auc: 0.9678 - val_loss: 0.3640 - val_accuracy: 0.8527 - val_f1: 0.8212 - val_auc: 0.9240\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2152 - accuracy: 0.9247 - f1: 0.8689 - auc: 0.9708 - val_loss: 0.3685 - val_accuracy: 0.8564 - val_f1: 0.8160 - val_auc: 0.9227\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.2126 - accuracy: 0.9247 - f1: 0.8666 - auc: 0.9713 - val_loss: 0.3896 - val_accuracy: 0.8327 - val_f1: 0.8003 - val_auc: 0.9145\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1829 - accuracy: 0.9435 - f1: 0.8851 - auc: 0.9802 - val_loss: 0.3704 - val_accuracy: 0.8564 - val_f1: 0.8262 - val_auc: 0.9239\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1638 - accuracy: 0.9417 - f1: 0.8991 - auc: 0.9829 - val_loss: 0.3872 - val_accuracy: 0.8582 - val_f1: 0.8320 - val_auc: 0.9226\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1421 - accuracy: 0.9525 - f1: 0.9063 - auc: 0.9861 - val_loss: 0.6060 - val_accuracy: 0.7582 - val_f1: 0.7428 - val_auc: 0.8490\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1922 - accuracy: 0.9283 - f1: 0.8964 - auc: 0.9779 - val_loss: 0.3833 - val_accuracy: 0.8618 - val_f1: 0.8350 - val_auc: 0.9251\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1238 - accuracy: 0.9614 - f1: 0.9213 - auc: 0.9904 - val_loss: 0.3874 - val_accuracy: 0.8600 - val_f1: 0.8339 - val_auc: 0.9238\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1029 - accuracy: 0.9704 - f1: 0.9362 - auc: 0.9923 - val_loss: 0.4322 - val_accuracy: 0.8400 - val_f1: 0.8218 - val_auc: 0.9179\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1008 - accuracy: 0.9686 - f1: 0.9393 - auc: 0.9930 - val_loss: 0.4581 - val_accuracy: 0.8345 - val_f1: 0.8202 - val_auc: 0.9133\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 83.45%\n",
            "F1: 82.16%\n",
            "AUC: 91.33%\n",
            "Loss: 0.46%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 96ms/step - loss: 0.6285 - accuracy: 0.6762 - f1: 0.5712 - auc: 0.7017 - val_loss: 0.5717 - val_accuracy: 0.7036 - val_f1: 0.6174 - val_auc: 0.8142\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5701 - accuracy: 0.6780 - f1: 0.6214 - auc: 0.7718 - val_loss: 0.5586 - val_accuracy: 0.7782 - val_f1: 0.6178 - val_auc: 0.8423\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.5209 - accuracy: 0.7928 - f1: 0.6479 - auc: 0.8533 - val_loss: 0.4840 - val_accuracy: 0.8255 - val_f1: 0.6750 - val_auc: 0.8684\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.4306 - accuracy: 0.8341 - f1: 0.7142 - auc: 0.8918 - val_loss: 0.4106 - val_accuracy: 0.8182 - val_f1: 0.7274 - val_auc: 0.8960\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3695 - accuracy: 0.8538 - f1: 0.7716 - auc: 0.9141 - val_loss: 0.3924 - val_accuracy: 0.8200 - val_f1: 0.7680 - val_auc: 0.9037\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.3419 - accuracy: 0.8628 - f1: 0.7850 - auc: 0.9278 - val_loss: 0.3794 - val_accuracy: 0.8618 - val_f1: 0.7771 - val_auc: 0.9097\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2983 - accuracy: 0.8834 - f1: 0.8002 - auc: 0.9461 - val_loss: 0.3723 - val_accuracy: 0.8364 - val_f1: 0.7626 - val_auc: 0.9148\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2810 - accuracy: 0.8870 - f1: 0.8235 - auc: 0.9525 - val_loss: 0.3511 - val_accuracy: 0.8564 - val_f1: 0.7984 - val_auc: 0.9239\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.2396 - accuracy: 0.8987 - f1: 0.8494 - auc: 0.9651 - val_loss: 0.3766 - val_accuracy: 0.8564 - val_f1: 0.8134 - val_auc: 0.9182\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2207 - accuracy: 0.9139 - f1: 0.8596 - auc: 0.9708 - val_loss: 0.3952 - val_accuracy: 0.8273 - val_f1: 0.7909 - val_auc: 0.9119\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2142 - accuracy: 0.9103 - f1: 0.8681 - auc: 0.9727 - val_loss: 0.3727 - val_accuracy: 0.8418 - val_f1: 0.8162 - val_auc: 0.9229\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1697 - accuracy: 0.9354 - f1: 0.8973 - auc: 0.9819 - val_loss: 0.3803 - val_accuracy: 0.8545 - val_f1: 0.8215 - val_auc: 0.9227\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1477 - accuracy: 0.9498 - f1: 0.9066 - auc: 0.9861 - val_loss: 0.4089 - val_accuracy: 0.8618 - val_f1: 0.8321 - val_auc: 0.9216\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1581 - accuracy: 0.9444 - f1: 0.9047 - auc: 0.9834 - val_loss: 0.4262 - val_accuracy: 0.8364 - val_f1: 0.8070 - val_auc: 0.9120\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1742 - accuracy: 0.9345 - f1: 0.8995 - auc: 0.9805 - val_loss: 0.4206 - val_accuracy: 0.8636 - val_f1: 0.8435 - val_auc: 0.9188\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1164 - accuracy: 0.9614 - f1: 0.9134 - auc: 0.9920 - val_loss: 0.4653 - val_accuracy: 0.8164 - val_f1: 0.7960 - val_auc: 0.8999\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1356 - accuracy: 0.9480 - f1: 0.9142 - auc: 0.9877 - val_loss: 0.6195 - val_accuracy: 0.8055 - val_f1: 0.7990 - val_auc: 0.8890\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1804 - accuracy: 0.9265 - f1: 0.8992 - auc: 0.9804 - val_loss: 0.4048 - val_accuracy: 0.8455 - val_f1: 0.8225 - val_auc: 0.9176\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0976 - accuracy: 0.9686 - f1: 0.9292 - auc: 0.9948 - val_loss: 0.4101 - val_accuracy: 0.8473 - val_f1: 0.8283 - val_auc: 0.9197\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.0736 - accuracy: 0.9830 - f1: 0.9474 - auc: 0.9961 - val_loss: 0.4429 - val_accuracy: 0.8600 - val_f1: 0.8327 - val_auc: 0.9196\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 86.00%\n",
            "F1: 83.72%\n",
            "AUC: 91.96%\n",
            "Loss: 0.44%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KFOLD CROSS-VAL BASED ON: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
        "\n",
        "\n",
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser = tf.reshape(X_train, [-1, 1, 1324])\n",
        "\n",
        "Y1 = to_categorical(y_train, 2)\n",
        "Y1_reshaped = tf.reshape(Y1, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser.shape, Y1_reshaped.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser = tf.reshape(X_test, [-1, 1, 1324])\n",
        "\n",
        "Y2 = to_categorical(y_test, 2)\n",
        "Y2_reshaped = tf.reshape(Y2, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser.shape, Y2_reshaped.shape)\n",
        "\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(LSTM(100, input_shape=(1, 1324), return_sequences=True))\n",
        "  model.add(Dense(1324,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128,activation='sigmoid'))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR85E_BlWts4",
        "outputId": "dc49fbdf-6a3a-497f-d162-c3845b2f50d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.4844066798686981 - Accuracy: 85.09091138839722 - F1: 84.01060700416565 - AUC: 91.86297059059143%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.5347909331321716 - Accuracy: 85.63636541366577 - F1: 85.68759560585022 - AUC: 91.61157608032227%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.5550999045372009 - Accuracy: 79.81818318367004 - F1: 78.2090425491333 - AUC: 87.48595118522644%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.40450307726860046 - Accuracy: 85.27272939682007 - F1: 82.2762131690979 - AUC: 91.96512699127197%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.41972315311431885 - Accuracy: 86.00000143051147 - F1: 84.5345675945282 - AUC: 92.4781858921051%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.48046985268592834 - Accuracy: 83.99999737739563 - F1: 83.59013795852661 - AUC: 91.56957864761353%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.4541427493095398 - Accuracy: 83.27272534370422 - F1: 81.73644542694092 - AUC: 91.24346375465393%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.4181312620639801 - Accuracy: 86.54545545578003 - F1: 84.26713347434998 - AUC: 92.46149063110352%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.45813027024269104 - Accuracy: 83.45454335212708 - F1: 82.16482996940613 - AUC: 91.33338928222656%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.44291457533836365 - Accuracy: 86.00000143051147 - F1: 83.71851444244385 - AUC: 91.95801615715027%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.46523124575614927\n",
            "> Accuracy: 84.5090913772583 (+- 1.8891605920387164)\n",
            "> F1: 83.01950871944427 (+- 1.970709550540168)\n",
            "> AUC: 91.3969749212265 (+- 1.3622220100353397)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVxSFf5TySpR"
      },
      "source": [
        "## **4. Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llzyd9P08tz2"
      },
      "outputs": [],
      "source": [
        "#lyfinal_df = labeling(lyrics_embeddings, lyfinal_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxg1ExJNJg13"
      },
      "outputs": [],
      "source": [
        "#final_df = lyfinal_df.sort_values('probability_sexist', ascending=False)\n",
        "#final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXa4M0RdLLI6"
      },
      "outputs": [],
      "source": [
        "#final_df.to_csv('final_labeled_df.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model2_FastText.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}