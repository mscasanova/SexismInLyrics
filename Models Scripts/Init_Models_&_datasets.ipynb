{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Init.Models_&_datasets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Initial Models with existing Dataset**"
      ],
      "metadata": {
        "id": "UBz1qhBMiTCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal is to choose which model works better "
      ],
      "metadata": {
        "id": "8JTFKPfAiaMX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv4hYpFY4Qg3"
      },
      "source": [
        "## **0.File Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.1 Requirements**\n"
      ],
      "metadata": {
        "id": "LGbyGa13YSpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ],
      "metadata": {
        "id": "lUM5UW904PIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2285626c-63a6-48bb-8307-f0b6ff0e43a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laserembeddings\n",
            "  Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.21.6)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.11.0+cu113)\n",
            "Collecting transliterate==1.10.2\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=039e704a3867537a0e08c6db842951ec01943ff298887b28323a84fdef2ebc10\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: mock, transliterate, subword-nmt, sacremoses, laserembeddings\n",
            "Successfully installed laserembeddings-1.1.2 mock-4.0.3 sacremoses-0.0.35 subword-nmt-0.3.8 transliterate-1.10.2\n",
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.2 Imports**"
      ],
      "metadata": {
        "id": "CFmisGpVYXwR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svuw4Lw64Qg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebb1e5b-5ef9-4995-abe6-ad839edd733a"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "import regex as re \n",
        "import string\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import re\n",
        "from laserembeddings import Laser\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Reshaping datasets to tensors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#for Colab file dealing\n",
        "import glob\n",
        "#You can mount your Google Drive files by running the following code snippet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # Now all files in: /content/gdrive/My Drive/location_of_the_file\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **0.3 Functions**"
      ],
      "metadata": {
        "id": "MoYE0eWKYuBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.1 For Text Processing**"
      ],
      "metadata": {
        "id": "OzoUuFtMpUG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_preprocessing(text_data):\n",
        "    # you could use this function for preprocess tweets\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "            # hashtags -> words, URLs -> URL and mentions -> USER\n",
        "            text = re.sub('#', '', text)\n",
        "            text = re.sub('((www\\.[\\\\s]+)|(https?://[^\\\\s]+))', 'URL', text)\n",
        "            text = re.sub('@[A-Za-z0-9_-]+', 'USER', text)\n",
        "            text = re.sub('RT @[A-Za-z0-9_-]+:', 'USER', text)\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('\\!', ' ', text) # !\n",
        "            text = re.sub('\\?', ' ', text) # ?\n",
        "            text = re.sub('\\W', ' ', text) # symbols\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('[\\s]+', ' ', text) # spaces\n",
        "            text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text) # remove spaces between numbers\n",
        "            preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ],
      "metadata": {
        "id": "uMLmGy68Xbcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.2 For Model Evaluation**"
      ],
      "metadata": {
        "id": "LT4Xhz51pYH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 evaluation\n",
        "def f1(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"
      ],
      "metadata": {
        "id": "2-ggg2gXQ1tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asEl-avP4QhD"
      },
      "source": [
        "## **1. Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Dataset**"
      ],
      "metadata": {
        "id": "rzT0ykt6XnpX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iawCSHJ14QhE",
        "outputId": "051112e6-6903-40f4-85fd-39d755c3af3f"
      },
      "source": [
        "training = '/content/gdrive/My Drive/training_dataset.csv'\n",
        "training = pd.read_csv(training)\n",
        "training_df = training.copy()\n",
        "training_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               text  \\\n",
              "0               0  Red One Sugababes Girls bring the fun of life ...   \n",
              "1               1  I guess it was yourself you were involved with...   \n",
              "2               2  Bill collectors at my door What can you do for...   \n",
              "3               3  I ain't cooking all day (I ain't your mama!) I...   \n",
              "4               4  All hands on deck All in front all in the back...   \n",
              "...           ...                                                ...   \n",
              "21772        3595  \"Experimentos que surgen en la ociosidad de la...   \n",
              "21773        3596  Mucho feminismo pero la Pedroche en tetas. Por...   \n",
              "21774        3597  hermana estaba contando a madrastra que un gom...   \n",
              "21775        3598  @AdrianFtm24 @s0ymia Mucho feminismo, pero mir...   \n",
              "21776        3599  @sotosinmas A muchísimos hombres no les gustan...   \n",
              "\n",
              "            Class language dataset       Category      highlight  \n",
              "0          sexism       en  lyrics  Not specified  Not specified  \n",
              "1          sexism       en  lyrics  Not specified  Not specified  \n",
              "2          sexism       en  lyrics  Not specified  Not specified  \n",
              "3          sexism       en  lyrics  Not specified  Not specified  \n",
              "4          sexism       en  lyrics  Not specified  Not specified  \n",
              "...           ...      ...     ...            ...            ...  \n",
              "21772  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "21773      sexism       es   MeTwo  Not specified  Not specified  \n",
              "21774  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "21775      sexism       es   MeTwo  Not specified  Not specified  \n",
              "21776  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "\n",
              "[21777 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18b0917f-5995-4924-886d-21af1cd7a722\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>Class</th>\n",
              "      <th>language</th>\n",
              "      <th>dataset</th>\n",
              "      <th>Category</th>\n",
              "      <th>highlight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Red One Sugababes Girls bring the fun of life ...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I guess it was yourself you were involved with...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Bill collectors at my door What can you do for...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I ain't cooking all day (I ain't your mama!) I...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>All hands on deck All in front all in the back...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21772</th>\n",
              "      <td>3595</td>\n",
              "      <td>\"Experimentos que surgen en la ociosidad de la...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21773</th>\n",
              "      <td>3596</td>\n",
              "      <td>Mucho feminismo pero la Pedroche en tetas. Por...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21774</th>\n",
              "      <td>3597</td>\n",
              "      <td>hermana estaba contando a madrastra que un gom...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21775</th>\n",
              "      <td>3598</td>\n",
              "      <td>@AdrianFtm24 @s0ymia Mucho feminismo, pero mir...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21776</th>\n",
              "      <td>3599</td>\n",
              "      <td>@sotosinmas A muchísimos hombres no les gustan...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21777 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b0917f-5995-4924-886d-21af1cd7a722')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18b0917f-5995-4924-886d-21af1cd7a722 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18b0917f-5995-4924-886d-21af1cd7a722');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Cleaning and Embedding**"
      ],
      "metadata": {
        "id": "iyX0OumNXuoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laser = Laser() # importing class for using embeddings extraction"
      ],
      "metadata": {
        "id": "mE19RZFeXfGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 Dataset: Exist, Exist test & MeTwo for training and Lyrics for testing** "
      ],
      "metadata": {
        "id": "cJofAhm3Y4WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "train_data = training_df[(training_df['dataset']=='exist')|(training_df['dataset']=='exist_test')|(training_df['dataset']=='MeTwo')]\n",
        "texts_tobe_processed_train = train_data['text']\n",
        "\n",
        "\n",
        "texts_processed_train = tweet_preprocessing(texts_tobe_processed_train)\n",
        "\n",
        "\n",
        "train_embeddings = laser.embed_sentences(texts_processed_train, lang = 'en') \n",
        "\n",
        "train_data[['Class']] = train_data[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "train_labels = train_data['Class']\n",
        "train_labels = train_labels.astype('int64')\n",
        "\n",
        "\n",
        "# test data\n",
        "\n",
        "#since I do not really know what '-1' means I will drop the 145 rows with value -1 for the testing part\n",
        "test_data = training_df[(training_df['dataset']=='lyrics')&(training_df['Class']!='-1')]\n",
        "\n",
        "texts_tobe_processed_test = test_data['text']\n",
        "\n",
        "texts_processed_test = tweet_preprocessing(texts_tobe_processed_test)\n",
        "\n",
        "    \n",
        "test_embeddings = laser.embed_sentences(texts_processed_test, lang = 'en')\n",
        "\n",
        "test_data[['Class']] = test_data[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "test_labels = test_data['Class']\n",
        "test_labels = test_labels.astype('int64')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUnKHJfnXVEf",
        "outputId": "a727e282-ec21-4ec4-cd77-210ad80ae3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Dataset: Exist for training & Exist_test for testing**\n"
      ],
      "metadata": {
        "id": "2z6klJ9NZHjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "train_data2 = training_df[training_df['dataset']=='exist']\n",
        "texts_tobe_processed_train2 = train_data2['text']\n",
        "\n",
        "\n",
        "texts_processed_train2 = tweet_preprocessing(texts_tobe_processed_train2)\n",
        "\n",
        "\n",
        "train_embeddings2 = laser.embed_sentences(texts_processed_train2, lang = 'en') \n",
        "\n",
        "train_data2[['Class']] = train_data2[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "train_labels2 = train_data2['Class']\n",
        "train_labels2 = train_labels2.astype('int64')\n",
        "\n",
        "\n",
        "# test data\n",
        "\n",
        "test_data2 = training_df[training_df['dataset']=='exist_test']\n",
        "\n",
        "texts_tobe_processed_test2 = test_data2['text']\n",
        "\n",
        "texts_processed_test2 = tweet_preprocessing(texts_tobe_processed_test2)\n",
        "\n",
        "    \n",
        "test_embeddings2 = laser.embed_sentences(texts_processed_test2, lang = 'en')\n",
        "\n",
        "test_data2[['Class']] = test_data2[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "test_labels2 = test_data2['Class']\n",
        "test_labels2 = test_labels2.astype('int64')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fmRRhhIXTYm",
        "outputId": "b9cdd878-e192-4121-e277-7973371cbbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Modeling**"
      ],
      "metadata": {
        "id": "_CYcMwRV90Rc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG7L_4Tn4QhF"
      },
      "source": [
        "### **2.1 SVM + Dataset: Exist, Exist test & MeTwo for training and Lyrics for testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KvQ3TP84QhG"
      },
      "source": [
        "### Train with tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os3ZFKOv4QhH"
      },
      "source": [
        "# train the model (SVM for example)\n",
        "model = svm.SVC(kernel='linear', degree=3, gamma='auto', tol=0.001)\n",
        "model.fit(train_embeddings, train_labels)\n",
        "prediction = model.predict(test_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cy_2nkp4QhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefe8562-cb94-432e-ba3a-fc90b4ed33f7"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "# measure model performance\n",
        "accuracy = cross_val_score(model, train_embeddings, train_labels, scoring='accuracy', cv=10).mean()\n",
        "f1_ = cross_val_score(model, train_embeddings, train_labels, cv=10, scoring= 'f1').mean()\n",
        "auc = cross_val_score(model, train_embeddings, train_labels, cv=10, scoring= 'roc_auc').mean()\n",
        "\n",
        "print('ACC:', accuracy)\n",
        "print('F1:', f1_)\n",
        "print('AUC:', auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC: 0.6837396380683856\n",
            "F1: 0.6533043244083196\n",
            "AUC: 0.7437647023707117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 SVM + Dataset: Exist for training & Exist_test for testing**\n",
        "now we use as train the training exist dataset and as test the testing exist dataset, this way we can see if the model is the one that does not work or the classifier is not adapting to the lyrics dataset. "
      ],
      "metadata": {
        "id": "tsp8TIb__UJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model (SVM)\n",
        "model2 = svm.SVC(kernel='linear', degree=3, gamma='auto', tol=0.001)\n",
        "model2.fit(train_embeddings2, train_labels2)\n",
        "prediction2 = model2.predict(test_embeddings2)"
      ],
      "metadata": {
        "id": "p5lqAljMBUqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# measure model performance\n",
        "accuracy = cross_val_score(model2, train_embeddings2, train_labels2, cv=10, scoring= 'accuracy').mean()\n",
        "f1_ = cross_val_score(model2, train_embeddings2, train_labels2, cv=10, scoring= 'f1').mean()\n",
        "auc = cross_val_score(model2, train_embeddings2, train_labels2, cv=10, scoring= 'roc_auc').mean()\n",
        "\n",
        "print('ACC:', accuracy)\n",
        "print('F1:', f1_)\n",
        "print('AUC:', auc)"
      ],
      "metadata": {
        "id": "clNjNHanBWr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bc5780-053d-4f30-f0f3-b36e717c18bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC: 0.7084632049758894\n",
            "F1: 0.6997301330869063\n",
            "AUC: 0.7696235346104098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 LSTM + Datasets: Exist, Exist test & MeTwo**"
      ],
      "metadata": {
        "id": "J0DKBiIt2R9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser = tf.reshape(train_embeddings, [-1, 1, 1024])\n",
        "\n",
        "Y1 = to_categorical(train_labels, 2)\n",
        "Y1_reshaped = tf.reshape(Y1, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser.shape, Y1_reshaped.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser = tf.reshape(test_embeddings, [-1, 1, 1024])\n",
        "\n",
        "Y2 = to_categorical(test_labels, 2)\n",
        "Y2_reshaped = tf.reshape(Y2, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser.shape, Y2_reshaped.shape)\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_neur = tf.keras.Sequential()\n",
        "  model_neur.add(LSTM(100, input_shape=(1, 1024), return_sequences=True))\n",
        "  model_neur.add(Dense(1024,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model_neur.add(Dropout(0.5))\n",
        "  model_neur.add(Dense(128,activation='sigmoid'))\n",
        "  model_neur.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model_neur.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_neur.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_neur.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr4JVjQ12U8Z",
        "outputId": "ba9c6431-2712-4630-813b-5804d35e1c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (14678, 1, 1024) (14678, 1, 2)\n",
            "Test data shapes: (387, 1, 1024) (387, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 27ms/step - loss: 0.6629 - accuracy: 0.5762 - f1: 0.5268 - auc: 0.6236 - val_loss: 0.6446 - val_accuracy: 0.6176 - val_f1: 0.5547 - val_auc: 0.6911\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5890 - accuracy: 0.6861 - f1: 0.5960 - auc: 0.7520 - val_loss: 0.7421 - val_accuracy: 0.5866 - val_f1: 0.5521 - val_auc: 0.6087\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5689 - accuracy: 0.7008 - f1: 0.6120 - auc: 0.7740 - val_loss: 0.7192 - val_accuracy: 0.5814 - val_f1: 0.5589 - val_auc: 0.6249\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5598 - accuracy: 0.7100 - f1: 0.6199 - auc: 0.7834 - val_loss: 0.6768 - val_accuracy: 0.5711 - val_f1: 0.5643 - val_auc: 0.6565\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5520 - accuracy: 0.7173 - f1: 0.6267 - auc: 0.7901 - val_loss: 0.9090 - val_accuracy: 0.5297 - val_f1: 0.5431 - val_auc: 0.5787\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5450 - accuracy: 0.7209 - f1: 0.6323 - auc: 0.7966 - val_loss: 0.7127 - val_accuracy: 0.6098 - val_f1: 0.5915 - val_auc: 0.6741\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5331 - accuracy: 0.7251 - f1: 0.6407 - auc: 0.8064 - val_loss: 0.8273 - val_accuracy: 0.5736 - val_f1: 0.5680 - val_auc: 0.6173\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5261 - accuracy: 0.7342 - f1: 0.6469 - auc: 0.8132 - val_loss: 0.6544 - val_accuracy: 0.6512 - val_f1: 0.5895 - val_auc: 0.7045\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5214 - accuracy: 0.7294 - f1: 0.6486 - auc: 0.8152 - val_loss: 0.6270 - val_accuracy: 0.6951 - val_f1: 0.6070 - val_auc: 0.7408\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5151 - accuracy: 0.7377 - f1: 0.6550 - auc: 0.8213 - val_loss: 0.7442 - val_accuracy: 0.6072 - val_f1: 0.5998 - val_auc: 0.6780\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5060 - accuracy: 0.7430 - f1: 0.6611 - auc: 0.8283 - val_loss: 0.7128 - val_accuracy: 0.6408 - val_f1: 0.6126 - val_auc: 0.7021\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4954 - accuracy: 0.7489 - f1: 0.6687 - auc: 0.8366 - val_loss: 0.7264 - val_accuracy: 0.6202 - val_f1: 0.5931 - val_auc: 0.6721\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4941 - accuracy: 0.7489 - f1: 0.6701 - auc: 0.8376 - val_loss: 0.7396 - val_accuracy: 0.6486 - val_f1: 0.6136 - val_auc: 0.6973\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4838 - accuracy: 0.7562 - f1: 0.6774 - auc: 0.8450 - val_loss: 0.7765 - val_accuracy: 0.6512 - val_f1: 0.6254 - val_auc: 0.7032\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4864 - accuracy: 0.7567 - f1: 0.6773 - auc: 0.8436 - val_loss: 0.8029 - val_accuracy: 0.6434 - val_f1: 0.6251 - val_auc: 0.6987\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4741 - accuracy: 0.7624 - f1: 0.6842 - auc: 0.8524 - val_loss: 0.8810 - val_accuracy: 0.6253 - val_f1: 0.6174 - val_auc: 0.6821\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4629 - accuracy: 0.7725 - f1: 0.6942 - auc: 0.8605 - val_loss: 0.6571 - val_accuracy: 0.6951 - val_f1: 0.6516 - val_auc: 0.7612\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4486 - accuracy: 0.7814 - f1: 0.7030 - auc: 0.8705 - val_loss: 0.6561 - val_accuracy: 0.6873 - val_f1: 0.6343 - val_auc: 0.7492\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4458 - accuracy: 0.7836 - f1: 0.7060 - auc: 0.8719 - val_loss: 0.9944 - val_accuracy: 0.6227 - val_f1: 0.6135 - val_auc: 0.6694\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4380 - accuracy: 0.7893 - f1: 0.7120 - auc: 0.8770 - val_loss: 0.6114 - val_accuracy: 0.7183 - val_f1: 0.6515 - val_auc: 0.7821\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 71.83%\n",
            "F1: 65.86%\n",
            "AUC: 78.21%\n",
            "Loss: 0.61%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6679 - accuracy: 0.5895 - f1: 0.5271 - auc: 0.6201 - val_loss: 0.6673 - val_accuracy: 0.6072 - val_f1: 0.5464 - val_auc: 0.6488\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5899 - accuracy: 0.6835 - f1: 0.5939 - auc: 0.7506 - val_loss: 1.0418 - val_accuracy: 0.4729 - val_f1: 0.5209 - val_auc: 0.5542\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5687 - accuracy: 0.7033 - f1: 0.6132 - auc: 0.7746 - val_loss: 0.8676 - val_accuracy: 0.5297 - val_f1: 0.5407 - val_auc: 0.5774\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5610 - accuracy: 0.7096 - f1: 0.6202 - auc: 0.7820 - val_loss: 0.7068 - val_accuracy: 0.5814 - val_f1: 0.5617 - val_auc: 0.6353\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5492 - accuracy: 0.7199 - f1: 0.6283 - auc: 0.7930 - val_loss: 0.6951 - val_accuracy: 0.5943 - val_f1: 0.5738 - val_auc: 0.6587\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5459 - accuracy: 0.7222 - f1: 0.6315 - auc: 0.7954 - val_loss: 0.7090 - val_accuracy: 0.5788 - val_f1: 0.5782 - val_auc: 0.6587\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5372 - accuracy: 0.7250 - f1: 0.6386 - auc: 0.8032 - val_loss: 0.6401 - val_accuracy: 0.6279 - val_f1: 0.5695 - val_auc: 0.6958\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5348 - accuracy: 0.7236 - f1: 0.6391 - auc: 0.8045 - val_loss: 0.6325 - val_accuracy: 0.6848 - val_f1: 0.6137 - val_auc: 0.7367\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5225 - accuracy: 0.7301 - f1: 0.6485 - auc: 0.8148 - val_loss: 0.9003 - val_accuracy: 0.5840 - val_f1: 0.5823 - val_auc: 0.6373\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5156 - accuracy: 0.7386 - f1: 0.6543 - auc: 0.8209 - val_loss: 0.6954 - val_accuracy: 0.6253 - val_f1: 0.6200 - val_auc: 0.7136\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5082 - accuracy: 0.7385 - f1: 0.6598 - auc: 0.8258 - val_loss: 0.6864 - val_accuracy: 0.6331 - val_f1: 0.6097 - val_auc: 0.7043\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5033 - accuracy: 0.7465 - f1: 0.6627 - auc: 0.8305 - val_loss: 0.6566 - val_accuracy: 0.6434 - val_f1: 0.6133 - val_auc: 0.7216\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4921 - accuracy: 0.7532 - f1: 0.6711 - auc: 0.8389 - val_loss: 0.7393 - val_accuracy: 0.6382 - val_f1: 0.6229 - val_auc: 0.7065\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4889 - accuracy: 0.7532 - f1: 0.6744 - auc: 0.8414 - val_loss: 0.7579 - val_accuracy: 0.6357 - val_f1: 0.6246 - val_auc: 0.7057\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4801 - accuracy: 0.7600 - f1: 0.6798 - auc: 0.8476 - val_loss: 0.6602 - val_accuracy: 0.6718 - val_f1: 0.6438 - val_auc: 0.7503\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4770 - accuracy: 0.7573 - f1: 0.6826 - auc: 0.8496 - val_loss: 0.6668 - val_accuracy: 0.6744 - val_f1: 0.6404 - val_auc: 0.7454\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4665 - accuracy: 0.7658 - f1: 0.6904 - auc: 0.8571 - val_loss: 0.7218 - val_accuracy: 0.6770 - val_f1: 0.6446 - val_auc: 0.7362\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4645 - accuracy: 0.7683 - f1: 0.6926 - auc: 0.8585 - val_loss: 0.5938 - val_accuracy: 0.7313 - val_f1: 0.6337 - val_auc: 0.7770\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4537 - accuracy: 0.7733 - f1: 0.6992 - auc: 0.8661 - val_loss: 0.6611 - val_accuracy: 0.7158 - val_f1: 0.6694 - val_auc: 0.7741\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4426 - accuracy: 0.7857 - f1: 0.7081 - auc: 0.8737 - val_loss: 0.9230 - val_accuracy: 0.6357 - val_f1: 0.6258 - val_auc: 0.6894\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 63.57%\n",
            "F1: 63.37%\n",
            "AUC: 68.94%\n",
            "Loss: 0.92%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6690 - accuracy: 0.5849 - f1: 0.5251 - auc: 0.6168 - val_loss: 0.7422 - val_accuracy: 0.5271 - val_f1: 0.5281 - val_auc: 0.5753\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5908 - accuracy: 0.6853 - f1: 0.5931 - auc: 0.7496 - val_loss: 0.8064 - val_accuracy: 0.5633 - val_f1: 0.5484 - val_auc: 0.5903\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5700 - accuracy: 0.7053 - f1: 0.6117 - auc: 0.7728 - val_loss: 0.7377 - val_accuracy: 0.5840 - val_f1: 0.5615 - val_auc: 0.6246\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5591 - accuracy: 0.7130 - f1: 0.6210 - auc: 0.7835 - val_loss: 0.7264 - val_accuracy: 0.5788 - val_f1: 0.5568 - val_auc: 0.6171\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5475 - accuracy: 0.7191 - f1: 0.6302 - auc: 0.7948 - val_loss: 0.8821 - val_accuracy: 0.5245 - val_f1: 0.5456 - val_auc: 0.5868\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5393 - accuracy: 0.7289 - f1: 0.6368 - auc: 0.8024 - val_loss: 0.7919 - val_accuracy: 0.5659 - val_f1: 0.5687 - val_auc: 0.6232\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5337 - accuracy: 0.7308 - f1: 0.6413 - auc: 0.8067 - val_loss: 0.6953 - val_accuracy: 0.6124 - val_f1: 0.5850 - val_auc: 0.6708\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5263 - accuracy: 0.7336 - f1: 0.6458 - auc: 0.8129 - val_loss: 0.6469 - val_accuracy: 0.6615 - val_f1: 0.6084 - val_auc: 0.7232\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5152 - accuracy: 0.7400 - f1: 0.6544 - auc: 0.8216 - val_loss: 0.6046 - val_accuracy: 0.7080 - val_f1: 0.6312 - val_auc: 0.7664\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5148 - accuracy: 0.7399 - f1: 0.6550 - auc: 0.8217 - val_loss: 0.6423 - val_accuracy: 0.6822 - val_f1: 0.6166 - val_auc: 0.7360\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5028 - accuracy: 0.7459 - f1: 0.6636 - auc: 0.8314 - val_loss: 0.8117 - val_accuracy: 0.6150 - val_f1: 0.6067 - val_auc: 0.6763\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4956 - accuracy: 0.7474 - f1: 0.6690 - auc: 0.8360 - val_loss: 0.6815 - val_accuracy: 0.6512 - val_f1: 0.6117 - val_auc: 0.7130\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4860 - accuracy: 0.7581 - f1: 0.6764 - auc: 0.8447 - val_loss: 0.7459 - val_accuracy: 0.6072 - val_f1: 0.5994 - val_auc: 0.6768\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4812 - accuracy: 0.7573 - f1: 0.6795 - auc: 0.8470 - val_loss: 0.9165 - val_accuracy: 0.6047 - val_f1: 0.6004 - val_auc: 0.6562\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4756 - accuracy: 0.7617 - f1: 0.6841 - auc: 0.8505 - val_loss: 0.7102 - val_accuracy: 0.6641 - val_f1: 0.6246 - val_auc: 0.7180\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4682 - accuracy: 0.7639 - f1: 0.6891 - auc: 0.8560 - val_loss: 0.6283 - val_accuracy: 0.7028 - val_f1: 0.6268 - val_auc: 0.7564\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4659 - accuracy: 0.7689 - f1: 0.6926 - auc: 0.8583 - val_loss: 0.6354 - val_accuracy: 0.6925 - val_f1: 0.6354 - val_auc: 0.7557\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4538 - accuracy: 0.7759 - f1: 0.6986 - auc: 0.8656 - val_loss: 0.6486 - val_accuracy: 0.7106 - val_f1: 0.6531 - val_auc: 0.7635\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4419 - accuracy: 0.7855 - f1: 0.7078 - auc: 0.8742 - val_loss: 0.6855 - val_accuracy: 0.7028 - val_f1: 0.6453 - val_auc: 0.7484\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4379 - accuracy: 0.7844 - f1: 0.7120 - auc: 0.8762 - val_loss: 0.6305 - val_accuracy: 0.7209 - val_f1: 0.6411 - val_auc: 0.7660\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 72.09%\n",
            "F1: 64.40%\n",
            "AUC: 76.60%\n",
            "Loss: 0.63%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6585 - accuracy: 0.5991 - f1: 0.5314 - auc: 0.6401 - val_loss: 0.8970 - val_accuracy: 0.4780 - val_f1: 0.5190 - val_auc: 0.5498\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5875 - accuracy: 0.6860 - f1: 0.5972 - auc: 0.7536 - val_loss: 0.9024 - val_accuracy: 0.4961 - val_f1: 0.5291 - val_auc: 0.5610\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5692 - accuracy: 0.7019 - f1: 0.6120 - auc: 0.7737 - val_loss: 0.6858 - val_accuracy: 0.5943 - val_f1: 0.5689 - val_auc: 0.6554\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5594 - accuracy: 0.7130 - f1: 0.6210 - auc: 0.7838 - val_loss: 0.8634 - val_accuracy: 0.5504 - val_f1: 0.5454 - val_auc: 0.5836\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5491 - accuracy: 0.7207 - f1: 0.6290 - auc: 0.7934 - val_loss: 0.6694 - val_accuracy: 0.6047 - val_f1: 0.5676 - val_auc: 0.6718\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5418 - accuracy: 0.7268 - f1: 0.6354 - auc: 0.8002 - val_loss: 0.6671 - val_accuracy: 0.5866 - val_f1: 0.5693 - val_auc: 0.6673\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5303 - accuracy: 0.7301 - f1: 0.6425 - auc: 0.8094 - val_loss: 0.6463 - val_accuracy: 0.6408 - val_f1: 0.5846 - val_auc: 0.7013\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5314 - accuracy: 0.7299 - f1: 0.6425 - auc: 0.8079 - val_loss: 0.5963 - val_accuracy: 0.7132 - val_f1: 0.5959 - val_auc: 0.7606\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5192 - accuracy: 0.7393 - f1: 0.6507 - auc: 0.8184 - val_loss: 0.7077 - val_accuracy: 0.6382 - val_f1: 0.6264 - val_auc: 0.7165\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5148 - accuracy: 0.7417 - f1: 0.6555 - auc: 0.8218 - val_loss: 0.6008 - val_accuracy: 0.7106 - val_f1: 0.6013 - val_auc: 0.7601\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5090 - accuracy: 0.7412 - f1: 0.6585 - auc: 0.8262 - val_loss: 0.6628 - val_accuracy: 0.6667 - val_f1: 0.6351 - val_auc: 0.7387\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5056 - accuracy: 0.7401 - f1: 0.6621 - auc: 0.8276 - val_loss: 0.7082 - val_accuracy: 0.6434 - val_f1: 0.6207 - val_auc: 0.7105\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4938 - accuracy: 0.7519 - f1: 0.6701 - auc: 0.8380 - val_loss: 0.7836 - val_accuracy: 0.6305 - val_f1: 0.6111 - val_auc: 0.6845\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4927 - accuracy: 0.7514 - f1: 0.6720 - auc: 0.8389 - val_loss: 0.8742 - val_accuracy: 0.6176 - val_f1: 0.6026 - val_auc: 0.6643\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4817 - accuracy: 0.7571 - f1: 0.6794 - auc: 0.8465 - val_loss: 0.5993 - val_accuracy: 0.7106 - val_f1: 0.6376 - val_auc: 0.7726\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4766 - accuracy: 0.7587 - f1: 0.6832 - auc: 0.8501 - val_loss: 0.7502 - val_accuracy: 0.6305 - val_f1: 0.6175 - val_auc: 0.6985\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4748 - accuracy: 0.7678 - f1: 0.6855 - auc: 0.8524 - val_loss: 0.6330 - val_accuracy: 0.6796 - val_f1: 0.6340 - val_auc: 0.7525\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4619 - accuracy: 0.7707 - f1: 0.6937 - auc: 0.8607 - val_loss: 0.6639 - val_accuracy: 0.6951 - val_f1: 0.6599 - val_auc: 0.7634\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4513 - accuracy: 0.7811 - f1: 0.7021 - auc: 0.8685 - val_loss: 0.6397 - val_accuracy: 0.7132 - val_f1: 0.6716 - val_auc: 0.7814\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4549 - accuracy: 0.7769 - f1: 0.7015 - auc: 0.8659 - val_loss: 0.6248 - val_accuracy: 0.7054 - val_f1: 0.6634 - val_auc: 0.7801\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 70.54%\n",
            "F1: 66.64%\n",
            "AUC: 78.01%\n",
            "Loss: 0.62%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6698 - accuracy: 0.5763 - f1: 0.5213 - auc: 0.6168 - val_loss: 0.7912 - val_accuracy: 0.5401 - val_f1: 0.5340 - val_auc: 0.5739\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5907 - accuracy: 0.6829 - f1: 0.5933 - auc: 0.7502 - val_loss: 0.7911 - val_accuracy: 0.5685 - val_f1: 0.5505 - val_auc: 0.5956\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5707 - accuracy: 0.7036 - f1: 0.6114 - auc: 0.7722 - val_loss: 0.7780 - val_accuracy: 0.5607 - val_f1: 0.5493 - val_auc: 0.5949\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5593 - accuracy: 0.7115 - f1: 0.6210 - auc: 0.7838 - val_loss: 0.6449 - val_accuracy: 0.6331 - val_f1: 0.5754 - val_auc: 0.6929\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5507 - accuracy: 0.7203 - f1: 0.6276 - auc: 0.7920 - val_loss: 0.7804 - val_accuracy: 0.5607 - val_f1: 0.5486 - val_auc: 0.5903\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5403 - accuracy: 0.7280 - f1: 0.6370 - auc: 0.8011 - val_loss: 0.7414 - val_accuracy: 0.5788 - val_f1: 0.5560 - val_auc: 0.6080\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5384 - accuracy: 0.7250 - f1: 0.6368 - auc: 0.8025 - val_loss: 0.6378 - val_accuracy: 0.6486 - val_f1: 0.5767 - val_auc: 0.7072\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5286 - accuracy: 0.7354 - f1: 0.6441 - auc: 0.8109 - val_loss: 0.6430 - val_accuracy: 0.6667 - val_f1: 0.5974 - val_auc: 0.7187\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5187 - accuracy: 0.7387 - f1: 0.6519 - auc: 0.8193 - val_loss: 0.6240 - val_accuracy: 0.6796 - val_f1: 0.6061 - val_auc: 0.7394\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5155 - accuracy: 0.7401 - f1: 0.6550 - auc: 0.8215 - val_loss: 0.6663 - val_accuracy: 0.6357 - val_f1: 0.6083 - val_auc: 0.7113\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5096 - accuracy: 0.7440 - f1: 0.6593 - auc: 0.8264 - val_loss: 0.6869 - val_accuracy: 0.6279 - val_f1: 0.6034 - val_auc: 0.6991\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5039 - accuracy: 0.7431 - f1: 0.6623 - auc: 0.8297 - val_loss: 0.8181 - val_accuracy: 0.6047 - val_f1: 0.6019 - val_auc: 0.6684\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4899 - accuracy: 0.7537 - f1: 0.6727 - auc: 0.8410 - val_loss: 0.7822 - val_accuracy: 0.6176 - val_f1: 0.6154 - val_auc: 0.6920\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4893 - accuracy: 0.7552 - f1: 0.6743 - auc: 0.8413 - val_loss: 0.6919 - val_accuracy: 0.6693 - val_f1: 0.6368 - val_auc: 0.7337\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4770 - accuracy: 0.7613 - f1: 0.6829 - auc: 0.8502 - val_loss: 0.7046 - val_accuracy: 0.6615 - val_f1: 0.6308 - val_auc: 0.7250\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4736 - accuracy: 0.7658 - f1: 0.6859 - auc: 0.8532 - val_loss: 0.6124 - val_accuracy: 0.7183 - val_f1: 0.6515 - val_auc: 0.7776\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4630 - accuracy: 0.7720 - f1: 0.6925 - auc: 0.8605 - val_loss: 0.6700 - val_accuracy: 0.6873 - val_f1: 0.6601 - val_auc: 0.7643\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4575 - accuracy: 0.7774 - f1: 0.6984 - auc: 0.8643 - val_loss: 0.7428 - val_accuracy: 0.6822 - val_f1: 0.6502 - val_auc: 0.7391\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4482 - accuracy: 0.7815 - f1: 0.7049 - auc: 0.8704 - val_loss: 0.7668 - val_accuracy: 0.6589 - val_f1: 0.6438 - val_auc: 0.7261\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4409 - accuracy: 0.7864 - f1: 0.7100 - auc: 0.8752 - val_loss: 0.6914 - val_accuracy: 0.7028 - val_f1: 0.6509 - val_auc: 0.7514\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 70.28%\n",
            "F1: 65.18%\n",
            "AUC: 75.14%\n",
            "Loss: 0.69%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6516 - accuracy: 0.6082 - f1: 0.5386 - auc: 0.6555 - val_loss: 0.6631 - val_accuracy: 0.6021 - val_f1: 0.5518 - val_auc: 0.6623\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5814 - accuracy: 0.6936 - f1: 0.6006 - auc: 0.7607 - val_loss: 0.8705 - val_accuracy: 0.5323 - val_f1: 0.5421 - val_auc: 0.5788\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5705 - accuracy: 0.7045 - f1: 0.6107 - auc: 0.7723 - val_loss: 0.8408 - val_accuracy: 0.5685 - val_f1: 0.5522 - val_auc: 0.5963\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5601 - accuracy: 0.7114 - f1: 0.6212 - auc: 0.7831 - val_loss: 0.6689 - val_accuracy: 0.6176 - val_f1: 0.5756 - val_auc: 0.6758\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5510 - accuracy: 0.7194 - f1: 0.6277 - auc: 0.7912 - val_loss: 0.7069 - val_accuracy: 0.5840 - val_f1: 0.5657 - val_auc: 0.6382\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5452 - accuracy: 0.7239 - f1: 0.6325 - auc: 0.7966 - val_loss: 0.6647 - val_accuracy: 0.6382 - val_f1: 0.5909 - val_auc: 0.6949\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5351 - accuracy: 0.7255 - f1: 0.6401 - auc: 0.8053 - val_loss: 0.6361 - val_accuracy: 0.6408 - val_f1: 0.5905 - val_auc: 0.7190\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5302 - accuracy: 0.7278 - f1: 0.6439 - auc: 0.8086 - val_loss: 0.7174 - val_accuracy: 0.5788 - val_f1: 0.5662 - val_auc: 0.6332\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5207 - accuracy: 0.7350 - f1: 0.6491 - auc: 0.8173 - val_loss: 0.7702 - val_accuracy: 0.5917 - val_f1: 0.5910 - val_auc: 0.6599\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5158 - accuracy: 0.7357 - f1: 0.6544 - auc: 0.8207 - val_loss: 0.6917 - val_accuracy: 0.6331 - val_f1: 0.6024 - val_auc: 0.6948\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5046 - accuracy: 0.7419 - f1: 0.6615 - auc: 0.8291 - val_loss: 0.6556 - val_accuracy: 0.6537 - val_f1: 0.6092 - val_auc: 0.7188\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5027 - accuracy: 0.7446 - f1: 0.6643 - auc: 0.8314 - val_loss: 0.6151 - val_accuracy: 0.6977 - val_f1: 0.6282 - val_auc: 0.7598\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4923 - accuracy: 0.7498 - f1: 0.6709 - auc: 0.8384 - val_loss: 0.8417 - val_accuracy: 0.6072 - val_f1: 0.6016 - val_auc: 0.6664\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4859 - accuracy: 0.7534 - f1: 0.6765 - auc: 0.8434 - val_loss: 0.6158 - val_accuracy: 0.7080 - val_f1: 0.6082 - val_auc: 0.7554\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4790 - accuracy: 0.7570 - f1: 0.6809 - auc: 0.8481 - val_loss: 0.7105 - val_accuracy: 0.6589 - val_f1: 0.6164 - val_auc: 0.7080\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4700 - accuracy: 0.7624 - f1: 0.6877 - auc: 0.8547 - val_loss: 0.6211 - val_accuracy: 0.6925 - val_f1: 0.6371 - val_auc: 0.7640\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4655 - accuracy: 0.7677 - f1: 0.6911 - auc: 0.8581 - val_loss: 0.7467 - val_accuracy: 0.6202 - val_f1: 0.6181 - val_auc: 0.7007\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4559 - accuracy: 0.7718 - f1: 0.6972 - auc: 0.8644 - val_loss: 0.7165 - val_accuracy: 0.6977 - val_f1: 0.6515 - val_auc: 0.7460\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4534 - accuracy: 0.7739 - f1: 0.7004 - auc: 0.8661 - val_loss: 0.6342 - val_accuracy: 0.7132 - val_f1: 0.6631 - val_auc: 0.7774\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4442 - accuracy: 0.7805 - f1: 0.7061 - auc: 0.8720 - val_loss: 0.8327 - val_accuracy: 0.6176 - val_f1: 0.6212 - val_auc: 0.6946\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 61.76%\n",
            "F1: 62.56%\n",
            "AUC: 69.46%\n",
            "Loss: 0.83%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6558 - accuracy: 0.6016 - f1: 0.5333 - auc: 0.6469 - val_loss: 0.6824 - val_accuracy: 0.5995 - val_f1: 0.5503 - val_auc: 0.6424\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5937 - accuracy: 0.6807 - f1: 0.5923 - auc: 0.7464 - val_loss: 0.7948 - val_accuracy: 0.5452 - val_f1: 0.5414 - val_auc: 0.5804\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5733 - accuracy: 0.7001 - f1: 0.6091 - auc: 0.7692 - val_loss: 0.7445 - val_accuracy: 0.5685 - val_f1: 0.5574 - val_auc: 0.6161\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5588 - accuracy: 0.7122 - f1: 0.6211 - auc: 0.7841 - val_loss: 0.9546 - val_accuracy: 0.4858 - val_f1: 0.5326 - val_auc: 0.5695\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5599 - accuracy: 0.7051 - f1: 0.6210 - auc: 0.7822 - val_loss: 0.6730 - val_accuracy: 0.5943 - val_f1: 0.5840 - val_auc: 0.6788\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5411 - accuracy: 0.7248 - f1: 0.6339 - auc: 0.7998 - val_loss: 0.7000 - val_accuracy: 0.6047 - val_f1: 0.5915 - val_auc: 0.6774\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5335 - accuracy: 0.7278 - f1: 0.6405 - auc: 0.8065 - val_loss: 0.6565 - val_accuracy: 0.6563 - val_f1: 0.6221 - val_auc: 0.7297\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5285 - accuracy: 0.7303 - f1: 0.6450 - auc: 0.8098 - val_loss: 0.9870 - val_accuracy: 0.5659 - val_f1: 0.5671 - val_auc: 0.6141\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5226 - accuracy: 0.7338 - f1: 0.6491 - auc: 0.8156 - val_loss: 0.7903 - val_accuracy: 0.5788 - val_f1: 0.5859 - val_auc: 0.6498\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5104 - accuracy: 0.7425 - f1: 0.6579 - auc: 0.8251 - val_loss: 0.7867 - val_accuracy: 0.5762 - val_f1: 0.5819 - val_auc: 0.6440\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5025 - accuracy: 0.7415 - f1: 0.6624 - auc: 0.8301 - val_loss: 0.7986 - val_accuracy: 0.6305 - val_f1: 0.6209 - val_auc: 0.6946\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4962 - accuracy: 0.7484 - f1: 0.6686 - auc: 0.8357 - val_loss: 0.7547 - val_accuracy: 0.6434 - val_f1: 0.6256 - val_auc: 0.7076\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5003 - accuracy: 0.7481 - f1: 0.6670 - auc: 0.8325 - val_loss: 0.6356 - val_accuracy: 0.6563 - val_f1: 0.6195 - val_auc: 0.7398\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4851 - accuracy: 0.7575 - f1: 0.6760 - auc: 0.8444 - val_loss: 0.7257 - val_accuracy: 0.6382 - val_f1: 0.6297 - val_auc: 0.7181\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4834 - accuracy: 0.7567 - f1: 0.6788 - auc: 0.8451 - val_loss: 0.6908 - val_accuracy: 0.6693 - val_f1: 0.6374 - val_auc: 0.7354\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4686 - accuracy: 0.7707 - f1: 0.6885 - auc: 0.8565 - val_loss: 0.7197 - val_accuracy: 0.6718 - val_f1: 0.6481 - val_auc: 0.7392\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4627 - accuracy: 0.7706 - f1: 0.6930 - auc: 0.8601 - val_loss: 0.8155 - val_accuracy: 0.6615 - val_f1: 0.6474 - val_auc: 0.7244\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4541 - accuracy: 0.7761 - f1: 0.6995 - auc: 0.8662 - val_loss: 0.7897 - val_accuracy: 0.6744 - val_f1: 0.6545 - val_auc: 0.7362\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4473 - accuracy: 0.7796 - f1: 0.7048 - auc: 0.8707 - val_loss: 0.6665 - val_accuracy: 0.6951 - val_f1: 0.6665 - val_auc: 0.7710\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4396 - accuracy: 0.7838 - f1: 0.7096 - auc: 0.8754 - val_loss: 0.6955 - val_accuracy: 0.6951 - val_f1: 0.6605 - val_auc: 0.7588\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 69.51%\n",
            "F1: 66.74%\n",
            "AUC: 75.88%\n",
            "Loss: 0.70%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 27ms/step - loss: 0.6776 - accuracy: 0.5697 - f1: 0.5143 - auc: 0.5992 - val_loss: 0.9680 - val_accuracy: 0.4548 - val_f1: 0.5030 - val_auc: 0.5419\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5947 - accuracy: 0.6814 - f1: 0.5906 - auc: 0.7461 - val_loss: 0.8683 - val_accuracy: 0.5142 - val_f1: 0.5312 - val_auc: 0.5599\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5740 - accuracy: 0.6995 - f1: 0.6087 - auc: 0.7689 - val_loss: 0.7881 - val_accuracy: 0.5814 - val_f1: 0.5524 - val_auc: 0.5984\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5596 - accuracy: 0.7109 - f1: 0.6211 - auc: 0.7835 - val_loss: 0.7781 - val_accuracy: 0.5556 - val_f1: 0.5416 - val_auc: 0.5839\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5511 - accuracy: 0.7166 - f1: 0.6276 - auc: 0.7912 - val_loss: 0.6695 - val_accuracy: 0.5736 - val_f1: 0.5550 - val_auc: 0.6496\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5440 - accuracy: 0.7225 - f1: 0.6334 - auc: 0.7974 - val_loss: 0.6278 - val_accuracy: 0.6693 - val_f1: 0.5540 - val_auc: 0.7156\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5470 - accuracy: 0.7180 - f1: 0.6300 - auc: 0.7943 - val_loss: 0.7040 - val_accuracy: 0.5607 - val_f1: 0.5590 - val_auc: 0.6274\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5292 - accuracy: 0.7349 - f1: 0.6446 - auc: 0.8100 - val_loss: 0.6514 - val_accuracy: 0.6434 - val_f1: 0.6049 - val_auc: 0.7148\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5204 - accuracy: 0.7383 - f1: 0.6503 - auc: 0.8180 - val_loss: 0.7160 - val_accuracy: 0.6021 - val_f1: 0.5906 - val_auc: 0.6716\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5178 - accuracy: 0.7429 - f1: 0.6531 - auc: 0.8197 - val_loss: 0.7352 - val_accuracy: 0.6021 - val_f1: 0.5894 - val_auc: 0.6639\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5151 - accuracy: 0.7412 - f1: 0.6553 - auc: 0.8216 - val_loss: 0.5921 - val_accuracy: 0.6977 - val_f1: 0.6153 - val_auc: 0.7685\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4984 - accuracy: 0.7510 - f1: 0.6664 - auc: 0.8346 - val_loss: 0.6448 - val_accuracy: 0.6589 - val_f1: 0.6168 - val_auc: 0.7320\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4930 - accuracy: 0.7574 - f1: 0.6714 - auc: 0.8390 - val_loss: 0.7165 - val_accuracy: 0.6537 - val_f1: 0.6233 - val_auc: 0.7128\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4896 - accuracy: 0.7581 - f1: 0.6740 - auc: 0.8418 - val_loss: 0.6907 - val_accuracy: 0.6718 - val_f1: 0.6413 - val_auc: 0.7388\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4817 - accuracy: 0.7608 - f1: 0.6804 - auc: 0.8473 - val_loss: 0.8445 - val_accuracy: 0.6253 - val_f1: 0.6117 - val_auc: 0.6772\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4753 - accuracy: 0.7666 - f1: 0.6831 - auc: 0.8512 - val_loss: 0.6503 - val_accuracy: 0.6848 - val_f1: 0.6427 - val_auc: 0.7539\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4716 - accuracy: 0.7676 - f1: 0.6886 - auc: 0.8539 - val_loss: 0.6687 - val_accuracy: 0.6822 - val_f1: 0.6425 - val_auc: 0.7468\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4613 - accuracy: 0.7746 - f1: 0.6935 - auc: 0.8615 - val_loss: 0.6814 - val_accuracy: 0.6822 - val_f1: 0.6466 - val_auc: 0.7474\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4551 - accuracy: 0.7808 - f1: 0.6987 - auc: 0.8661 - val_loss: 0.8022 - val_accuracy: 0.6460 - val_f1: 0.6340 - val_auc: 0.7117\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4403 - accuracy: 0.7876 - f1: 0.7108 - auc: 0.8759 - val_loss: 0.7619 - val_accuracy: 0.6615 - val_f1: 0.6439 - val_auc: 0.7278\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 66.15%\n",
            "F1: 65.37%\n",
            "AUC: 72.78%\n",
            "Loss: 0.76%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 27ms/step - loss: 0.6606 - accuracy: 0.5931 - f1: 0.5291 - auc: 0.6351 - val_loss: 0.7359 - val_accuracy: 0.5866 - val_f1: 0.5438 - val_auc: 0.6049\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5838 - accuracy: 0.6923 - f1: 0.5990 - auc: 0.7580 - val_loss: 0.8583 - val_accuracy: 0.5607 - val_f1: 0.5416 - val_auc: 0.5712\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5661 - accuracy: 0.7097 - f1: 0.6158 - auc: 0.7773 - val_loss: 0.6408 - val_accuracy: 0.6357 - val_f1: 0.5595 - val_auc: 0.6955\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5562 - accuracy: 0.7206 - f1: 0.6218 - auc: 0.7865 - val_loss: 0.6960 - val_accuracy: 0.6124 - val_f1: 0.5727 - val_auc: 0.6615\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5479 - accuracy: 0.7210 - f1: 0.6311 - auc: 0.7948 - val_loss: 0.7322 - val_accuracy: 0.5762 - val_f1: 0.5591 - val_auc: 0.6208\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5396 - accuracy: 0.7264 - f1: 0.6371 - auc: 0.8017 - val_loss: 0.7427 - val_accuracy: 0.5762 - val_f1: 0.5707 - val_auc: 0.6363\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5315 - accuracy: 0.7299 - f1: 0.6423 - auc: 0.8088 - val_loss: 0.7153 - val_accuracy: 0.6253 - val_f1: 0.5977 - val_auc: 0.6825\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5325 - accuracy: 0.7248 - f1: 0.6426 - auc: 0.8071 - val_loss: 0.6503 - val_accuracy: 0.6305 - val_f1: 0.5890 - val_auc: 0.7032\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5238 - accuracy: 0.7314 - f1: 0.6491 - auc: 0.8147 - val_loss: 0.6833 - val_accuracy: 0.6072 - val_f1: 0.5780 - val_auc: 0.6669\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5191 - accuracy: 0.7366 - f1: 0.6517 - auc: 0.8189 - val_loss: 0.7261 - val_accuracy: 0.6124 - val_f1: 0.6031 - val_auc: 0.6859\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5072 - accuracy: 0.7436 - f1: 0.6611 - auc: 0.8284 - val_loss: 0.9255 - val_accuracy: 0.5891 - val_f1: 0.5874 - val_auc: 0.6431\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5111 - accuracy: 0.7372 - f1: 0.6583 - auc: 0.8237 - val_loss: 0.8797 - val_accuracy: 0.5943 - val_f1: 0.5919 - val_auc: 0.6512\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4969 - accuracy: 0.7466 - f1: 0.6690 - auc: 0.8354 - val_loss: 0.7691 - val_accuracy: 0.6047 - val_f1: 0.5918 - val_auc: 0.6598\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4878 - accuracy: 0.7537 - f1: 0.6753 - auc: 0.8430 - val_loss: 0.6555 - val_accuracy: 0.6693 - val_f1: 0.6141 - val_auc: 0.7269\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4798 - accuracy: 0.7598 - f1: 0.6818 - auc: 0.8486 - val_loss: 0.7252 - val_accuracy: 0.6279 - val_f1: 0.6081 - val_auc: 0.6925\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4748 - accuracy: 0.7651 - f1: 0.6853 - auc: 0.8528 - val_loss: 0.6052 - val_accuracy: 0.7106 - val_f1: 0.6175 - val_auc: 0.7666\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4653 - accuracy: 0.7675 - f1: 0.6919 - auc: 0.8589 - val_loss: 0.6640 - val_accuracy: 0.6848 - val_f1: 0.6427 - val_auc: 0.7500\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4599 - accuracy: 0.7708 - f1: 0.6950 - auc: 0.8619 - val_loss: 0.6789 - val_accuracy: 0.6822 - val_f1: 0.6463 - val_auc: 0.7484\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4553 - accuracy: 0.7757 - f1: 0.6998 - auc: 0.8656 - val_loss: 0.6556 - val_accuracy: 0.6925 - val_f1: 0.6375 - val_auc: 0.7486\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4399 - accuracy: 0.7874 - f1: 0.7098 - auc: 0.8759 - val_loss: 0.6932 - val_accuracy: 0.6822 - val_f1: 0.6494 - val_auc: 0.7474\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 68.22%\n",
            "F1: 65.34%\n",
            "AUC: 74.74%\n",
            "Loss: 0.69%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 8s 27ms/step - loss: 0.6513 - accuracy: 0.6031 - f1: 0.5377 - auc: 0.6559 - val_loss: 0.6875 - val_accuracy: 0.5969 - val_f1: 0.5528 - val_auc: 0.6393\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5785 - accuracy: 0.6953 - f1: 0.6040 - auc: 0.7641 - val_loss: 0.7364 - val_accuracy: 0.5866 - val_f1: 0.5557 - val_auc: 0.6148\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5719 - accuracy: 0.7030 - f1: 0.6113 - auc: 0.7712 - val_loss: 0.7332 - val_accuracy: 0.5943 - val_f1: 0.5573 - val_auc: 0.6185\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5563 - accuracy: 0.7143 - f1: 0.6232 - auc: 0.7868 - val_loss: 0.7149 - val_accuracy: 0.5762 - val_f1: 0.5693 - val_auc: 0.6434\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5470 - accuracy: 0.7241 - f1: 0.6310 - auc: 0.7955 - val_loss: 0.6406 - val_accuracy: 0.6382 - val_f1: 0.5732 - val_auc: 0.7002\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5454 - accuracy: 0.7231 - f1: 0.6332 - auc: 0.7970 - val_loss: 0.7533 - val_accuracy: 0.5788 - val_f1: 0.5643 - val_auc: 0.6226\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5369 - accuracy: 0.7284 - f1: 0.6388 - auc: 0.8043 - val_loss: 0.7859 - val_accuracy: 0.5788 - val_f1: 0.5686 - val_auc: 0.6226\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5275 - accuracy: 0.7323 - f1: 0.6455 - auc: 0.8118 - val_loss: 0.6606 - val_accuracy: 0.6305 - val_f1: 0.5923 - val_auc: 0.6998\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5248 - accuracy: 0.7325 - f1: 0.6476 - auc: 0.8143 - val_loss: 0.7405 - val_accuracy: 0.5917 - val_f1: 0.5822 - val_auc: 0.6534\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5155 - accuracy: 0.7363 - f1: 0.6552 - auc: 0.8212 - val_loss: 0.8799 - val_accuracy: 0.5736 - val_f1: 0.5803 - val_auc: 0.6347\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5126 - accuracy: 0.7414 - f1: 0.6564 - auc: 0.8238 - val_loss: 0.7070 - val_accuracy: 0.6357 - val_f1: 0.6122 - val_auc: 0.7014\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4996 - accuracy: 0.7502 - f1: 0.6659 - auc: 0.8339 - val_loss: 0.8325 - val_accuracy: 0.6227 - val_f1: 0.6054 - val_auc: 0.6703\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4940 - accuracy: 0.7511 - f1: 0.6707 - auc: 0.8380 - val_loss: 0.7189 - val_accuracy: 0.6434 - val_f1: 0.6173 - val_auc: 0.7046\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4868 - accuracy: 0.7544 - f1: 0.6764 - auc: 0.8426 - val_loss: 0.7320 - val_accuracy: 0.6357 - val_f1: 0.6224 - val_auc: 0.7077\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4792 - accuracy: 0.7604 - f1: 0.6805 - auc: 0.8488 - val_loss: 0.6576 - val_accuracy: 0.6925 - val_f1: 0.6385 - val_auc: 0.7483\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4685 - accuracy: 0.7689 - f1: 0.6884 - auc: 0.8570 - val_loss: 0.9681 - val_accuracy: 0.6124 - val_f1: 0.6049 - val_auc: 0.6597\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4675 - accuracy: 0.7655 - f1: 0.6911 - auc: 0.8566 - val_loss: 0.6806 - val_accuracy: 0.6873 - val_f1: 0.6419 - val_auc: 0.7437\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4677 - accuracy: 0.7658 - f1: 0.6905 - auc: 0.8567 - val_loss: 0.6885 - val_accuracy: 0.6796 - val_f1: 0.6393 - val_auc: 0.7389\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4506 - accuracy: 0.7791 - f1: 0.7024 - auc: 0.8686 - val_loss: 0.6890 - val_accuracy: 0.6796 - val_f1: 0.6395 - val_auc: 0.7396\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4425 - accuracy: 0.7864 - f1: 0.7083 - auc: 0.8741 - val_loss: 0.6693 - val_accuracy: 0.6951 - val_f1: 0.6421 - val_auc: 0.7500\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 69.51%\n",
            "F1: 64.44%\n",
            "AUC: 75.00%\n",
            "Loss: 0.67%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbdVHNC4opih",
        "outputId": "cabce8de-4e71-4ed1-9ae6-4d3201c377fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.6113957762718201 - Accuracy: 71.83462381362915 - F1: 65.86218476295471 - AUC: 78.21478843688965%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.9229946732521057 - Accuracy: 63.56589198112488 - F1: 63.368427753448486 - AUC: 68.9401626586914%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.6305097341537476 - Accuracy: 72.09302186965942 - F1: 64.40009474754333 - AUC: 76.59829258918762%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.6248045563697815 - Accuracy: 70.54263353347778 - F1: 66.64077043533325 - AUC: 78.00512909889221%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.6914043426513672 - Accuracy: 70.28423547744751 - F1: 65.17699360847473 - AUC: 75.13570785522461%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.8326829075813293 - Accuracy: 61.757105588912964 - F1: 62.561601400375366 - AUC: 69.46096420288086%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.695461630821228 - Accuracy: 69.50904130935669 - F1: 66.73864722251892 - AUC: 75.8811891078949%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.7618870139122009 - Accuracy: 66.14987254142761 - F1: 65.36709666252136 - AUC: 72.78375625610352%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.6931982636451721 - Accuracy: 68.2170569896698 - F1: 65.34437537193298 - AUC: 74.73776936531067%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.6692891120910645 - Accuracy: 69.50904130935669 - F1: 64.44050669670105 - AUC: 74.99983310699463%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.7133628010749817\n",
            "> Accuracy: 68.34625244140625 (+- 3.2954592780857137)\n",
            "> F1: 64.99006986618042 (+- 1.2658125518547427)\n",
            "> AUC: 74.475759267807 (+- 3.0389122994819777)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **2.4 LSTM + Dataset: Exist for training & Exist_test for testing**"
      ],
      "metadata": {
        "id": "E8yiUDjUDjSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser2 = tf.reshape(train_embeddings2, [-1, 1, 1024])\n",
        "\n",
        "Y12 = to_categorical(train_labels2, 2)\n",
        "Y1_reshaped2 = tf.reshape(Y12, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser2.shape, Y1_reshaped2.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser2 = tf.reshape(test_embeddings2, [-1, 1, 1024])\n",
        "\n",
        "Y22 = to_categorical(test_labels2, 2)\n",
        "Y2_reshaped2 = tf.reshape(Y22, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser2.shape, Y2_reshaped2.shape)\n",
        "\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model_neur2 = tf.keras.Sequential()\n",
        "  model_neur2.add(LSTM(100, input_shape=(1, 1024), return_sequences=True))\n",
        "  model_neur2.add(Dense(1024,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model_neur2.add(Dropout(0.5))\n",
        "  model_neur2.add(Dense(128,activation='sigmoid'))\n",
        "  model_neur2.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model_neur2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model_neur2.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model_neur2.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjqGGo59DfdV",
        "outputId": "0166ce69-dcc6-4e0f-c504-947c5cc8c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (6977, 1, 1024) (6977, 1, 2)\n",
            "Test data shapes: (4368, 1, 1024) (4368, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 25ms/step - loss: 0.6537 - accuracy: 0.6049 - f1: 0.5366 - auc: 0.6509 - val_loss: 0.6577 - val_accuracy: 0.6047 - val_f1: 0.5549 - val_auc: 0.6664\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5845 - accuracy: 0.6919 - f1: 0.5997 - auc: 0.7581 - val_loss: 0.7403 - val_accuracy: 0.5866 - val_f1: 0.5565 - val_auc: 0.6130\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5685 - accuracy: 0.7082 - f1: 0.6137 - auc: 0.7750 - val_loss: 0.7875 - val_accuracy: 0.5711 - val_f1: 0.5557 - val_auc: 0.6039\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5609 - accuracy: 0.7122 - f1: 0.6201 - auc: 0.7821 - val_loss: 0.7614 - val_accuracy: 0.5478 - val_f1: 0.5479 - val_auc: 0.5918\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5476 - accuracy: 0.7239 - f1: 0.6296 - auc: 0.7947 - val_loss: 0.6945 - val_accuracy: 0.5788 - val_f1: 0.5738 - val_auc: 0.6562\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5380 - accuracy: 0.7282 - f1: 0.6377 - auc: 0.8029 - val_loss: 0.6865 - val_accuracy: 0.5762 - val_f1: 0.5693 - val_auc: 0.6519\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5292 - accuracy: 0.7301 - f1: 0.6440 - auc: 0.8105 - val_loss: 0.6467 - val_accuracy: 0.6486 - val_f1: 0.6003 - val_auc: 0.7147\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5264 - accuracy: 0.7328 - f1: 0.6469 - auc: 0.8128 - val_loss: 0.6643 - val_accuracy: 0.6408 - val_f1: 0.6109 - val_auc: 0.7141\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5192 - accuracy: 0.7341 - f1: 0.6512 - auc: 0.8178 - val_loss: 0.8160 - val_accuracy: 0.6072 - val_f1: 0.6002 - val_auc: 0.6673\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5149 - accuracy: 0.7365 - f1: 0.6555 - auc: 0.8214 - val_loss: 0.8360 - val_accuracy: 0.5943 - val_f1: 0.5985 - val_auc: 0.6629\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5005 - accuracy: 0.7509 - f1: 0.6652 - auc: 0.8332 - val_loss: 0.6459 - val_accuracy: 0.6641 - val_f1: 0.6214 - val_auc: 0.7358\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4977 - accuracy: 0.7480 - f1: 0.6672 - auc: 0.8342 - val_loss: 0.6485 - val_accuracy: 0.6744 - val_f1: 0.6272 - val_auc: 0.7405\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4908 - accuracy: 0.7550 - f1: 0.6723 - auc: 0.8403 - val_loss: 0.7218 - val_accuracy: 0.6589 - val_f1: 0.6318 - val_auc: 0.7220\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4863 - accuracy: 0.7520 - f1: 0.6760 - auc: 0.8421 - val_loss: 0.7144 - val_accuracy: 0.6486 - val_f1: 0.6244 - val_auc: 0.7153\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4754 - accuracy: 0.7632 - f1: 0.6831 - auc: 0.8514 - val_loss: 0.8541 - val_accuracy: 0.6305 - val_f1: 0.6236 - val_auc: 0.6923\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4801 - accuracy: 0.7573 - f1: 0.6817 - auc: 0.8473 - val_loss: 0.6963 - val_accuracy: 0.6641 - val_f1: 0.6282 - val_auc: 0.7240\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4591 - accuracy: 0.7720 - f1: 0.6951 - auc: 0.8625 - val_loss: 0.7009 - val_accuracy: 0.6615 - val_f1: 0.6315 - val_auc: 0.7267\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4600 - accuracy: 0.7732 - f1: 0.6958 - auc: 0.8619 - val_loss: 0.6898 - val_accuracy: 0.6718 - val_f1: 0.6286 - val_auc: 0.7271\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4524 - accuracy: 0.7766 - f1: 0.7005 - auc: 0.8673 - val_loss: 0.7232 - val_accuracy: 0.6796 - val_f1: 0.6532 - val_auc: 0.7455\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4465 - accuracy: 0.7814 - f1: 0.7053 - auc: 0.8704 - val_loss: 0.6496 - val_accuracy: 0.7132 - val_f1: 0.6643 - val_auc: 0.7742\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 71.32%\n",
            "F1: 66.43%\n",
            "AUC: 77.42%\n",
            "Loss: 0.65%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6584 - accuracy: 0.5934 - f1: 0.5324 - auc: 0.6414 - val_loss: 0.8475 - val_accuracy: 0.5090 - val_f1: 0.5298 - val_auc: 0.5614\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5892 - accuracy: 0.6846 - f1: 0.5955 - auc: 0.7518 - val_loss: 0.6904 - val_accuracy: 0.6150 - val_f1: 0.5638 - val_auc: 0.6491\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5763 - accuracy: 0.6927 - f1: 0.6068 - auc: 0.7655 - val_loss: 0.6437 - val_accuracy: 0.6227 - val_f1: 0.5616 - val_auc: 0.6863\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5563 - accuracy: 0.7132 - f1: 0.6231 - auc: 0.7866 - val_loss: 0.7522 - val_accuracy: 0.5711 - val_f1: 0.5570 - val_auc: 0.6103\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5498 - accuracy: 0.7184 - f1: 0.6288 - auc: 0.7928 - val_loss: 0.6566 - val_accuracy: 0.6279 - val_f1: 0.5810 - val_auc: 0.6903\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5431 - accuracy: 0.7201 - f1: 0.6329 - auc: 0.7977 - val_loss: 0.7394 - val_accuracy: 0.5711 - val_f1: 0.5784 - val_auc: 0.6475\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5339 - accuracy: 0.7265 - f1: 0.6404 - auc: 0.8054 - val_loss: 0.8807 - val_accuracy: 0.5556 - val_f1: 0.5640 - val_auc: 0.6098\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5252 - accuracy: 0.7299 - f1: 0.6474 - auc: 0.8126 - val_loss: 0.6123 - val_accuracy: 0.6848 - val_f1: 0.6016 - val_auc: 0.7491\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5208 - accuracy: 0.7344 - f1: 0.6489 - auc: 0.8163 - val_loss: 0.8046 - val_accuracy: 0.5917 - val_f1: 0.5953 - val_auc: 0.6598\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5179 - accuracy: 0.7377 - f1: 0.6519 - auc: 0.8186 - val_loss: 1.0004 - val_accuracy: 0.5530 - val_f1: 0.5714 - val_auc: 0.6218\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5092 - accuracy: 0.7393 - f1: 0.6593 - auc: 0.8252 - val_loss: 0.8621 - val_accuracy: 0.6021 - val_f1: 0.6023 - val_auc: 0.6641\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5045 - accuracy: 0.7421 - f1: 0.6621 - auc: 0.8289 - val_loss: 0.8052 - val_accuracy: 0.6202 - val_f1: 0.6126 - val_auc: 0.6833\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4922 - accuracy: 0.7495 - f1: 0.6705 - auc: 0.8375 - val_loss: 0.9038 - val_accuracy: 0.5685 - val_f1: 0.5877 - val_auc: 0.6422\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4841 - accuracy: 0.7580 - f1: 0.6770 - auc: 0.8450 - val_loss: 0.7512 - val_accuracy: 0.6331 - val_f1: 0.6130 - val_auc: 0.6937\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4818 - accuracy: 0.7559 - f1: 0.6786 - auc: 0.8457 - val_loss: 0.6179 - val_accuracy: 0.7028 - val_f1: 0.6536 - val_auc: 0.7767\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.4741 - accuracy: 0.7666 - f1: 0.6856 - auc: 0.8528 - val_loss: 0.7049 - val_accuracy: 0.6589 - val_f1: 0.6294 - val_auc: 0.7237\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4715 - accuracy: 0.7673 - f1: 0.6859 - auc: 0.8541 - val_loss: 0.6780 - val_accuracy: 0.6977 - val_f1: 0.6508 - val_auc: 0.7539\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4609 - accuracy: 0.7705 - f1: 0.6948 - auc: 0.8608 - val_loss: 0.9296 - val_accuracy: 0.6279 - val_f1: 0.6232 - val_auc: 0.6857\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4516 - accuracy: 0.7788 - f1: 0.7000 - auc: 0.8674 - val_loss: 0.6593 - val_accuracy: 0.6848 - val_f1: 0.6351 - val_auc: 0.7474\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4458 - accuracy: 0.7819 - f1: 0.7063 - auc: 0.8711 - val_loss: 0.8680 - val_accuracy: 0.6150 - val_f1: 0.6195 - val_auc: 0.6862\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 61.50%\n",
            "F1: 63.26%\n",
            "AUC: 68.62%\n",
            "Loss: 0.87%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6624 - accuracy: 0.5925 - f1: 0.5299 - auc: 0.6296 - val_loss: 0.9433 - val_accuracy: 0.4625 - val_f1: 0.5166 - val_auc: 0.5529\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5859 - accuracy: 0.6910 - f1: 0.5978 - auc: 0.7559 - val_loss: 0.6605 - val_accuracy: 0.6072 - val_f1: 0.5604 - val_auc: 0.6632\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5665 - accuracy: 0.7039 - f1: 0.6149 - auc: 0.7764 - val_loss: 0.8200 - val_accuracy: 0.5711 - val_f1: 0.5541 - val_auc: 0.5984\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5599 - accuracy: 0.7119 - f1: 0.6201 - auc: 0.7828 - val_loss: 0.9106 - val_accuracy: 0.5297 - val_f1: 0.5410 - val_auc: 0.5776\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5489 - accuracy: 0.7179 - f1: 0.6296 - auc: 0.7935 - val_loss: 0.7090 - val_accuracy: 0.5685 - val_f1: 0.5624 - val_auc: 0.6324\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5391 - accuracy: 0.7241 - f1: 0.6353 - auc: 0.8013 - val_loss: 0.6911 - val_accuracy: 0.6331 - val_f1: 0.5996 - val_auc: 0.6905\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5339 - accuracy: 0.7259 - f1: 0.6418 - auc: 0.8065 - val_loss: 0.8396 - val_accuracy: 0.5840 - val_f1: 0.5780 - val_auc: 0.6345\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.5294 - accuracy: 0.7267 - f1: 0.6435 - auc: 0.8094 - val_loss: 0.8336 - val_accuracy: 0.5866 - val_f1: 0.5835 - val_auc: 0.6412\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5218 - accuracy: 0.7326 - f1: 0.6495 - auc: 0.8157 - val_loss: 0.7200 - val_accuracy: 0.6227 - val_f1: 0.5992 - val_auc: 0.6812\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5130 - accuracy: 0.7380 - f1: 0.6554 - auc: 0.8228 - val_loss: 0.6737 - val_accuracy: 0.6563 - val_f1: 0.6233 - val_auc: 0.7269\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5049 - accuracy: 0.7450 - f1: 0.6616 - auc: 0.8288 - val_loss: 0.7149 - val_accuracy: 0.6305 - val_f1: 0.5997 - val_auc: 0.6836\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4983 - accuracy: 0.7485 - f1: 0.6672 - auc: 0.8340 - val_loss: 0.7472 - val_accuracy: 0.6331 - val_f1: 0.6270 - val_auc: 0.7113\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4923 - accuracy: 0.7498 - f1: 0.6716 - auc: 0.8385 - val_loss: 0.7596 - val_accuracy: 0.6253 - val_f1: 0.6018 - val_auc: 0.6765\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4843 - accuracy: 0.7539 - f1: 0.6768 - auc: 0.8443 - val_loss: 0.9021 - val_accuracy: 0.6098 - val_f1: 0.6006 - val_auc: 0.6576\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4756 - accuracy: 0.7617 - f1: 0.6841 - auc: 0.8512 - val_loss: 0.6723 - val_accuracy: 0.6563 - val_f1: 0.6139 - val_auc: 0.7202\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4685 - accuracy: 0.7646 - f1: 0.6884 - auc: 0.8558 - val_loss: 0.8152 - val_accuracy: 0.6563 - val_f1: 0.6347 - val_auc: 0.7070\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4662 - accuracy: 0.7674 - f1: 0.6922 - auc: 0.8573 - val_loss: 0.6781 - val_accuracy: 0.6667 - val_f1: 0.6350 - val_auc: 0.7391\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4547 - accuracy: 0.7769 - f1: 0.6978 - auc: 0.8657 - val_loss: 0.7187 - val_accuracy: 0.6925 - val_f1: 0.6577 - val_auc: 0.7493\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4550 - accuracy: 0.7718 - f1: 0.6991 - auc: 0.8644 - val_loss: 0.7293 - val_accuracy: 0.6822 - val_f1: 0.6547 - val_auc: 0.7452\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4367 - accuracy: 0.7881 - f1: 0.7115 - auc: 0.8779 - val_loss: 0.8347 - val_accuracy: 0.6460 - val_f1: 0.6392 - val_auc: 0.7136\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 64.60%\n",
            "F1: 64.65%\n",
            "AUC: 71.36%\n",
            "Loss: 0.83%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 27ms/step - loss: 0.6574 - accuracy: 0.5967 - f1: 0.5324 - auc: 0.6383 - val_loss: 1.0051 - val_accuracy: 0.4599 - val_f1: 0.5145 - val_auc: 0.5499\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5865 - accuracy: 0.6896 - f1: 0.5982 - auc: 0.7552 - val_loss: 0.6740 - val_accuracy: 0.6098 - val_f1: 0.5614 - val_auc: 0.6586\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5660 - accuracy: 0.7034 - f1: 0.6142 - auc: 0.7770 - val_loss: 0.7235 - val_accuracy: 0.5788 - val_f1: 0.5578 - val_auc: 0.6234\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5616 - accuracy: 0.7111 - f1: 0.6200 - auc: 0.7811 - val_loss: 0.7113 - val_accuracy: 0.5866 - val_f1: 0.5552 - val_auc: 0.6197\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5508 - accuracy: 0.7188 - f1: 0.6277 - auc: 0.7916 - val_loss: 0.6668 - val_accuracy: 0.6021 - val_f1: 0.5712 - val_auc: 0.6707\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5419 - accuracy: 0.7254 - f1: 0.6353 - auc: 0.7997 - val_loss: 0.7674 - val_accuracy: 0.5762 - val_f1: 0.5713 - val_auc: 0.6308\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5329 - accuracy: 0.7273 - f1: 0.6410 - auc: 0.8072 - val_loss: 0.6378 - val_accuracy: 0.6563 - val_f1: 0.5995 - val_auc: 0.7203\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5337 - accuracy: 0.7264 - f1: 0.6416 - auc: 0.8062 - val_loss: 0.7403 - val_accuracy: 0.5943 - val_f1: 0.5947 - val_auc: 0.6724\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5223 - accuracy: 0.7351 - f1: 0.6494 - auc: 0.8159 - val_loss: 0.6931 - val_accuracy: 0.6176 - val_f1: 0.5985 - val_auc: 0.6890\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5116 - accuracy: 0.7371 - f1: 0.6563 - auc: 0.8239 - val_loss: 0.7984 - val_accuracy: 0.5917 - val_f1: 0.5890 - val_auc: 0.6534\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5083 - accuracy: 0.7431 - f1: 0.6593 - auc: 0.8270 - val_loss: 0.6563 - val_accuracy: 0.6744 - val_f1: 0.6281 - val_auc: 0.7367\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4955 - accuracy: 0.7497 - f1: 0.6692 - auc: 0.8365 - val_loss: 0.6354 - val_accuracy: 0.6718 - val_f1: 0.6349 - val_auc: 0.7537\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4945 - accuracy: 0.7506 - f1: 0.6705 - auc: 0.8376 - val_loss: 0.7763 - val_accuracy: 0.6382 - val_f1: 0.6203 - val_auc: 0.6967\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4838 - accuracy: 0.7607 - f1: 0.6782 - auc: 0.8458 - val_loss: 0.6207 - val_accuracy: 0.7028 - val_f1: 0.6246 - val_auc: 0.7569\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4762 - accuracy: 0.7632 - f1: 0.6835 - auc: 0.8514 - val_loss: 0.8043 - val_accuracy: 0.6382 - val_f1: 0.6189 - val_auc: 0.6918\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4676 - accuracy: 0.7685 - f1: 0.6891 - auc: 0.8569 - val_loss: 0.7414 - val_accuracy: 0.6563 - val_f1: 0.6267 - val_auc: 0.7126\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4615 - accuracy: 0.7713 - f1: 0.6958 - auc: 0.8613 - val_loss: 0.6940 - val_accuracy: 0.6718 - val_f1: 0.6408 - val_auc: 0.7394\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4518 - accuracy: 0.7810 - f1: 0.7008 - auc: 0.8678 - val_loss: 0.7345 - val_accuracy: 0.6512 - val_f1: 0.6316 - val_auc: 0.7195\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4460 - accuracy: 0.7860 - f1: 0.7065 - auc: 0.8720 - val_loss: 0.7628 - val_accuracy: 0.6641 - val_f1: 0.6402 - val_auc: 0.7223\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4358 - accuracy: 0.7913 - f1: 0.7142 - auc: 0.8786 - val_loss: 0.6843 - val_accuracy: 0.6822 - val_f1: 0.6416 - val_auc: 0.7432\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 68.22%\n",
            "F1: 64.86%\n",
            "AUC: 74.32%\n",
            "Loss: 0.68%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6546 - accuracy: 0.5982 - f1: 0.5341 - auc: 0.6445 - val_loss: 0.8234 - val_accuracy: 0.5478 - val_f1: 0.5420 - val_auc: 0.5787\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5841 - accuracy: 0.6889 - f1: 0.6004 - auc: 0.7575 - val_loss: 0.8872 - val_accuracy: 0.5090 - val_f1: 0.5346 - val_auc: 0.5658\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5673 - accuracy: 0.7049 - f1: 0.6141 - auc: 0.7757 - val_loss: 0.6557 - val_accuracy: 0.6047 - val_f1: 0.5666 - val_auc: 0.6763\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5576 - accuracy: 0.7157 - f1: 0.6220 - auc: 0.7851 - val_loss: 0.7269 - val_accuracy: 0.5762 - val_f1: 0.5599 - val_auc: 0.6236\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5482 - accuracy: 0.7223 - f1: 0.6299 - auc: 0.7942 - val_loss: 0.6086 - val_accuracy: 0.6822 - val_f1: 0.5815 - val_auc: 0.7435\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5475 - accuracy: 0.7191 - f1: 0.6308 - auc: 0.7946 - val_loss: 0.7687 - val_accuracy: 0.5736 - val_f1: 0.5648 - val_auc: 0.6177\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5372 - accuracy: 0.7237 - f1: 0.6384 - auc: 0.8032 - val_loss: 0.6162 - val_accuracy: 0.7003 - val_f1: 0.5723 - val_auc: 0.7404\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5308 - accuracy: 0.7273 - f1: 0.6420 - auc: 0.8084 - val_loss: 0.7421 - val_accuracy: 0.5995 - val_f1: 0.5989 - val_auc: 0.6760\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5228 - accuracy: 0.7287 - f1: 0.6489 - auc: 0.8138 - val_loss: 0.6894 - val_accuracy: 0.5607 - val_f1: 0.5722 - val_auc: 0.6464\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5097 - accuracy: 0.7402 - f1: 0.6588 - auc: 0.8254 - val_loss: 0.6980 - val_accuracy: 0.6279 - val_f1: 0.6002 - val_auc: 0.6903\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5087 - accuracy: 0.7376 - f1: 0.6584 - auc: 0.8255 - val_loss: 0.6170 - val_accuracy: 0.6951 - val_f1: 0.6357 - val_auc: 0.7623\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5000 - accuracy: 0.7444 - f1: 0.6663 - auc: 0.8325 - val_loss: 0.7781 - val_accuracy: 0.6072 - val_f1: 0.5957 - val_auc: 0.6634\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4890 - accuracy: 0.7505 - f1: 0.6729 - auc: 0.8409 - val_loss: 0.8118 - val_accuracy: 0.6072 - val_f1: 0.5989 - val_auc: 0.6650\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4803 - accuracy: 0.7582 - f1: 0.6798 - auc: 0.8477 - val_loss: 0.7739 - val_accuracy: 0.6382 - val_f1: 0.6137 - val_auc: 0.6903\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4751 - accuracy: 0.7593 - f1: 0.6839 - auc: 0.8508 - val_loss: 0.7881 - val_accuracy: 0.6098 - val_f1: 0.6037 - val_auc: 0.6738\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4804 - accuracy: 0.7509 - f1: 0.6814 - auc: 0.8452 - val_loss: 0.6411 - val_accuracy: 0.6899 - val_f1: 0.6161 - val_auc: 0.7451\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4679 - accuracy: 0.7615 - f1: 0.6882 - auc: 0.8554 - val_loss: 0.6704 - val_accuracy: 0.6770 - val_f1: 0.6361 - val_auc: 0.7429\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4544 - accuracy: 0.7720 - f1: 0.6982 - auc: 0.8647 - val_loss: 0.8052 - val_accuracy: 0.6718 - val_f1: 0.6411 - val_auc: 0.7197\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4484 - accuracy: 0.7759 - f1: 0.7027 - auc: 0.8688 - val_loss: 0.9271 - val_accuracy: 0.6021 - val_f1: 0.6095 - val_auc: 0.6703\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4426 - accuracy: 0.7805 - f1: 0.7083 - auc: 0.8725 - val_loss: 0.6558 - val_accuracy: 0.6873 - val_f1: 0.6337 - val_auc: 0.7473\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 68.73%\n",
            "F1: 63.98%\n",
            "AUC: 74.73%\n",
            "Loss: 0.66%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 8s 31ms/step - loss: 0.6690 - accuracy: 0.5835 - f1: 0.5256 - auc: 0.6157 - val_loss: 0.7138 - val_accuracy: 0.5840 - val_f1: 0.5340 - val_auc: 0.5964\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5957 - accuracy: 0.6810 - f1: 0.5901 - auc: 0.7448 - val_loss: 0.7473 - val_accuracy: 0.5762 - val_f1: 0.5472 - val_auc: 0.5986\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5700 - accuracy: 0.7044 - f1: 0.6124 - auc: 0.7727 - val_loss: 0.7722 - val_accuracy: 0.5659 - val_f1: 0.5480 - val_auc: 0.5934\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5629 - accuracy: 0.7083 - f1: 0.6180 - auc: 0.7802 - val_loss: 0.8761 - val_accuracy: 0.5401 - val_f1: 0.5405 - val_auc: 0.5750\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5581 - accuracy: 0.7179 - f1: 0.6236 - auc: 0.7855 - val_loss: 0.7198 - val_accuracy: 0.5711 - val_f1: 0.5665 - val_auc: 0.6392\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5487 - accuracy: 0.7199 - f1: 0.6290 - auc: 0.7936 - val_loss: 0.6531 - val_accuracy: 0.6202 - val_f1: 0.5769 - val_auc: 0.6866\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.5394 - accuracy: 0.7286 - f1: 0.6363 - auc: 0.8017 - val_loss: 0.6746 - val_accuracy: 0.6227 - val_f1: 0.5843 - val_auc: 0.6827\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.5337 - accuracy: 0.7314 - f1: 0.6419 - auc: 0.8072 - val_loss: 0.6510 - val_accuracy: 0.6512 - val_f1: 0.5923 - val_auc: 0.7083\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5209 - accuracy: 0.7363 - f1: 0.6499 - auc: 0.8174 - val_loss: 0.6934 - val_accuracy: 0.6331 - val_f1: 0.6101 - val_auc: 0.7044\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5133 - accuracy: 0.7417 - f1: 0.6564 - auc: 0.8233 - val_loss: 0.9913 - val_accuracy: 0.5426 - val_f1: 0.5574 - val_auc: 0.6029\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5081 - accuracy: 0.7434 - f1: 0.6601 - auc: 0.8274 - val_loss: 0.6931 - val_accuracy: 0.5917 - val_f1: 0.5803 - val_auc: 0.6650\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5040 - accuracy: 0.7449 - f1: 0.6626 - auc: 0.8299 - val_loss: 0.7854 - val_accuracy: 0.6253 - val_f1: 0.6054 - val_auc: 0.6761\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4960 - accuracy: 0.7513 - f1: 0.6697 - auc: 0.8368 - val_loss: 0.7555 - val_accuracy: 0.5969 - val_f1: 0.5928 - val_auc: 0.6651\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4865 - accuracy: 0.7530 - f1: 0.6762 - auc: 0.8434 - val_loss: 0.9551 - val_accuracy: 0.6021 - val_f1: 0.5989 - val_auc: 0.6524\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4759 - accuracy: 0.7632 - f1: 0.6826 - auc: 0.8513 - val_loss: 0.6536 - val_accuracy: 0.6796 - val_f1: 0.6294 - val_auc: 0.7436\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4741 - accuracy: 0.7611 - f1: 0.6860 - auc: 0.8521 - val_loss: 0.7381 - val_accuracy: 0.6512 - val_f1: 0.6213 - val_auc: 0.7077\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4619 - accuracy: 0.7688 - f1: 0.6929 - auc: 0.8601 - val_loss: 0.7236 - val_accuracy: 0.6641 - val_f1: 0.6304 - val_auc: 0.7215\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4607 - accuracy: 0.7707 - f1: 0.6944 - auc: 0.8611 - val_loss: 0.7005 - val_accuracy: 0.6822 - val_f1: 0.6363 - val_auc: 0.7340\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4479 - accuracy: 0.7774 - f1: 0.7033 - auc: 0.8696 - val_loss: 0.8683 - val_accuracy: 0.6227 - val_f1: 0.6229 - val_auc: 0.6904\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4517 - accuracy: 0.7722 - f1: 0.7026 - auc: 0.8665 - val_loss: 0.8160 - val_accuracy: 0.5685 - val_f1: 0.5876 - val_auc: 0.6436\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 56.85%\n",
            "F1: 59.84%\n",
            "AUC: 64.36%\n",
            "Loss: 0.82%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6528 - accuracy: 0.6027 - f1: 0.5356 - auc: 0.6507 - val_loss: 0.6809 - val_accuracy: 0.6176 - val_f1: 0.5549 - val_auc: 0.6558\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5852 - accuracy: 0.6925 - f1: 0.5988 - auc: 0.7564 - val_loss: 0.8080 - val_accuracy: 0.5736 - val_f1: 0.5524 - val_auc: 0.5955\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5684 - accuracy: 0.7053 - f1: 0.6132 - auc: 0.7741 - val_loss: 0.9321 - val_accuracy: 0.5168 - val_f1: 0.5371 - val_auc: 0.5697\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5553 - accuracy: 0.7134 - f1: 0.6245 - auc: 0.7871 - val_loss: 0.6913 - val_accuracy: 0.5814 - val_f1: 0.5615 - val_auc: 0.6431\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5468 - accuracy: 0.7239 - f1: 0.6298 - auc: 0.7954 - val_loss: 0.6232 - val_accuracy: 0.6718 - val_f1: 0.5736 - val_auc: 0.7221\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5415 - accuracy: 0.7254 - f1: 0.6354 - auc: 0.8001 - val_loss: 0.7624 - val_accuracy: 0.5891 - val_f1: 0.5778 - val_auc: 0.6425\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5332 - accuracy: 0.7295 - f1: 0.6407 - auc: 0.8066 - val_loss: 0.6750 - val_accuracy: 0.6357 - val_f1: 0.5917 - val_auc: 0.6899\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5273 - accuracy: 0.7301 - f1: 0.6455 - auc: 0.8116 - val_loss: 0.7912 - val_accuracy: 0.5659 - val_f1: 0.5753 - val_auc: 0.6345\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5185 - accuracy: 0.7363 - f1: 0.6514 - auc: 0.8183 - val_loss: 0.6542 - val_accuracy: 0.6641 - val_f1: 0.6082 - val_auc: 0.7206\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5099 - accuracy: 0.7441 - f1: 0.6584 - auc: 0.8263 - val_loss: 0.7522 - val_accuracy: 0.6331 - val_f1: 0.6233 - val_auc: 0.7040\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5081 - accuracy: 0.7423 - f1: 0.6610 - auc: 0.8269 - val_loss: 0.6881 - val_accuracy: 0.6460 - val_f1: 0.6183 - val_auc: 0.7155\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4949 - accuracy: 0.7519 - f1: 0.6686 - auc: 0.8371 - val_loss: 0.6585 - val_accuracy: 0.6641 - val_f1: 0.6202 - val_auc: 0.7305\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4877 - accuracy: 0.7579 - f1: 0.6747 - auc: 0.8426 - val_loss: 0.6771 - val_accuracy: 0.6744 - val_f1: 0.6323 - val_auc: 0.7361\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4844 - accuracy: 0.7558 - f1: 0.6775 - auc: 0.8437 - val_loss: 0.9439 - val_accuracy: 0.6072 - val_f1: 0.6022 - val_auc: 0.6594\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4742 - accuracy: 0.7622 - f1: 0.6847 - auc: 0.8522 - val_loss: 0.7167 - val_accuracy: 0.6667 - val_f1: 0.6386 - val_auc: 0.7307\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4656 - accuracy: 0.7676 - f1: 0.6913 - auc: 0.8579 - val_loss: 0.6772 - val_accuracy: 0.6873 - val_f1: 0.6543 - val_auc: 0.7559\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4641 - accuracy: 0.7672 - f1: 0.6923 - auc: 0.8589 - val_loss: 0.6297 - val_accuracy: 0.7209 - val_f1: 0.6546 - val_auc: 0.7736\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4597 - accuracy: 0.7730 - f1: 0.6967 - auc: 0.8626 - val_loss: 0.7917 - val_accuracy: 0.6382 - val_f1: 0.6237 - val_auc: 0.6999\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4484 - accuracy: 0.7795 - f1: 0.7023 - auc: 0.8693 - val_loss: 0.9078 - val_accuracy: 0.6563 - val_f1: 0.6406 - val_auc: 0.7055\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4434 - accuracy: 0.7846 - f1: 0.7083 - auc: 0.8726 - val_loss: 0.6496 - val_accuracy: 0.7132 - val_f1: 0.6593 - val_auc: 0.7699\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 71.32%\n",
            "F1: 66.21%\n",
            "AUC: 76.99%\n",
            "Loss: 0.65%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6681 - accuracy: 0.5843 - f1: 0.5274 - auc: 0.6206 - val_loss: 0.8463 - val_accuracy: 0.4599 - val_f1: 0.5130 - val_auc: 0.5456\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5871 - accuracy: 0.6873 - f1: 0.5958 - auc: 0.7536 - val_loss: 0.8880 - val_accuracy: 0.5504 - val_f1: 0.5428 - val_auc: 0.5723\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5706 - accuracy: 0.7038 - f1: 0.6117 - auc: 0.7721 - val_loss: 0.7443 - val_accuracy: 0.5866 - val_f1: 0.5604 - val_auc: 0.6184\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5571 - accuracy: 0.7151 - f1: 0.6228 - auc: 0.7859 - val_loss: 0.7920 - val_accuracy: 0.5607 - val_f1: 0.5538 - val_auc: 0.5992\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5619 - accuracy: 0.7077 - f1: 0.6197 - auc: 0.7806 - val_loss: 0.7719 - val_accuracy: 0.5685 - val_f1: 0.5554 - val_auc: 0.6048\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5442 - accuracy: 0.7226 - f1: 0.6322 - auc: 0.7975 - val_loss: 0.6942 - val_accuracy: 0.5943 - val_f1: 0.5752 - val_auc: 0.6563\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5386 - accuracy: 0.7260 - f1: 0.6376 - auc: 0.8020 - val_loss: 0.6449 - val_accuracy: 0.6176 - val_f1: 0.5626 - val_auc: 0.6825\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5327 - accuracy: 0.7312 - f1: 0.6417 - auc: 0.8074 - val_loss: 0.7798 - val_accuracy: 0.5711 - val_f1: 0.5682 - val_auc: 0.6234\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5263 - accuracy: 0.7320 - f1: 0.6457 - auc: 0.8118 - val_loss: 0.6721 - val_accuracy: 0.6098 - val_f1: 0.5846 - val_auc: 0.6785\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5174 - accuracy: 0.7382 - f1: 0.6523 - auc: 0.8193 - val_loss: 0.8752 - val_accuracy: 0.5814 - val_f1: 0.5829 - val_auc: 0.6362\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5104 - accuracy: 0.7426 - f1: 0.6582 - auc: 0.8254 - val_loss: 0.7078 - val_accuracy: 0.5995 - val_f1: 0.5843 - val_auc: 0.6637\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5028 - accuracy: 0.7441 - f1: 0.6619 - auc: 0.8306 - val_loss: 0.6539 - val_accuracy: 0.6512 - val_f1: 0.6102 - val_auc: 0.7231\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4980 - accuracy: 0.7507 - f1: 0.6666 - auc: 0.8338 - val_loss: 0.7759 - val_accuracy: 0.6408 - val_f1: 0.6186 - val_auc: 0.6953\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4893 - accuracy: 0.7547 - f1: 0.6742 - auc: 0.8411 - val_loss: 0.6944 - val_accuracy: 0.6589 - val_f1: 0.6247 - val_auc: 0.7223\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4782 - accuracy: 0.7615 - f1: 0.6819 - auc: 0.8493 - val_loss: 0.7327 - val_accuracy: 0.6460 - val_f1: 0.6136 - val_auc: 0.6996\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4763 - accuracy: 0.7610 - f1: 0.6829 - auc: 0.8502 - val_loss: 0.7743 - val_accuracy: 0.6357 - val_f1: 0.6222 - val_auc: 0.7003\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4689 - accuracy: 0.7680 - f1: 0.6884 - auc: 0.8554 - val_loss: 0.6455 - val_accuracy: 0.6977 - val_f1: 0.6523 - val_auc: 0.7647\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4636 - accuracy: 0.7701 - f1: 0.6927 - auc: 0.8599 - val_loss: 0.6931 - val_accuracy: 0.6460 - val_f1: 0.6239 - val_auc: 0.7215\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4534 - accuracy: 0.7784 - f1: 0.7000 - auc: 0.8666 - val_loss: 0.8247 - val_accuracy: 0.6021 - val_f1: 0.6126 - val_auc: 0.6822\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4458 - accuracy: 0.7851 - f1: 0.7067 - auc: 0.8719 - val_loss: 0.7033 - val_accuracy: 0.6382 - val_f1: 0.6133 - val_auc: 0.7056\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 63.82%\n",
            "F1: 61.81%\n",
            "AUC: 70.56%\n",
            "Loss: 0.70%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 7s 26ms/step - loss: 0.6572 - accuracy: 0.5890 - f1: 0.5329 - auc: 0.6396 - val_loss: 0.8633 - val_accuracy: 0.5245 - val_f1: 0.5384 - val_auc: 0.5718\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5846 - accuracy: 0.6896 - f1: 0.5994 - auc: 0.7569 - val_loss: 0.8703 - val_accuracy: 0.5271 - val_f1: 0.5399 - val_auc: 0.5719\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5682 - accuracy: 0.7083 - f1: 0.6138 - auc: 0.7749 - val_loss: 0.7464 - val_accuracy: 0.5736 - val_f1: 0.5539 - val_auc: 0.6100\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5552 - accuracy: 0.7196 - f1: 0.6244 - auc: 0.7877 - val_loss: 0.7433 - val_accuracy: 0.5814 - val_f1: 0.5589 - val_auc: 0.6162\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5519 - accuracy: 0.7159 - f1: 0.6269 - auc: 0.7903 - val_loss: 0.8326 - val_accuracy: 0.5452 - val_f1: 0.5482 - val_auc: 0.5870\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5395 - accuracy: 0.7224 - f1: 0.6362 - auc: 0.8018 - val_loss: 0.7330 - val_accuracy: 0.5711 - val_f1: 0.5684 - val_auc: 0.6362\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5305 - accuracy: 0.7306 - f1: 0.6442 - auc: 0.8095 - val_loss: 0.6347 - val_accuracy: 0.6589 - val_f1: 0.5809 - val_auc: 0.7145\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5242 - accuracy: 0.7336 - f1: 0.6469 - auc: 0.8143 - val_loss: 0.7568 - val_accuracy: 0.5995 - val_f1: 0.5820 - val_auc: 0.6491\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5215 - accuracy: 0.7350 - f1: 0.6522 - auc: 0.8170 - val_loss: 0.7352 - val_accuracy: 0.5891 - val_f1: 0.5813 - val_auc: 0.6533\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5173 - accuracy: 0.7352 - f1: 0.6523 - auc: 0.8194 - val_loss: 0.7744 - val_accuracy: 0.5969 - val_f1: 0.5916 - val_auc: 0.6603\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5004 - accuracy: 0.7468 - f1: 0.6646 - auc: 0.8328 - val_loss: 0.6958 - val_accuracy: 0.6408 - val_f1: 0.6039 - val_auc: 0.6970\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.5081 - accuracy: 0.7410 - f1: 0.6611 - auc: 0.8261 - val_loss: 0.6975 - val_accuracy: 0.6589 - val_f1: 0.6183 - val_auc: 0.7131\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 20ms/step - loss: 0.4926 - accuracy: 0.7476 - f1: 0.6709 - auc: 0.8383 - val_loss: 0.6360 - val_accuracy: 0.6899 - val_f1: 0.6381 - val_auc: 0.7540\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4864 - accuracy: 0.7566 - f1: 0.6767 - auc: 0.8435 - val_loss: 0.7537 - val_accuracy: 0.6098 - val_f1: 0.5989 - val_auc: 0.6729\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4769 - accuracy: 0.7637 - f1: 0.6823 - auc: 0.8504 - val_loss: 0.7040 - val_accuracy: 0.6718 - val_f1: 0.6309 - val_auc: 0.7256\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4679 - accuracy: 0.7669 - f1: 0.6896 - auc: 0.8567 - val_loss: 0.7341 - val_accuracy: 0.6202 - val_f1: 0.6059 - val_auc: 0.6895\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4625 - accuracy: 0.7708 - f1: 0.6943 - auc: 0.8610 - val_loss: 0.8198 - val_accuracy: 0.6253 - val_f1: 0.6208 - val_auc: 0.6930\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4565 - accuracy: 0.7729 - f1: 0.6978 - auc: 0.8646 - val_loss: 0.7362 - val_accuracy: 0.6744 - val_f1: 0.6455 - val_auc: 0.7346\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4465 - accuracy: 0.7819 - f1: 0.7062 - auc: 0.8712 - val_loss: 0.7158 - val_accuracy: 0.6641 - val_f1: 0.6279 - val_auc: 0.7235\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4432 - accuracy: 0.7829 - f1: 0.7078 - auc: 0.8733 - val_loss: 0.7667 - val_accuracy: 0.6899 - val_f1: 0.6538 - val_auc: 0.7381\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 68.99%\n",
            "F1: 66.20%\n",
            "AUC: 73.81%\n",
            "Loss: 0.77%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 8s 27ms/step - loss: 0.6542 - accuracy: 0.6011 - f1: 0.5347 - auc: 0.6491 - val_loss: 0.7422 - val_accuracy: 0.5659 - val_f1: 0.5396 - val_auc: 0.5907\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5831 - accuracy: 0.6876 - f1: 0.5999 - auc: 0.7582 - val_loss: 0.7548 - val_accuracy: 0.5866 - val_f1: 0.5574 - val_auc: 0.6131\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5703 - accuracy: 0.7009 - f1: 0.6118 - auc: 0.7723 - val_loss: 0.7473 - val_accuracy: 0.5814 - val_f1: 0.5526 - val_auc: 0.6052\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5550 - accuracy: 0.7144 - f1: 0.6241 - auc: 0.7878 - val_loss: 0.7091 - val_accuracy: 0.5736 - val_f1: 0.5566 - val_auc: 0.6179\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5504 - accuracy: 0.7154 - f1: 0.6281 - auc: 0.7916 - val_loss: 0.7027 - val_accuracy: 0.5891 - val_f1: 0.5815 - val_auc: 0.6630\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5413 - accuracy: 0.7246 - f1: 0.6342 - auc: 0.7996 - val_loss: 0.7564 - val_accuracy: 0.5711 - val_f1: 0.5746 - val_auc: 0.6376\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.5294 - accuracy: 0.7317 - f1: 0.6442 - auc: 0.8098 - val_loss: 0.6426 - val_accuracy: 0.6589 - val_f1: 0.5844 - val_auc: 0.7051\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5317 - accuracy: 0.7278 - f1: 0.6422 - auc: 0.8072 - val_loss: 0.8835 - val_accuracy: 0.5788 - val_f1: 0.5793 - val_auc: 0.6328\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5164 - accuracy: 0.7394 - f1: 0.6530 - auc: 0.8201 - val_loss: 0.6420 - val_accuracy: 0.6615 - val_f1: 0.6036 - val_auc: 0.7247\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5156 - accuracy: 0.7393 - f1: 0.6546 - auc: 0.8211 - val_loss: 0.8049 - val_accuracy: 0.6021 - val_f1: 0.5930 - val_auc: 0.6573\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4999 - accuracy: 0.7516 - f1: 0.6665 - auc: 0.8336 - val_loss: 0.6262 - val_accuracy: 0.6951 - val_f1: 0.6382 - val_auc: 0.7591\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.5053 - accuracy: 0.7458 - f1: 0.6617 - auc: 0.8288 - val_loss: 0.6430 - val_accuracy: 0.6589 - val_f1: 0.6223 - val_auc: 0.7381\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.4977 - accuracy: 0.7492 - f1: 0.6675 - auc: 0.8348 - val_loss: 0.7375 - val_accuracy: 0.6279 - val_f1: 0.6129 - val_auc: 0.6956\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4861 - accuracy: 0.7543 - f1: 0.6758 - auc: 0.8433 - val_loss: 0.7261 - val_accuracy: 0.6667 - val_f1: 0.6318 - val_auc: 0.7197\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.4812 - accuracy: 0.7581 - f1: 0.6799 - auc: 0.8465 - val_loss: 0.7182 - val_accuracy: 0.6848 - val_f1: 0.6360 - val_auc: 0.7266\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4767 - accuracy: 0.7603 - f1: 0.6827 - auc: 0.8498 - val_loss: 1.0757 - val_accuracy: 0.5633 - val_f1: 0.5793 - val_auc: 0.6240\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4737 - accuracy: 0.7637 - f1: 0.6845 - auc: 0.8525 - val_loss: 0.7459 - val_accuracy: 0.6693 - val_f1: 0.6398 - val_auc: 0.7252\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.4623 - accuracy: 0.7718 - f1: 0.6945 - auc: 0.8605 - val_loss: 0.7286 - val_accuracy: 0.6744 - val_f1: 0.6376 - val_auc: 0.7273\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 3s 21ms/step - loss: 0.4577 - accuracy: 0.7798 - f1: 0.6970 - auc: 0.8638 - val_loss: 0.7148 - val_accuracy: 0.7003 - val_f1: 0.6681 - val_auc: 0.7606\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 3s 22ms/step - loss: 0.4444 - accuracy: 0.7852 - f1: 0.7074 - auc: 0.8730 - val_loss: 0.7125 - val_accuracy: 0.6848 - val_f1: 0.6508 - val_auc: 0.7469\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 68.48%\n",
            "F1: 65.43%\n",
            "AUC: 74.69%\n",
            "Loss: 0.71%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT9xDAHIolmD",
        "outputId": "7fd7664c-785d-46e9-bbd3-7fecd706af8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.649603545665741 - Accuracy: 71.3178277015686 - F1: 66.43450856208801 - AUC: 77.4232268333435%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.8680086135864258 - Accuracy: 61.49870753288269 - F1: 63.260167837142944 - AUC: 68.62267851829529%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.8347148299217224 - Accuracy: 64.59948420524597 - F1: 64.65307474136353 - AUC: 71.36189937591553%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.6843291521072388 - Accuracy: 68.2170569896698 - F1: 64.86336588859558 - AUC: 74.3224561214447%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.6557521224021912 - Accuracy: 68.73385310173035 - F1: 63.9815628528595 - AUC: 74.72708225250244%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.8160151243209839 - Accuracy: 56.84754252433777 - F1: 59.83566641807556 - AUC: 64.35978412628174%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.6496459245681763 - Accuracy: 71.3178277015686 - F1: 66.20635390281677 - AUC: 76.9935667514801%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.7033060789108276 - Accuracy: 63.82429003715515 - F1: 61.80880069732666 - AUC: 70.56366801261902%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.7666885256767273 - Accuracy: 68.99224519729614 - F1: 66.19771718978882 - AUC: 73.80933165550232%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.7125092148780823 - Accuracy: 68.47545504570007 - F1: 65.43039083480835 - AUC: 74.69069361686707%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.7340573132038116\n",
            "> Accuracy: 66.38242900371552 (+- 4.396487655296338)\n",
            "> F1: 64.26716089248657 (+- 2.0203882360521472)\n",
            "> AUC: 72.68743872642517 (+- 3.8107098073866377)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}