{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM Trained with a sample of lyrics from each decade**"
      ],
      "metadata": {
        "id": "UcWPmrQYk4i5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQoOE5Ec24L"
      },
      "source": [
        "## **0.File Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMqTVkmgGSk"
      },
      "source": [
        "### **0.1 Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DoSHPrgEfJ",
        "outputId": "bc770534-9006-4895-982f-272f48775d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laserembeddings\n",
            "  Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting transliterate==1.10.2\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.21.6)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=83c3934bc5b66db8530bec31c3ad57a454dfcc9d2bf937495e1899ed0bcda52b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: mock, transliterate, subword-nmt, sacremoses, laserembeddings\n",
            "Successfully installed laserembeddings-1.1.2 mock-4.0.3 sacremoses-0.0.35 subword-nmt-0.3.8 transliterate-1.10.2\n",
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ]
        }
      ],
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzrJE1c_gP0i"
      },
      "source": [
        "### **0.2 Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-k-wVfCdBlc",
        "outputId": "b4465150-22c7-416c-ab8d-2c219541e2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "\n",
        "#Shell command\n",
        "from IPython.display import JSON\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "#Text Processing\n",
        "import string\n",
        "import re\n",
        "\n",
        "#Modeling\n",
        "#from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Reshaping datasets to tensors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "#for Colab file dealing\n",
        "import glob\n",
        "#You can mount your Google Drive files by running the following code snippet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # Now all files in: /content/gdrive/My Drive/location_of_the_file\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnKduo33J5RC"
      },
      "outputs": [],
      "source": [
        "#Laser\n",
        "from laserembeddings import Laser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0JtAv0glFX"
      },
      "source": [
        "### **0.3 Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.1 For Text Processing**"
      ],
      "metadata": {
        "id": "D8T-f4KllIh7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C8ayV2QpLmq"
      },
      "outputs": [],
      "source": [
        "def lyrics_preprocessing(text_data):\n",
        "\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "      text = re.sub('\\[', '', text)\n",
        "      text = re.sub('\\]', '', text)\n",
        "      text = re.sub('\\_', ' ', text) # _\n",
        "      text = re.sub('\\!', ' ', text) # !\n",
        "      text = re.sub('\\?', ' ', text) # ?\n",
        "      text = re.sub('\\-', ' ', text) # -\n",
        "      text = re.sub(\"[\\[].*?\\]\", \"\", text)#delete everything between square brackets\n",
        "      \n",
        "      text = re.sub(\"EmbedShare URLCopyEmbedCopy\", '', text) #NOOO VA??????\n",
        "      text = re.sub(\"EmbedShareURLCopyEmbedCopy\", '', text) \n",
        "\n",
        "      preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8tmtMayqQK"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_preprocessed (Files, mypath, df):\n",
        "  #paragraphs \n",
        "  titles = []\n",
        "  paragraphs = []\n",
        "  for i in range(len(Files)):\n",
        "    f = open(mypath+'/'+Files[i], 'r')\n",
        "\n",
        "    data = f.read()\n",
        "    data_splited = data.split(\"\\n\\n\")\n",
        "    \n",
        "\n",
        "    for j in data_splited:\n",
        "      titles.append(Files[i])\n",
        "      unwanted = j.split(\"\\n\")\n",
        "      wanted = []\n",
        "      \n",
        "      if '[' in unwanted[0]:\n",
        "        wanted = unwanted[1:]\n",
        "        j = \"\\n\".join(wanted)\n",
        "\n",
        "      paragraphs.append(j)\n",
        "\n",
        "  df['title'] = titles\n",
        "  df['paragraph'] = paragraphs\n",
        "  \n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.2 For Model Evaluation**"
      ],
      "metadata": {
        "id": "-NwFoR7xlRwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 evaluation\n",
        "def f1(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"
      ],
      "metadata": {
        "id": "ky2zTKlflSUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.3 For Labeling**"
      ],
      "metadata": {
        "id": "NecwZOArlX4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def labeling (l_embeddings, df):\n",
        "  Xnew = tf.reshape(l_embeddings, [-1, 1, 1024])\n",
        "\n",
        "  probs=model.predict(Xnew) \n",
        "  #The first value of the prediction is for class 0 and the second for class 1 \n",
        "\n",
        "\n",
        "  ynew = []\n",
        "  probabilities = []\n",
        "  psxist = []\n",
        "  p_not_sxist = []\n",
        "  c=0\n",
        "  for item in probs:\n",
        "    if item[0][0]>item[0][1]:\n",
        "      y = 0\n",
        "      probability = item[0][0]  \n",
        "    else:\n",
        "      y = 1\n",
        "      probability = item[0][1]\n",
        "    p_not_sxist = np.append(p_not_sxist, item[0][0])\n",
        "    psxist = np.append(psxist, item[0][1])\n",
        "    c+=1\n",
        "    ynew = np.append(ynew, y)\n",
        "    probabilities = np.append(probabilities, probability)\n",
        "\n",
        "  df['sexist_label'] = ynew.astype('int')\n",
        "  df['sexist_label probability'] = probabilities\n",
        "  df['probability_sexist'] = psxist\n",
        "  df['probability_NOT_sexist'] = p_not_sxist\n",
        "  \n",
        "  df = df.sort_values('probability_sexist', ascending=False)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "YjLfTrSClZW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1t9ZT8Zc8Kg"
      },
      "source": [
        "## **1. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3S3-7TQly-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "ea0412b7-346c-41af-90b7-79470b498bdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0                 lyricstxtBailemos_Dani Fernandez.txt   \n",
              "1    lyricstxtNathy Peluso Bzrp Music Sessions Vol....   \n",
              "2                       lyricstxtSafaera_Bad Bunny.txt   \n",
              "3                           lyricstxtIndeciso_Reik.txt   \n",
              "5                  lyricstxtLa Jeepeta _Nio Garcia.txt   \n",
              "..                                                 ...   \n",
              "760             lyricstxtbailamos_enrique iglesias.txt   \n",
              "761  lyricstxtanybody seen my baby_The rolling ston...   \n",
              "762                      lyricstxtCalma _Pedro Cap.txt   \n",
              "763    lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt   \n",
              "764                   lyricstxtHyper hyper_Scooter.txt   \n",
              "\n",
              "                                             paragraph  label  \\\n",
              "0    Bailaremos\\nBailaremos\\nBailemos\\nBailemos\\nBa...    1.0   \n",
              "1    Motherfuckin' ladies dancin'\\nMotherfu-Motherf...    1.0   \n",
              "2    Bla, bla, bla, bla, bla, bla\\nEy, yo', yo', yo...    1.0   \n",
              "3    Victoria ella no es un secreto\\nQue tú a mí me...    1.0   \n",
              "5    Arrebata'o, dando vuelta en la jeepeta (Dando ...    1.0   \n",
              "..                                                 ...    ...   \n",
              "760  Don't let the world in outside\\nDon't let a mo...    0.0   \n",
              "761  We came to rock for Brooklyn\\nAnd Queens\\nAnd ...    0.0   \n",
              "762  Desde la isla del encanto\\nFarru lanzai Pedro ...    0.0   \n",
              "763  Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...    0.0   \n",
              "764  We want to sing a big shout to U.S. and to all...    0.0   \n",
              "\n",
              "     true_label (0,1 or NA) racialized_person (0,1 or NA)  \\\n",
              "0                         0                             0   \n",
              "1                         1                             0   \n",
              "2                         0                             0   \n",
              "3                         1                             0   \n",
              "5                         1                             1   \n",
              "..                      ...                           ...   \n",
              "760                       0                             0   \n",
              "761                       0                             0   \n",
              "762                       0                             0   \n",
              "763                       0                             0   \n",
              "764                       0                             0   \n",
              "\n",
              "                              Reason      label probability  \\\n",
              "0                                NaN  9.897.588.491.439.810   \n",
              "1                 motherhood-related  9.618.873.596.191.400   \n",
              "2                                NaN  9.564.121.961.593.620   \n",
              "3                 hypersexualization  9.481.527.805.328.360   \n",
              "5    body shaming, sexual harassment  9.465.652.704.238.890   \n",
              "..                               ...                    ...   \n",
              "760                              NaN    998.933.732.509.613   \n",
              "761                              NaN  9.989.345.669.746.390   \n",
              "762                              NaN  9.989.352.822.303.770   \n",
              "763                              NaN  9.989.357.590.675.350   \n",
              "764                              NaN  9.989.377.856.254.570   \n",
              "\n",
              "         probability_sexist  probability_NOT_sexist  \n",
              "0     9.897.588.491.439.810  11.161.846.108.734.600  \n",
              "1     9.618.873.596.191.400   3.857.753.425.836.560  \n",
              "2     9.564.121.961.593.620   4.455.895.721.912.380  \n",
              "3     9.481.527.805.328.360   5.226.750.299.334.520  \n",
              "5     9.465.652.704.238.890  54.083.433.002.233.500  \n",
              "..                      ...                     ...  \n",
              "760  11.397.618.800.401.600     998.933.732.509.613  \n",
              "761  11.381.290.387.362.200   9.989.345.669.746.390  \n",
              "762  11.362.035.293.132.000   9.989.352.822.303.770  \n",
              "763   1.135.141.239.501.530   9.989.357.590.675.350  \n",
              "764  11.311.753.187.328.500   9.989.377.856.254.570  \n",
              "\n",
              "[1665 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2841c06-fc99-4559-9978-4d9856c39c09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>true_label (0,1 or NA)</th>\n",
              "      <th>racialized_person (0,1 or NA)</th>\n",
              "      <th>Reason</th>\n",
              "      <th>label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtBailemos_Dani Fernandez.txt</td>\n",
              "      <td>Bailaremos\\nBailaremos\\nBailemos\\nBailemos\\nBa...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.897.588.491.439.810</td>\n",
              "      <td>9.897.588.491.439.810</td>\n",
              "      <td>11.161.846.108.734.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtNathy Peluso Bzrp Music Sessions Vol....</td>\n",
              "      <td>Motherfuckin' ladies dancin'\\nMotherfu-Motherf...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>motherhood-related</td>\n",
              "      <td>9.618.873.596.191.400</td>\n",
              "      <td>9.618.873.596.191.400</td>\n",
              "      <td>3.857.753.425.836.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtSafaera_Bad Bunny.txt</td>\n",
              "      <td>Bla, bla, bla, bla, bla, bla\\nEy, yo', yo', yo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.564.121.961.593.620</td>\n",
              "      <td>9.564.121.961.593.620</td>\n",
              "      <td>4.455.895.721.912.380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtIndeciso_Reik.txt</td>\n",
              "      <td>Victoria ella no es un secreto\\nQue tú a mí me...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>hypersexualization</td>\n",
              "      <td>9.481.527.805.328.360</td>\n",
              "      <td>9.481.527.805.328.360</td>\n",
              "      <td>5.226.750.299.334.520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lyricstxtLa Jeepeta _Nio Garcia.txt</td>\n",
              "      <td>Arrebata'o, dando vuelta en la jeepeta (Dando ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>body shaming, sexual harassment</td>\n",
              "      <td>9.465.652.704.238.890</td>\n",
              "      <td>9.465.652.704.238.890</td>\n",
              "      <td>54.083.433.002.233.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>lyricstxtbailamos_enrique iglesias.txt</td>\n",
              "      <td>Don't let the world in outside\\nDon't let a mo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "      <td>11.397.618.800.401.600</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>lyricstxtanybody seen my baby_The rolling ston...</td>\n",
              "      <td>We came to rock for Brooklyn\\nAnd Queens\\nAnd ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "      <td>11.381.290.387.362.200</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>lyricstxtCalma _Pedro Cap.txt</td>\n",
              "      <td>Desde la isla del encanto\\nFarru lanzai Pedro ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "      <td>11.362.035.293.132.000</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt</td>\n",
              "      <td>Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "      <td>1.135.141.239.501.530</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>lyricstxtHyper hyper_Scooter.txt</td>\n",
              "      <td>We want to sing a big shout to U.S. and to all...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "      <td>11.311.753.187.328.500</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1665 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2841c06-fc99-4559-9978-4d9856c39c09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2841c06-fc99-4559-9978-4d9856c39c09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2841c06-fc99-4559-9978-4d9856c39c09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Pharagraphs to train and test \n",
        "labeled_2021 = '/content/gdrive/My Drive/predicted_2021.csv'\n",
        "labeled_60s = '/content/gdrive/My Drive/predicted_60s.csv' \n",
        "labeled_round2 = '/content/gdrive/My Drive/lyrics_Predicted_Round2.csv'\n",
        "\n",
        "l2021_df = pd.read_csv(labeled_2021)\n",
        "l60s_df = pd.read_csv(labeled_60s)\n",
        "lround2 = pd.read_csv(labeled_round2)\n",
        "lround2 = lround2.drop(columns=['decade'])\n",
        "\n",
        "#dataframe to be used\n",
        "tdf = pd.concat([l2021_df, l60s_df, lround2])\n",
        "tdf = tdf.dropna(subset=['true_label (0,1 or NA)'])\n",
        "tdf = tdf.replace([1.0, 0.0],[1,0])\n",
        "tdf = tdf[(tdf['true_label (0,1 or NA)'] != 'NAP')]\n",
        "pd.to_numeric(tdf['true_label (0,1 or NA)'], downcast = 'integer')\n",
        "tdf['true_label (0,1 or NA)']= pd.to_numeric(tdf['true_label (0,1 or NA)'])\n",
        "tdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KzVf7_Qzf1_I",
        "outputId": "66294e7f-2cdb-430a-a07b-d422d80282c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0               lyricstxtElla No Es Tuya _Rochy RD.txt   \n",
              "1               lyricstxtElla No Es Tuya _Rochy RD.txt   \n",
              "2                        lyricstxtAmanece_Anuel AA.txt   \n",
              "3                         lyricstxtMorado_J Balvin.txt   \n",
              "4                         lyricstxtMorado_J Balvin.txt   \n",
              "..                                                 ...   \n",
              "760             lyricstxtbailamos_enrique iglesias.txt   \n",
              "761  lyricstxtanybody seen my baby_The rolling ston...   \n",
              "762                      lyricstxtCalma _Pedro Cap.txt   \n",
              "763    lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt   \n",
              "764                   lyricstxtHyper hyper_Scooter.txt   \n",
              "\n",
              "                                             paragraph  label  \\\n",
              "0    Ella no e' tuya, te vendió sueño (Sí, porque c...    1.0   \n",
              "1    Ella no e' tuya, te vendió sueño\\nDice que no ...    1.0   \n",
              "2    Y como Karol G en mi cama (Cama)\\nComo Becky G...    1.0   \n",
              "3    Yo pedí un trago y ella la botella (Uh, uh, uh...    1.0   \n",
              "4    Yo pedí un trago y ella la botella (Ah-ah)\\nAb...    1.0   \n",
              "..                                                 ...    ...   \n",
              "760  Don't let the world in outside\\nDon't let a mo...    0.0   \n",
              "761  We came to rock for Brooklyn\\nAnd Queens\\nAnd ...    0.0   \n",
              "762  Desde la isla del encanto\\nFarru lanzai Pedro ...    0.0   \n",
              "763  Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...    0.0   \n",
              "764  We want to sing a big shout to U.S. and to all...    0.0   \n",
              "\n",
              "     true_label (0,1 or NA)  racialized_person (0,1 or NA)  \\\n",
              "0                       1.0                            0.0   \n",
              "1                       1.0                            0.0   \n",
              "2                       1.0                            0.0   \n",
              "3                       1.0                            0.0   \n",
              "4                       1.0                            0.0   \n",
              "..                      ...                            ...   \n",
              "760                     0.0                            0.0   \n",
              "761                     0.0                            0.0   \n",
              "762                     0.0                            0.0   \n",
              "763                     0.0                            0.0   \n",
              "764                     0.0                            0.0   \n",
              "\n",
              "                                                Reason      label probability  \\\n",
              "0                               attribute stereotyoing    995.332.658.290.863   \n",
              "1                               attribute stereotyoing  9.952.580.332.756.040   \n",
              "2    hypersexualization, paternalism, attribute ste...  9.944.848.418.235.770   \n",
              "3                                       victim blaming    993.961.751.461.029   \n",
              "4                                       victim blaming  9.939.129.948.616.020   \n",
              "..                                                 ...                    ...   \n",
              "760                                                NaN    998.933.732.509.613   \n",
              "761                                                NaN  9.989.345.669.746.390   \n",
              "762                                                NaN  9.989.352.822.303.770   \n",
              "763                                                NaN  9.989.357.590.675.350   \n",
              "764                                                NaN  9.989.377.856.254.570   \n",
              "\n",
              "         probability_sexist probability_NOT_sexist  \n",
              "0       995.332.658.290.863    479.504.419.490.695  \n",
              "1     9.952.580.332.756.040  4.873.421.508.818.860  \n",
              "2     9.944.848.418.235.770  5.661.717.616.021.630  \n",
              "3       993.961.751.461.029  6.203.438.155.353.060  \n",
              "4     9.939.129.948.616.020  6.251.112.557.947.630  \n",
              "..                      ...                    ...  \n",
              "760  11.397.618.800.401.600    998.933.732.509.613  \n",
              "761  11.381.290.387.362.200  9.989.345.669.746.390  \n",
              "762  11.362.035.293.132.000  9.989.352.822.303.770  \n",
              "763   1.135.141.239.501.530  9.989.357.590.675.350  \n",
              "764  11.311.753.187.328.500  9.989.377.856.254.570  \n",
              "\n",
              "[635 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76f0b651-3b20-42c0-b87e-03c9e2413633\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>true_label (0,1 or NA)</th>\n",
              "      <th>racialized_person (0,1 or NA)</th>\n",
              "      <th>Reason</th>\n",
              "      <th>label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtElla No Es Tuya _Rochy RD.txt</td>\n",
              "      <td>Ella no e' tuya, te vendió sueño (Sí, porque c...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>attribute stereotyoing</td>\n",
              "      <td>995.332.658.290.863</td>\n",
              "      <td>995.332.658.290.863</td>\n",
              "      <td>479.504.419.490.695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtElla No Es Tuya _Rochy RD.txt</td>\n",
              "      <td>Ella no e' tuya, te vendió sueño\\nDice que no ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>attribute stereotyoing</td>\n",
              "      <td>9.952.580.332.756.040</td>\n",
              "      <td>9.952.580.332.756.040</td>\n",
              "      <td>4.873.421.508.818.860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtAmanece_Anuel AA.txt</td>\n",
              "      <td>Y como Karol G en mi cama (Cama)\\nComo Becky G...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>hypersexualization, paternalism, attribute ste...</td>\n",
              "      <td>9.944.848.418.235.770</td>\n",
              "      <td>9.944.848.418.235.770</td>\n",
              "      <td>5.661.717.616.021.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtMorado_J Balvin.txt</td>\n",
              "      <td>Yo pedí un trago y ella la botella (Uh, uh, uh...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>victim blaming</td>\n",
              "      <td>993.961.751.461.029</td>\n",
              "      <td>993.961.751.461.029</td>\n",
              "      <td>6.203.438.155.353.060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxtMorado_J Balvin.txt</td>\n",
              "      <td>Yo pedí un trago y ella la botella (Ah-ah)\\nAb...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>victim blaming</td>\n",
              "      <td>9.939.129.948.616.020</td>\n",
              "      <td>9.939.129.948.616.020</td>\n",
              "      <td>6.251.112.557.947.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>lyricstxtbailamos_enrique iglesias.txt</td>\n",
              "      <td>Don't let the world in outside\\nDon't let a mo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "      <td>11.397.618.800.401.600</td>\n",
              "      <td>998.933.732.509.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>lyricstxtanybody seen my baby_The rolling ston...</td>\n",
              "      <td>We came to rock for Brooklyn\\nAnd Queens\\nAnd ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "      <td>11.381.290.387.362.200</td>\n",
              "      <td>9.989.345.669.746.390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>lyricstxtCalma _Pedro Cap.txt</td>\n",
              "      <td>Desde la isla del encanto\\nFarru lanzai Pedro ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "      <td>11.362.035.293.132.000</td>\n",
              "      <td>9.989.352.822.303.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>lyricstxtUptown Funk_Mark Ronson Bruno Mars.txt</td>\n",
              "      <td>Doh\\nDoh-doh-doh, doh-doh-doh, doh-doh\\nDoh-do...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "      <td>1.135.141.239.501.530</td>\n",
              "      <td>9.989.357.590.675.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>lyricstxtHyper hyper_Scooter.txt</td>\n",
              "      <td>We want to sing a big shout to U.S. and to all...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "      <td>11.311.753.187.328.500</td>\n",
              "      <td>9.989.377.856.254.570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>635 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76f0b651-3b20-42c0-b87e-03c9e2413633')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76f0b651-3b20-42c0-b87e-03c9e2413633 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76f0b651-3b20-42c0-b87e-03c9e2413633');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#training = \"C:/Users/Lau/Desktop/TFG/LYRICS_TFG/training_dataset.csv\"\n",
        "training_df = lround2.copy()\n",
        "training_df = training_df.dropna(subset=['true_label (0,1 or NA)'])\n",
        "training_df = training_df.replace([1.0, 0.0],[1,0])\n",
        "pd.to_numeric(training_df['true_label (0,1 or NA)'], downcast = 'integer')\n",
        "training_df['true_label (0,1 or NA)']= pd.to_numeric(training_df['true_label (0,1 or NA)'])\n",
        "training_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-9eFc_df5Un"
      },
      "source": [
        "## **2. Lyrics to be Labeled**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Lyrics to be labeled \n",
        "mypath60s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1960-1969'\n",
        "mypath70s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1970-1979'\n",
        "mypath80s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1980-1989'\n",
        "mypath90s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1990-1999'\n",
        "mypath00s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2000-2009'\n",
        "mypath10s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2010-2019'\n",
        "mypath20s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2020-2021'\n",
        "\n",
        "mypaths = [mypath60s, mypath70s, mypath80s, mypath90s, mypath00s, mypath10s, mypath20s]\n",
        "\n",
        "Files60s = [f for f in listdir(mypath60s) if isfile(join(mypath60s, f))]\n",
        "Files70s = [f for f in listdir(mypath70s) if isfile(join(mypath70s, f))]\n",
        "Files80s = [f for f in listdir(mypath80s) if isfile(join(mypath80s, f))]\n",
        "Files90s = [f for f in listdir(mypath90s) if isfile(join(mypath90s, f))]\n",
        "Files00s = [f for f in listdir(mypath00s) if isfile(join(mypath00s, f))]\n",
        "Files10s = [f for f in listdir(mypath10s) if isfile(join(mypath10s, f))]\n",
        "Files20s = [f for f in listdir(mypath20s) if isfile(join(mypath20s, f))]\n",
        "\n",
        "#Eliminate songs that are already labeled\n",
        "titles = tdf['title'].tolist()\n",
        "\n",
        "def del_labeled(list_files, list_titles):\n",
        "  for fl in list_files:\n",
        "    if fl in list_titles:\n",
        "      list_files.remove(fl)\n",
        "  return list_files\n",
        "\n",
        "Files = [Files60s, Files70s, Files80s, Files90s, Files00s, Files10s, Files20s]\n",
        "for i in Files: \n",
        "  i = del_labeled(i, titles)\n",
        "\n",
        "\n",
        "\n",
        "cols=['title', 'paragraph', 'label']\n",
        "lyfinal_df = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "i = 0\n",
        "lyrics_df_list = []\n",
        "for path in mypaths: \n",
        "  new_ly_df = pd.DataFrame(columns=cols)\n",
        "  ldf = get_paragraphs_preprocessed(Files[i], path, new_ly_df)\n",
        "  lyrics_df_list.append(ldf)\n",
        "  i+=1\n",
        "\n",
        "lyfinal_df = pd.concat(lyrics_df_list)\"\"\"\n",
        "\n",
        "\n",
        "lyfinal_df = pd.read_csv('/content/gdrive/My Drive/DEF_labeled_df.csv')\n",
        "lyfinal_df = lyfinal_df.drop(columns=['Unnamed: 0', 'sexist_label probability', 'racialized_label',\t'probability_sexist', 'probability_NOT_sexist'])\n",
        "lyfinal_df['sexist_label'] = ''\n",
        "lyfinal_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "FZHXK5UWlhRT",
        "outputId": "e8853b21-6c35-4bed-dbbb-f2efcb2b373d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0            lyricstxtCant Feel My Face_The Weeknd.txt   \n",
              "1                    lyricstxtgrande_paolo vallesi.txt   \n",
              "2                    lyricstxtScatman_Scatman john.txt   \n",
              "3         lyricstxtDont Wanna Go Home_Jason Derulo.txt   \n",
              "4                  lyricstxtCon Calma_Daddy Yankee.txt   \n",
              "...                                                ...   \n",
              "17402                 lyricstxtCorazon de neon_OMD.txt   \n",
              "17403         lyricstxtHave you seen her_MC hammer.txt   \n",
              "17404            lyricstxtHappy _Pharrell Williams.txt   \n",
              "17405                      lyricstxtMagic_Coldplay.txt   \n",
              "17406  lyricstxtwhy cant we be friends_smash mouth.txt   \n",
              "\n",
              "                                               paragraph sexist_label  \\\n",
              "0      I can't feel my face when I'm with you (I can'...                \n",
              "1      Paolo: Yo soy quien, se dormía en las clases d...                \n",
              "2      I'm the Scatman\\nSki-bi dibby dib yo da dub du...                \n",
              "3      I just met this sexy Haitian girl moving like ...                \n",
              "4      Con calma, yo quiero ver como ella lo menea (C...                \n",
              "...                                                  ...          ...   \n",
              "17402  Barcelona, Moscú, Casablanca\\nBruselas, Madrid...                \n",
              "17403  I see her face and I can't let go\\nShe's in my...                \n",
              "17404  (Because I'm happy)\\nClap along if you feel li...                \n",
              "17405  And I don't, and I don't, and I don't, and I d...                \n",
              "17406  Why can't we be friends\\nWhy can't we be frien...                \n",
              "\n",
              "       label_racialized  label_racialized probability  probability_racialized  \\\n",
              "0                     0                      0.569428                0.392769   \n",
              "1                     1                      0.498606                0.498606   \n",
              "2                     0                      0.754303                0.199873   \n",
              "3                     0                      0.733986                0.215519   \n",
              "4                     0                      0.713123                0.232265   \n",
              "...                 ...                           ...                     ...   \n",
              "17402                 0                      0.643671                0.294289   \n",
              "17403                 0                      0.705960                0.243503   \n",
              "17404                 0                      0.744704                0.211503   \n",
              "17405                 0                      0.747309                0.207083   \n",
              "17406                 0                      0.992321                0.006198   \n",
              "\n",
              "       probability_NOT_racialised  \n",
              "0                        0.569428  \n",
              "1                        0.450495  \n",
              "2                        0.754303  \n",
              "3                        0.733986  \n",
              "4                        0.713123  \n",
              "...                           ...  \n",
              "17402                    0.643671  \n",
              "17403                    0.705960  \n",
              "17404                    0.744704  \n",
              "17405                    0.747309  \n",
              "17406                    0.992321  \n",
              "\n",
              "[17407 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e53a29b2-80d3-40a0-8866-230cefe4b00e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>sexist_label</th>\n",
              "      <th>label_racialized</th>\n",
              "      <th>label_racialized probability</th>\n",
              "      <th>probability_racialized</th>\n",
              "      <th>probability_NOT_racialised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtCant Feel My Face_The Weeknd.txt</td>\n",
              "      <td>I can't feel my face when I'm with you (I can'...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.569428</td>\n",
              "      <td>0.392769</td>\n",
              "      <td>0.569428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtgrande_paolo vallesi.txt</td>\n",
              "      <td>Paolo: Yo soy quien, se dormía en las clases d...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0.498606</td>\n",
              "      <td>0.498606</td>\n",
              "      <td>0.450495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtScatman_Scatman john.txt</td>\n",
              "      <td>I'm the Scatman\\nSki-bi dibby dib yo da dub du...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.754303</td>\n",
              "      <td>0.199873</td>\n",
              "      <td>0.754303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtDont Wanna Go Home_Jason Derulo.txt</td>\n",
              "      <td>I just met this sexy Haitian girl moving like ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.733986</td>\n",
              "      <td>0.215519</td>\n",
              "      <td>0.733986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxtCon Calma_Daddy Yankee.txt</td>\n",
              "      <td>Con calma, yo quiero ver como ella lo menea (C...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.713123</td>\n",
              "      <td>0.232265</td>\n",
              "      <td>0.713123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17402</th>\n",
              "      <td>lyricstxtCorazon de neon_OMD.txt</td>\n",
              "      <td>Barcelona, Moscú, Casablanca\\nBruselas, Madrid...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.643671</td>\n",
              "      <td>0.294289</td>\n",
              "      <td>0.643671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17403</th>\n",
              "      <td>lyricstxtHave you seen her_MC hammer.txt</td>\n",
              "      <td>I see her face and I can't let go\\nShe's in my...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.705960</td>\n",
              "      <td>0.243503</td>\n",
              "      <td>0.705960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17404</th>\n",
              "      <td>lyricstxtHappy _Pharrell Williams.txt</td>\n",
              "      <td>(Because I'm happy)\\nClap along if you feel li...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.744704</td>\n",
              "      <td>0.211503</td>\n",
              "      <td>0.744704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17405</th>\n",
              "      <td>lyricstxtMagic_Coldplay.txt</td>\n",
              "      <td>And I don't, and I don't, and I don't, and I d...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.747309</td>\n",
              "      <td>0.207083</td>\n",
              "      <td>0.747309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17406</th>\n",
              "      <td>lyricstxtwhy cant we be friends_smash mouth.txt</td>\n",
              "      <td>Why can't we be friends\\nWhy can't we be frien...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.992321</td>\n",
              "      <td>0.006198</td>\n",
              "      <td>0.992321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17407 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e53a29b2-80d3-40a0-8866-230cefe4b00e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e53a29b2-80d3-40a0-8866-230cefe4b00e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e53a29b2-80d3-40a0-8866-230cefe4b00e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M627jdgcxIO"
      },
      "source": [
        "## **3. LSTM Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5jif2KuyI91"
      },
      "source": [
        "### **3.1 Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7c-p3iRrAte"
      },
      "outputs": [],
      "source": [
        "laser = Laser() # importing class for using embeddings extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2vuBSB6ydO2"
      },
      "outputs": [],
      "source": [
        "#processed dataframe\n",
        "X_tobe_processed = tdf['paragraph']\n",
        "\n",
        "X_processed = lyrics_preprocessing(X_tobe_processed)\n",
        "X_embeddings = laser.embed_sentences(X_processed, lang = 'es')\n",
        "\n",
        "y = tdf['true_label (0,1 or NA)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjlqlw3ffEib"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lyfinal_df['paragraph'] = lyfinal_df['paragraph'].astype(str)\n",
        "lyrics_processed = lyrics_preprocessing(lyfinal_df['paragraph'])\n",
        "lyrics_embeddings = laser.embed_sentences(lyrics_processed, lang = 'es')"
      ],
      "metadata": {
        "id": "E2Oo-0NB8gmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtgGcWYsyPFl"
      },
      "source": [
        "### **3.2 Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Oh78kMTEVME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c0f08a-8923-4fe8-afb2-da3bb4459306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (1115, 1, 1024) (1115, 1, 2)\n",
            "Test data shapes: (550, 1, 1024) (550, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 5s 124ms/step - loss: 0.7729 - accuracy: 0.4350 - f1: 0.5216 - auc: 0.3945 - val_loss: 0.6202 - val_accuracy: 0.7036 - val_f1: 0.5734 - val_auc: 0.6520\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6464 - accuracy: 0.6762 - f1: 0.5721 - auc: 0.6541 - val_loss: 0.6075 - val_accuracy: 0.7036 - val_f1: 0.5818 - val_auc: 0.7490\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6225 - accuracy: 0.6762 - f1: 0.5715 - auc: 0.7448 - val_loss: 0.5969 - val_accuracy: 0.7036 - val_f1: 0.5805 - val_auc: 0.8237\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6012 - accuracy: 0.6762 - f1: 0.5775 - auc: 0.8226 - val_loss: 0.5640 - val_accuracy: 0.7036 - val_f1: 0.5994 - val_auc: 0.8487\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5381 - accuracy: 0.6762 - f1: 0.6173 - auc: 0.8408 - val_loss: 0.4879 - val_accuracy: 0.7036 - val_f1: 0.6697 - val_auc: 0.8515\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4433 - accuracy: 0.8045 - f1: 0.6914 - auc: 0.8854 - val_loss: 0.4284 - val_accuracy: 0.8382 - val_f1: 0.7375 - val_auc: 0.8857\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3604 - accuracy: 0.8664 - f1: 0.7515 - auc: 0.9218 - val_loss: 0.4067 - val_accuracy: 0.8527 - val_f1: 0.7828 - val_auc: 0.8998\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3239 - accuracy: 0.8691 - f1: 0.8070 - auc: 0.9351 - val_loss: 0.3759 - val_accuracy: 0.8600 - val_f1: 0.7935 - val_auc: 0.9116\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2808 - accuracy: 0.8897 - f1: 0.8306 - auc: 0.9524 - val_loss: 0.3633 - val_accuracy: 0.8582 - val_f1: 0.8009 - val_auc: 0.9185\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2456 - accuracy: 0.9058 - f1: 0.8457 - auc: 0.9633 - val_loss: 0.3585 - val_accuracy: 0.8636 - val_f1: 0.8095 - val_auc: 0.9219\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2391 - accuracy: 0.9112 - f1: 0.8563 - auc: 0.9650 - val_loss: 0.3687 - val_accuracy: 0.8636 - val_f1: 0.8165 - val_auc: 0.9205\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2079 - accuracy: 0.9291 - f1: 0.8735 - auc: 0.9727 - val_loss: 0.3695 - val_accuracy: 0.8545 - val_f1: 0.8178 - val_auc: 0.9237\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1761 - accuracy: 0.9363 - f1: 0.8888 - auc: 0.9803 - val_loss: 0.3909 - val_accuracy: 0.8491 - val_f1: 0.8178 - val_auc: 0.9214\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1544 - accuracy: 0.9489 - f1: 0.9019 - auc: 0.9838 - val_loss: 0.3920 - val_accuracy: 0.8655 - val_f1: 0.8349 - val_auc: 0.9239\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1482 - accuracy: 0.9498 - f1: 0.9113 - auc: 0.9848 - val_loss: 0.4775 - val_accuracy: 0.8091 - val_f1: 0.7978 - val_auc: 0.8977\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1667 - accuracy: 0.9363 - f1: 0.8978 - auc: 0.9826 - val_loss: 0.4061 - val_accuracy: 0.8727 - val_f1: 0.8382 - val_auc: 0.9246\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1470 - accuracy: 0.9444 - f1: 0.9119 - auc: 0.9848 - val_loss: 0.4295 - val_accuracy: 0.8564 - val_f1: 0.8385 - val_auc: 0.9181\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1195 - accuracy: 0.9650 - f1: 0.9286 - auc: 0.9887 - val_loss: 0.4160 - val_accuracy: 0.8655 - val_f1: 0.8430 - val_auc: 0.9222\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1036 - accuracy: 0.9695 - f1: 0.9380 - auc: 0.9908 - val_loss: 0.4248 - val_accuracy: 0.8709 - val_f1: 0.8447 - val_auc: 0.9237\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0900 - accuracy: 0.9713 - f1: 0.9461 - auc: 0.9922 - val_loss: 0.4378 - val_accuracy: 0.8709 - val_f1: 0.8439 - val_auc: 0.9226\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 87.09%\n",
            "F1: 84.66%\n",
            "AUC: 92.26%\n",
            "Loss: 0.44%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 93ms/step - loss: 0.7925 - accuracy: 0.4395 - f1: 0.3971 - auc: 0.4368 - val_loss: 0.6227 - val_accuracy: 0.7036 - val_f1: 0.5539 - val_auc: 0.6779\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6591 - accuracy: 0.6762 - f1: 0.5881 - auc: 0.6718 - val_loss: 0.6115 - val_accuracy: 0.7036 - val_f1: 0.5650 - val_auc: 0.7224\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6311 - accuracy: 0.6762 - f1: 0.5460 - auc: 0.6981 - val_loss: 0.6056 - val_accuracy: 0.7036 - val_f1: 0.5655 - val_auc: 0.7557\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6176 - accuracy: 0.6762 - f1: 0.5781 - auc: 0.7350 - val_loss: 0.5889 - val_accuracy: 0.7036 - val_f1: 0.5986 - val_auc: 0.8276\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5892 - accuracy: 0.6762 - f1: 0.5869 - auc: 0.8129 - val_loss: 0.5493 - val_accuracy: 0.7036 - val_f1: 0.6017 - val_auc: 0.8490\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5053 - accuracy: 0.7175 - f1: 0.6387 - auc: 0.8508 - val_loss: 0.4627 - val_accuracy: 0.8273 - val_f1: 0.6650 - val_auc: 0.8866\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3933 - accuracy: 0.8439 - f1: 0.7296 - auc: 0.9107 - val_loss: 0.3973 - val_accuracy: 0.8309 - val_f1: 0.7573 - val_auc: 0.9005\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3284 - accuracy: 0.8628 - f1: 0.7940 - auc: 0.9338 - val_loss: 0.3806 - val_accuracy: 0.8382 - val_f1: 0.7810 - val_auc: 0.9104\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2910 - accuracy: 0.8735 - f1: 0.8174 - auc: 0.9489 - val_loss: 0.3683 - val_accuracy: 0.8473 - val_f1: 0.7783 - val_auc: 0.9168\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2613 - accuracy: 0.8951 - f1: 0.8221 - auc: 0.9592 - val_loss: 0.4118 - val_accuracy: 0.8055 - val_f1: 0.7597 - val_auc: 0.8985\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2550 - accuracy: 0.8960 - f1: 0.8292 - auc: 0.9613 - val_loss: 0.3606 - val_accuracy: 0.8564 - val_f1: 0.8040 - val_auc: 0.9218\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2129 - accuracy: 0.9166 - f1: 0.8601 - auc: 0.9725 - val_loss: 0.3656 - val_accuracy: 0.8509 - val_f1: 0.8090 - val_auc: 0.9212\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2096 - accuracy: 0.9193 - f1: 0.8664 - auc: 0.9727 - val_loss: 0.3758 - val_accuracy: 0.8527 - val_f1: 0.8105 - val_auc: 0.9203\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1819 - accuracy: 0.9345 - f1: 0.8863 - auc: 0.9795 - val_loss: 0.3852 - val_accuracy: 0.8509 - val_f1: 0.8152 - val_auc: 0.9202\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1618 - accuracy: 0.9426 - f1: 0.8933 - auc: 0.9833 - val_loss: 0.4193 - val_accuracy: 0.8236 - val_f1: 0.8044 - val_auc: 0.9125\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1526 - accuracy: 0.9471 - f1: 0.9042 - auc: 0.9848 - val_loss: 0.3941 - val_accuracy: 0.8655 - val_f1: 0.8292 - val_auc: 0.9224\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1432 - accuracy: 0.9480 - f1: 0.9095 - auc: 0.9863 - val_loss: 0.4043 - val_accuracy: 0.8673 - val_f1: 0.8294 - val_auc: 0.9218\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1273 - accuracy: 0.9605 - f1: 0.9195 - auc: 0.9885 - val_loss: 0.4244 - val_accuracy: 0.8473 - val_f1: 0.8259 - val_auc: 0.9193\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1063 - accuracy: 0.9641 - f1: 0.9297 - auc: 0.9919 - val_loss: 0.4313 - val_accuracy: 0.8600 - val_f1: 0.8327 - val_auc: 0.9199\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0934 - accuracy: 0.9695 - f1: 0.9395 - auc: 0.9926 - val_loss: 0.4354 - val_accuracy: 0.8655 - val_f1: 0.8417 - val_auc: 0.9216\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 86.55%\n",
            "F1: 84.47%\n",
            "AUC: 92.16%\n",
            "Loss: 0.44%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 95ms/step - loss: 0.7282 - accuracy: 0.6762 - f1: 0.4319 - auc: 0.6043 - val_loss: 0.6215 - val_accuracy: 0.7036 - val_f1: 0.5823 - val_auc: 0.7111\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6418 - accuracy: 0.6762 - f1: 0.5772 - auc: 0.6733 - val_loss: 0.6096 - val_accuracy: 0.7036 - val_f1: 0.5596 - val_auc: 0.7721\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6241 - accuracy: 0.6762 - f1: 0.5531 - auc: 0.7731 - val_loss: 0.5935 - val_accuracy: 0.7036 - val_f1: 0.5795 - val_auc: 0.8426\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5900 - accuracy: 0.6762 - f1: 0.5863 - auc: 0.8348 - val_loss: 0.5407 - val_accuracy: 0.7036 - val_f1: 0.6171 - val_auc: 0.8511\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4946 - accuracy: 0.7256 - f1: 0.6534 - auc: 0.8495 - val_loss: 0.4352 - val_accuracy: 0.8327 - val_f1: 0.7002 - val_auc: 0.8885\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3751 - accuracy: 0.8484 - f1: 0.7475 - auc: 0.9180 - val_loss: 0.3960 - val_accuracy: 0.8327 - val_f1: 0.7608 - val_auc: 0.9016\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3318 - accuracy: 0.8592 - f1: 0.7955 - auc: 0.9319 - val_loss: 0.3763 - val_accuracy: 0.8564 - val_f1: 0.7889 - val_auc: 0.9133\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2948 - accuracy: 0.8852 - f1: 0.8141 - auc: 0.9470 - val_loss: 0.3665 - val_accuracy: 0.8491 - val_f1: 0.7854 - val_auc: 0.9179\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2663 - accuracy: 0.8987 - f1: 0.8253 - auc: 0.9578 - val_loss: 0.3575 - val_accuracy: 0.8545 - val_f1: 0.7861 - val_auc: 0.9214\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2542 - accuracy: 0.8987 - f1: 0.8365 - auc: 0.9614 - val_loss: 0.3591 - val_accuracy: 0.8564 - val_f1: 0.8014 - val_auc: 0.9223\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2222 - accuracy: 0.9040 - f1: 0.8569 - auc: 0.9702 - val_loss: 0.3705 - val_accuracy: 0.8455 - val_f1: 0.8057 - val_auc: 0.9214\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1952 - accuracy: 0.9238 - f1: 0.8780 - auc: 0.9768 - val_loss: 0.3785 - val_accuracy: 0.8527 - val_f1: 0.8129 - val_auc: 0.9214\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1820 - accuracy: 0.9283 - f1: 0.8862 - auc: 0.9793 - val_loss: 0.3898 - val_accuracy: 0.8473 - val_f1: 0.8178 - val_auc: 0.9214\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1587 - accuracy: 0.9408 - f1: 0.8981 - auc: 0.9842 - val_loss: 0.3986 - val_accuracy: 0.8618 - val_f1: 0.8260 - val_auc: 0.9216\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1479 - accuracy: 0.9489 - f1: 0.9114 - auc: 0.9854 - val_loss: 0.4232 - val_accuracy: 0.8291 - val_f1: 0.8157 - val_auc: 0.9172\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1198 - accuracy: 0.9623 - f1: 0.9249 - auc: 0.9899 - val_loss: 0.4472 - val_accuracy: 0.8218 - val_f1: 0.8123 - val_auc: 0.9135\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1303 - accuracy: 0.9471 - f1: 0.9211 - auc: 0.9879 - val_loss: 0.4550 - val_accuracy: 0.8545 - val_f1: 0.8388 - val_auc: 0.9189\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.1286 - accuracy: 0.9516 - f1: 0.9297 - auc: 0.9880 - val_loss: 0.4553 - val_accuracy: 0.8527 - val_f1: 0.8429 - val_auc: 0.9215\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.1029 - accuracy: 0.9623 - f1: 0.9396 - auc: 0.9914 - val_loss: 0.4650 - val_accuracy: 0.8382 - val_f1: 0.8268 - val_auc: 0.9177\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0808 - accuracy: 0.9785 - f1: 0.9506 - auc: 0.9932 - val_loss: 0.5123 - val_accuracy: 0.8200 - val_f1: 0.8107 - val_auc: 0.9071\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 82.00%\n",
            "F1: 81.40%\n",
            "AUC: 90.71%\n",
            "Loss: 0.51%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 6s 115ms/step - loss: 0.7320 - accuracy: 0.5229 - f1: 0.4471 - auc: 0.5242 - val_loss: 0.6189 - val_accuracy: 0.7036 - val_f1: 0.5899 - val_auc: 0.6635\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6534 - accuracy: 0.6762 - f1: 0.5837 - auc: 0.6612 - val_loss: 0.6113 - val_accuracy: 0.7036 - val_f1: 0.5602 - val_auc: 0.7466\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6290 - accuracy: 0.6762 - f1: 0.5392 - auc: 0.7299 - val_loss: 0.6045 - val_accuracy: 0.7036 - val_f1: 0.5607 - val_auc: 0.8237\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6063 - accuracy: 0.6762 - f1: 0.5724 - auc: 0.8061 - val_loss: 0.5682 - val_accuracy: 0.7036 - val_f1: 0.6041 - val_auc: 0.8478\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5472 - accuracy: 0.6780 - f1: 0.6171 - auc: 0.8384 - val_loss: 0.4912 - val_accuracy: 0.7164 - val_f1: 0.6648 - val_auc: 0.8516\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.4264 - accuracy: 0.8099 - f1: 0.7054 - auc: 0.8943 - val_loss: 0.4047 - val_accuracy: 0.8382 - val_f1: 0.7477 - val_auc: 0.8974\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3482 - accuracy: 0.8583 - f1: 0.7760 - auc: 0.9243 - val_loss: 0.3850 - val_accuracy: 0.8455 - val_f1: 0.7862 - val_auc: 0.9095\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3252 - accuracy: 0.8610 - f1: 0.8056 - auc: 0.9357 - val_loss: 0.4749 - val_accuracy: 0.8091 - val_f1: 0.7820 - val_auc: 0.8898\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3082 - accuracy: 0.8726 - f1: 0.8059 - auc: 0.9416 - val_loss: 0.3927 - val_accuracy: 0.8509 - val_f1: 0.7947 - val_auc: 0.9098\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2784 - accuracy: 0.8816 - f1: 0.8185 - auc: 0.9533 - val_loss: 0.3631 - val_accuracy: 0.8527 - val_f1: 0.7844 - val_auc: 0.9197\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2464 - accuracy: 0.9004 - f1: 0.8397 - auc: 0.9649 - val_loss: 0.3643 - val_accuracy: 0.8618 - val_f1: 0.8048 - val_auc: 0.9203\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2298 - accuracy: 0.9040 - f1: 0.8565 - auc: 0.9686 - val_loss: 0.3627 - val_accuracy: 0.8582 - val_f1: 0.8124 - val_auc: 0.9231\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2080 - accuracy: 0.9121 - f1: 0.8683 - auc: 0.9738 - val_loss: 0.3815 - val_accuracy: 0.8582 - val_f1: 0.8208 - val_auc: 0.9210\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2062 - accuracy: 0.9202 - f1: 0.8705 - auc: 0.9736 - val_loss: 0.3825 - val_accuracy: 0.8564 - val_f1: 0.8106 - val_auc: 0.9209\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1975 - accuracy: 0.9238 - f1: 0.8750 - auc: 0.9758 - val_loss: 0.4018 - val_accuracy: 0.8327 - val_f1: 0.8027 - val_auc: 0.9151\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1658 - accuracy: 0.9417 - f1: 0.8976 - auc: 0.9824 - val_loss: 0.3799 - val_accuracy: 0.8582 - val_f1: 0.8245 - val_auc: 0.9242\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1568 - accuracy: 0.9453 - f1: 0.9026 - auc: 0.9846 - val_loss: 0.3913 - val_accuracy: 0.8618 - val_f1: 0.8327 - val_auc: 0.9258\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1552 - accuracy: 0.9399 - f1: 0.9031 - auc: 0.9843 - val_loss: 0.3982 - val_accuracy: 0.8636 - val_f1: 0.8344 - val_auc: 0.9250\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1349 - accuracy: 0.9516 - f1: 0.9216 - auc: 0.9875 - val_loss: 0.4202 - val_accuracy: 0.8364 - val_f1: 0.8206 - val_auc: 0.9195\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1144 - accuracy: 0.9641 - f1: 0.9279 - auc: 0.9910 - val_loss: 0.4369 - val_accuracy: 0.8345 - val_f1: 0.8197 - val_auc: 0.9166\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 83.45%\n",
            "F1: 82.24%\n",
            "AUC: 91.66%\n",
            "Loss: 0.44%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 104ms/step - loss: 0.6672 - accuracy: 0.6063 - f1: 0.5342 - auc: 0.6382 - val_loss: 0.6076 - val_accuracy: 0.7036 - val_f1: 0.5795 - val_auc: 0.7260\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6257 - accuracy: 0.6762 - f1: 0.5804 - auc: 0.7467 - val_loss: 0.5949 - val_accuracy: 0.7036 - val_f1: 0.5882 - val_auc: 0.8436\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5976 - accuracy: 0.6762 - f1: 0.5915 - auc: 0.8304 - val_loss: 0.5499 - val_accuracy: 0.7036 - val_f1: 0.6263 - val_auc: 0.8499\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5063 - accuracy: 0.6951 - f1: 0.6490 - auc: 0.8475 - val_loss: 0.4447 - val_accuracy: 0.8309 - val_f1: 0.6983 - val_auc: 0.8799\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.3766 - accuracy: 0.8493 - f1: 0.7538 - auc: 0.9148 - val_loss: 0.4118 - val_accuracy: 0.8436 - val_f1: 0.7850 - val_auc: 0.8994\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3252 - accuracy: 0.8709 - f1: 0.8161 - auc: 0.9349 - val_loss: 0.4060 - val_accuracy: 0.8473 - val_f1: 0.7992 - val_auc: 0.9056\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2867 - accuracy: 0.8798 - f1: 0.8264 - auc: 0.9493 - val_loss: 0.3649 - val_accuracy: 0.8691 - val_f1: 0.7963 - val_auc: 0.9182\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2730 - accuracy: 0.8915 - f1: 0.8311 - auc: 0.9549 - val_loss: 0.3901 - val_accuracy: 0.8200 - val_f1: 0.7730 - val_auc: 0.9086\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2468 - accuracy: 0.9013 - f1: 0.8414 - auc: 0.9632 - val_loss: 0.3635 - val_accuracy: 0.8673 - val_f1: 0.8087 - val_auc: 0.9208\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2133 - accuracy: 0.9130 - f1: 0.8629 - auc: 0.9727 - val_loss: 0.4127 - val_accuracy: 0.8491 - val_f1: 0.8141 - val_auc: 0.9110\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2078 - accuracy: 0.9256 - f1: 0.8764 - auc: 0.9727 - val_loss: 0.3929 - val_accuracy: 0.8600 - val_f1: 0.8256 - val_auc: 0.9187\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1679 - accuracy: 0.9399 - f1: 0.8901 - auc: 0.9816 - val_loss: 0.4181 - val_accuracy: 0.8291 - val_f1: 0.8055 - val_auc: 0.9146\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1571 - accuracy: 0.9444 - f1: 0.9066 - auc: 0.9831 - val_loss: 0.4132 - val_accuracy: 0.8582 - val_f1: 0.8324 - val_auc: 0.9195\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1636 - accuracy: 0.9336 - f1: 0.9026 - auc: 0.9822 - val_loss: 0.4061 - val_accuracy: 0.8691 - val_f1: 0.8332 - val_auc: 0.9228\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1258 - accuracy: 0.9623 - f1: 0.9257 - auc: 0.9876 - val_loss: 0.4153 - val_accuracy: 0.8673 - val_f1: 0.8354 - val_auc: 0.9219\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1060 - accuracy: 0.9722 - f1: 0.9306 - auc: 0.9901 - val_loss: 0.4293 - val_accuracy: 0.8673 - val_f1: 0.8386 - val_auc: 0.9216\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0954 - accuracy: 0.9758 - f1: 0.9389 - auc: 0.9912 - val_loss: 0.4425 - val_accuracy: 0.8709 - val_f1: 0.8426 - val_auc: 0.9195\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0850 - accuracy: 0.9785 - f1: 0.9528 - auc: 0.9913 - val_loss: 0.4597 - val_accuracy: 0.8636 - val_f1: 0.8414 - val_auc: 0.9183\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0751 - accuracy: 0.9865 - f1: 0.9595 - auc: 0.9922 - val_loss: 0.4939 - val_accuracy: 0.8291 - val_f1: 0.8296 - val_auc: 0.9153\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0884 - accuracy: 0.9731 - f1: 0.9499 - auc: 0.9917 - val_loss: 0.4868 - val_accuracy: 0.8673 - val_f1: 0.8508 - val_auc: 0.9198\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 86.73%\n",
            "F1: 85.38%\n",
            "AUC: 91.98%\n",
            "Loss: 0.49%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 94ms/step - loss: 0.6501 - accuracy: 0.6762 - f1: 0.5115 - auc: 0.6725 - val_loss: 0.6083 - val_accuracy: 0.7036 - val_f1: 0.5893 - val_auc: 0.7548\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.6223 - accuracy: 0.6762 - f1: 0.5822 - auc: 0.7558 - val_loss: 0.5892 - val_accuracy: 0.7036 - val_f1: 0.5845 - val_auc: 0.8470\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5828 - accuracy: 0.6762 - f1: 0.6006 - auc: 0.8291 - val_loss: 0.5247 - val_accuracy: 0.7036 - val_f1: 0.6299 - val_auc: 0.8511\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4704 - accuracy: 0.7462 - f1: 0.6746 - auc: 0.8634 - val_loss: 0.4175 - val_accuracy: 0.8418 - val_f1: 0.7175 - val_auc: 0.8953\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3577 - accuracy: 0.8493 - f1: 0.7723 - auc: 0.9224 - val_loss: 0.3867 - val_accuracy: 0.8436 - val_f1: 0.7801 - val_auc: 0.9078\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3154 - accuracy: 0.8700 - f1: 0.8182 - auc: 0.9390 - val_loss: 0.4088 - val_accuracy: 0.8455 - val_f1: 0.7979 - val_auc: 0.9064\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2775 - accuracy: 0.8762 - f1: 0.8287 - auc: 0.9528 - val_loss: 0.3609 - val_accuracy: 0.8527 - val_f1: 0.7961 - val_auc: 0.9212\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2415 - accuracy: 0.9058 - f1: 0.8490 - auc: 0.9652 - val_loss: 0.3695 - val_accuracy: 0.8636 - val_f1: 0.8115 - val_auc: 0.9206\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2202 - accuracy: 0.9193 - f1: 0.8650 - auc: 0.9703 - val_loss: 0.3689 - val_accuracy: 0.8618 - val_f1: 0.8190 - val_auc: 0.9223\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1854 - accuracy: 0.9318 - f1: 0.8774 - auc: 0.9789 - val_loss: 0.4205 - val_accuracy: 0.8491 - val_f1: 0.8213 - val_auc: 0.9140\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1878 - accuracy: 0.9291 - f1: 0.8847 - auc: 0.9772 - val_loss: 0.4078 - val_accuracy: 0.8291 - val_f1: 0.8080 - val_auc: 0.9159\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1710 - accuracy: 0.9399 - f1: 0.8961 - auc: 0.9810 - val_loss: 0.3962 - val_accuracy: 0.8455 - val_f1: 0.8142 - val_auc: 0.9201\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1477 - accuracy: 0.9543 - f1: 0.8970 - auc: 0.9852 - val_loss: 0.4277 - val_accuracy: 0.8527 - val_f1: 0.8305 - val_auc: 0.9166\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1496 - accuracy: 0.9471 - f1: 0.9055 - auc: 0.9858 - val_loss: 0.4009 - val_accuracy: 0.8400 - val_f1: 0.8184 - val_auc: 0.9202\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1176 - accuracy: 0.9668 - f1: 0.9261 - auc: 0.9903 - val_loss: 0.4167 - val_accuracy: 0.8418 - val_f1: 0.8235 - val_auc: 0.9202\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1021 - accuracy: 0.9749 - f1: 0.9353 - auc: 0.9920 - val_loss: 0.4259 - val_accuracy: 0.8491 - val_f1: 0.8341 - val_auc: 0.9224\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0885 - accuracy: 0.9767 - f1: 0.9430 - auc: 0.9932 - val_loss: 0.5013 - val_accuracy: 0.8109 - val_f1: 0.8086 - val_auc: 0.9059\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0889 - accuracy: 0.9749 - f1: 0.9412 - auc: 0.9930 - val_loss: 0.4493 - val_accuracy: 0.8509 - val_f1: 0.8414 - val_auc: 0.9243\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0736 - accuracy: 0.9821 - f1: 0.9532 - auc: 0.9940 - val_loss: 0.4716 - val_accuracy: 0.8418 - val_f1: 0.8363 - val_auc: 0.9201\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.0661 - accuracy: 0.9848 - f1: 0.9581 - auc: 0.9948 - val_loss: 0.4957 - val_accuracy: 0.8473 - val_f1: 0.8367 - val_auc: 0.9212\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 84.73%\n",
            "F1: 83.93%\n",
            "AUC: 92.12%\n",
            "Loss: 0.50%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 100ms/step - loss: 0.6643 - accuracy: 0.6188 - f1: 0.5256 - auc: 0.6483 - val_loss: 0.6079 - val_accuracy: 0.7036 - val_f1: 0.5841 - val_auc: 0.7128\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6281 - accuracy: 0.6762 - f1: 0.5815 - auc: 0.7235 - val_loss: 0.5998 - val_accuracy: 0.7036 - val_f1: 0.5809 - val_auc: 0.8421\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.6082 - accuracy: 0.6762 - f1: 0.5819 - auc: 0.8351 - val_loss: 0.5652 - val_accuracy: 0.7036 - val_f1: 0.6104 - val_auc: 0.8506\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5324 - accuracy: 0.6807 - f1: 0.6309 - auc: 0.8395 - val_loss: 0.4569 - val_accuracy: 0.8036 - val_f1: 0.6837 - val_auc: 0.8740\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3881 - accuracy: 0.8511 - f1: 0.7326 - auc: 0.9106 - val_loss: 0.3871 - val_accuracy: 0.8364 - val_f1: 0.7633 - val_auc: 0.9056\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3259 - accuracy: 0.8709 - f1: 0.8007 - auc: 0.9330 - val_loss: 0.3874 - val_accuracy: 0.8236 - val_f1: 0.7698 - val_auc: 0.9083\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3161 - accuracy: 0.8762 - f1: 0.8121 - auc: 0.9380 - val_loss: 0.4042 - val_accuracy: 0.8036 - val_f1: 0.7553 - val_auc: 0.9013\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2841 - accuracy: 0.8915 - f1: 0.8144 - auc: 0.9504 - val_loss: 0.3886 - val_accuracy: 0.8164 - val_f1: 0.7730 - val_auc: 0.9095\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2517 - accuracy: 0.9013 - f1: 0.8342 - auc: 0.9620 - val_loss: 0.3599 - val_accuracy: 0.8673 - val_f1: 0.8046 - val_auc: 0.9201\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2441 - accuracy: 0.8996 - f1: 0.8407 - auc: 0.9643 - val_loss: 0.3586 - val_accuracy: 0.8545 - val_f1: 0.8044 - val_auc: 0.9225\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2254 - accuracy: 0.9103 - f1: 0.8619 - auc: 0.9693 - val_loss: 0.3625 - val_accuracy: 0.8709 - val_f1: 0.8170 - val_auc: 0.9224\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2117 - accuracy: 0.9220 - f1: 0.8655 - auc: 0.9717 - val_loss: 0.3661 - val_accuracy: 0.8655 - val_f1: 0.8207 - val_auc: 0.9233\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1780 - accuracy: 0.9363 - f1: 0.8775 - auc: 0.9806 - val_loss: 0.3834 - val_accuracy: 0.8655 - val_f1: 0.8278 - val_auc: 0.9215\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1796 - accuracy: 0.9300 - f1: 0.8923 - auc: 0.9793 - val_loss: 0.3976 - val_accuracy: 0.8564 - val_f1: 0.8301 - val_auc: 0.9194\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1630 - accuracy: 0.9399 - f1: 0.8978 - auc: 0.9827 - val_loss: 0.3937 - val_accuracy: 0.8582 - val_f1: 0.8283 - val_auc: 0.9223\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1494 - accuracy: 0.9507 - f1: 0.9128 - auc: 0.9845 - val_loss: 0.4647 - val_accuracy: 0.8182 - val_f1: 0.7998 - val_auc: 0.9046\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1393 - accuracy: 0.9570 - f1: 0.9175 - auc: 0.9862 - val_loss: 0.4282 - val_accuracy: 0.8400 - val_f1: 0.8237 - val_auc: 0.9190\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1129 - accuracy: 0.9659 - f1: 0.9309 - auc: 0.9901 - val_loss: 0.4202 - val_accuracy: 0.8709 - val_f1: 0.8428 - val_auc: 0.9241\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1054 - accuracy: 0.9704 - f1: 0.9387 - auc: 0.9914 - val_loss: 0.4479 - val_accuracy: 0.8600 - val_f1: 0.8435 - val_auc: 0.9191\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1155 - accuracy: 0.9570 - f1: 0.9261 - auc: 0.9901 - val_loss: 0.4341 - val_accuracy: 0.8618 - val_f1: 0.8423 - val_auc: 0.9231\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 86.18%\n",
            "F1: 84.49%\n",
            "AUC: 92.31%\n",
            "Loss: 0.43%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 97ms/step - loss: 0.7211 - accuracy: 0.4771 - f1: 0.4759 - auc: 0.4685 - val_loss: 0.6149 - val_accuracy: 0.7036 - val_f1: 0.5804 - val_auc: 0.6599\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6340 - accuracy: 0.6762 - f1: 0.5756 - auc: 0.6804 - val_loss: 0.6042 - val_accuracy: 0.7036 - val_f1: 0.5735 - val_auc: 0.7960\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6202 - accuracy: 0.6762 - f1: 0.5578 - auc: 0.7620 - val_loss: 0.5904 - val_accuracy: 0.7036 - val_f1: 0.5815 - val_auc: 0.8495\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5802 - accuracy: 0.6762 - f1: 0.5927 - auc: 0.8423 - val_loss: 0.5294 - val_accuracy: 0.7036 - val_f1: 0.6412 - val_auc: 0.8525\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.4832 - accuracy: 0.7013 - f1: 0.6672 - auc: 0.8505 - val_loss: 0.4595 - val_accuracy: 0.7909 - val_f1: 0.7272 - val_auc: 0.8701\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3759 - accuracy: 0.8457 - f1: 0.7520 - auc: 0.9147 - val_loss: 0.3916 - val_accuracy: 0.8436 - val_f1: 0.7727 - val_auc: 0.9048\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3346 - accuracy: 0.8655 - f1: 0.7962 - auc: 0.9319 - val_loss: 0.3832 - val_accuracy: 0.8455 - val_f1: 0.7887 - val_auc: 0.9103\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3061 - accuracy: 0.8726 - f1: 0.8141 - auc: 0.9439 - val_loss: 0.3679 - val_accuracy: 0.8491 - val_f1: 0.7836 - val_auc: 0.9162\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2689 - accuracy: 0.8942 - f1: 0.8321 - auc: 0.9571 - val_loss: 0.3626 - val_accuracy: 0.8545 - val_f1: 0.7894 - val_auc: 0.9196\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2389 - accuracy: 0.9112 - f1: 0.8385 - auc: 0.9666 - val_loss: 0.3588 - val_accuracy: 0.8618 - val_f1: 0.8025 - val_auc: 0.9225\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2113 - accuracy: 0.9274 - f1: 0.8602 - auc: 0.9728 - val_loss: 0.3797 - val_accuracy: 0.8400 - val_f1: 0.7991 - val_auc: 0.9192\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1880 - accuracy: 0.9309 - f1: 0.8707 - auc: 0.9783 - val_loss: 0.4619 - val_accuracy: 0.7964 - val_f1: 0.7743 - val_auc: 0.8915\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1908 - accuracy: 0.9193 - f1: 0.8808 - auc: 0.9787 - val_loss: 0.4181 - val_accuracy: 0.8255 - val_f1: 0.7969 - val_auc: 0.9106\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1797 - accuracy: 0.9318 - f1: 0.8888 - auc: 0.9796 - val_loss: 0.4095 - val_accuracy: 0.8600 - val_f1: 0.8322 - val_auc: 0.9197\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1603 - accuracy: 0.9453 - f1: 0.9104 - auc: 0.9822 - val_loss: 0.4058 - val_accuracy: 0.8582 - val_f1: 0.8360 - val_auc: 0.9212\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1332 - accuracy: 0.9552 - f1: 0.9203 - auc: 0.9877 - val_loss: 0.4052 - val_accuracy: 0.8600 - val_f1: 0.8380 - val_auc: 0.9242\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9713 - f1: 0.9296 - auc: 0.9893 - val_loss: 0.4391 - val_accuracy: 0.8291 - val_f1: 0.8193 - val_auc: 0.9183\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0988 - accuracy: 0.9749 - f1: 0.9422 - auc: 0.9910 - val_loss: 0.4261 - val_accuracy: 0.8727 - val_f1: 0.8452 - val_auc: 0.9256\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0893 - accuracy: 0.9776 - f1: 0.9487 - auc: 0.9922 - val_loss: 0.4405 - val_accuracy: 0.8691 - val_f1: 0.8478 - val_auc: 0.9260\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0805 - accuracy: 0.9776 - f1: 0.9487 - auc: 0.9935 - val_loss: 0.4661 - val_accuracy: 0.8473 - val_f1: 0.8363 - val_auc: 0.9204\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 84.73%\n",
            "F1: 83.97%\n",
            "AUC: 92.04%\n",
            "Loss: 0.47%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 95ms/step - loss: 0.6300 - accuracy: 0.6762 - f1: 0.5627 - auc: 0.6935 - val_loss: 0.6036 - val_accuracy: 0.7036 - val_f1: 0.5734 - val_auc: 0.8274\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.6092 - accuracy: 0.6762 - f1: 0.5772 - auc: 0.8115 - val_loss: 0.5646 - val_accuracy: 0.7036 - val_f1: 0.5956 - val_auc: 0.8418\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5084 - accuracy: 0.7417 - f1: 0.6270 - auc: 0.8605 - val_loss: 0.4449 - val_accuracy: 0.8036 - val_f1: 0.6940 - val_auc: 0.8783\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3729 - accuracy: 0.8404 - f1: 0.7471 - auc: 0.9187 - val_loss: 0.4431 - val_accuracy: 0.8236 - val_f1: 0.7735 - val_auc: 0.8891\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.3441 - accuracy: 0.8556 - f1: 0.8008 - auc: 0.9284 - val_loss: 0.3923 - val_accuracy: 0.8545 - val_f1: 0.7918 - val_auc: 0.9084\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2918 - accuracy: 0.8735 - f1: 0.8183 - auc: 0.9483 - val_loss: 0.3646 - val_accuracy: 0.8527 - val_f1: 0.7852 - val_auc: 0.9182\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2761 - accuracy: 0.8870 - f1: 0.8279 - auc: 0.9543 - val_loss: 0.3578 - val_accuracy: 0.8618 - val_f1: 0.7951 - val_auc: 0.9212\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2410 - accuracy: 0.8996 - f1: 0.8447 - auc: 0.9653 - val_loss: 0.3578 - val_accuracy: 0.8582 - val_f1: 0.8079 - val_auc: 0.9227\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2183 - accuracy: 0.9103 - f1: 0.8575 - auc: 0.9714 - val_loss: 0.3717 - val_accuracy: 0.8691 - val_f1: 0.8181 - val_auc: 0.9219\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1892 - accuracy: 0.9291 - f1: 0.8737 - auc: 0.9782 - val_loss: 0.3715 - val_accuracy: 0.8582 - val_f1: 0.8137 - val_auc: 0.9233\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1816 - accuracy: 0.9291 - f1: 0.8790 - auc: 0.9790 - val_loss: 0.3798 - val_accuracy: 0.8491 - val_f1: 0.8143 - val_auc: 0.9226\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1515 - accuracy: 0.9471 - f1: 0.8960 - auc: 0.9855 - val_loss: 0.3878 - val_accuracy: 0.8473 - val_f1: 0.8151 - val_auc: 0.9218\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1539 - accuracy: 0.9417 - f1: 0.9032 - auc: 0.9853 - val_loss: 0.4264 - val_accuracy: 0.8509 - val_f1: 0.8340 - val_auc: 0.9179\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1375 - accuracy: 0.9525 - f1: 0.9084 - auc: 0.9877 - val_loss: 0.4069 - val_accuracy: 0.8400 - val_f1: 0.8219 - val_auc: 0.9217\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1197 - accuracy: 0.9596 - f1: 0.9213 - auc: 0.9908 - val_loss: 0.4354 - val_accuracy: 0.8255 - val_f1: 0.8153 - val_auc: 0.9163\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1033 - accuracy: 0.9677 - f1: 0.9321 - auc: 0.9927 - val_loss: 0.4163 - val_accuracy: 0.8673 - val_f1: 0.8412 - val_auc: 0.9245\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0894 - accuracy: 0.9749 - f1: 0.9429 - auc: 0.9943 - val_loss: 0.4352 - val_accuracy: 0.8564 - val_f1: 0.8370 - val_auc: 0.9233\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0746 - accuracy: 0.9812 - f1: 0.9528 - auc: 0.9952 - val_loss: 0.4518 - val_accuracy: 0.8473 - val_f1: 0.8369 - val_auc: 0.9233\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0789 - accuracy: 0.9776 - f1: 0.9532 - auc: 0.9948 - val_loss: 0.4701 - val_accuracy: 0.8636 - val_f1: 0.8473 - val_auc: 0.9237\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0738 - accuracy: 0.9749 - f1: 0.9568 - auc: 0.9955 - val_loss: 0.4773 - val_accuracy: 0.8636 - val_f1: 0.8495 - val_auc: 0.9231\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 86.36%\n",
            "F1: 85.24%\n",
            "AUC: 92.31%\n",
            "Loss: 0.48%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 4s 95ms/step - loss: 0.6484 - accuracy: 0.6762 - f1: 0.5595 - auc: 0.6950 - val_loss: 0.6087 - val_accuracy: 0.7036 - val_f1: 0.5679 - val_auc: 0.7394\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.6264 - accuracy: 0.6762 - f1: 0.5709 - auc: 0.7204 - val_loss: 0.5959 - val_accuracy: 0.7036 - val_f1: 0.5837 - val_auc: 0.8417\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5888 - accuracy: 0.6762 - f1: 0.5954 - auc: 0.8372 - val_loss: 0.5300 - val_accuracy: 0.7036 - val_f1: 0.6234 - val_auc: 0.8506\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4661 - accuracy: 0.7704 - f1: 0.6614 - auc: 0.8768 - val_loss: 0.4272 - val_accuracy: 0.8255 - val_f1: 0.7362 - val_auc: 0.8856\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3592 - accuracy: 0.8529 - f1: 0.7747 - auc: 0.9198 - val_loss: 0.3922 - val_accuracy: 0.8436 - val_f1: 0.7805 - val_auc: 0.9053\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3237 - accuracy: 0.8691 - f1: 0.8094 - auc: 0.9350 - val_loss: 0.3821 - val_accuracy: 0.8236 - val_f1: 0.7739 - val_auc: 0.9103\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2902 - accuracy: 0.8834 - f1: 0.8200 - auc: 0.9484 - val_loss: 0.4015 - val_accuracy: 0.8091 - val_f1: 0.7599 - val_auc: 0.9040\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2848 - accuracy: 0.8825 - f1: 0.8182 - auc: 0.9509 - val_loss: 0.4004 - val_accuracy: 0.8109 - val_f1: 0.7629 - val_auc: 0.9043\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2653 - accuracy: 0.8951 - f1: 0.8379 - auc: 0.9559 - val_loss: 0.3740 - val_accuracy: 0.8291 - val_f1: 0.7842 - val_auc: 0.9165\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2291 - accuracy: 0.9175 - f1: 0.8571 - auc: 0.9677 - val_loss: 0.3716 - val_accuracy: 0.8382 - val_f1: 0.7959 - val_auc: 0.9191\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2081 - accuracy: 0.9247 - f1: 0.8590 - auc: 0.9739 - val_loss: 0.3829 - val_accuracy: 0.8345 - val_f1: 0.7997 - val_auc: 0.9177\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1791 - accuracy: 0.9336 - f1: 0.8866 - auc: 0.9805 - val_loss: 0.3731 - val_accuracy: 0.8600 - val_f1: 0.8197 - val_auc: 0.9235\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1670 - accuracy: 0.9435 - f1: 0.8916 - auc: 0.9817 - val_loss: 0.3857 - val_accuracy: 0.8600 - val_f1: 0.8253 - val_auc: 0.9234\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1430 - accuracy: 0.9552 - f1: 0.9122 - auc: 0.9865 - val_loss: 0.3941 - val_accuracy: 0.8600 - val_f1: 0.8274 - val_auc: 0.9231\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1290 - accuracy: 0.9552 - f1: 0.9155 - auc: 0.9888 - val_loss: 0.4045 - val_accuracy: 0.8709 - val_f1: 0.8345 - val_auc: 0.9221\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.1211 - accuracy: 0.9605 - f1: 0.9257 - auc: 0.9890 - val_loss: 0.4317 - val_accuracy: 0.8291 - val_f1: 0.8230 - val_auc: 0.9199\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1104 - accuracy: 0.9623 - f1: 0.9358 - auc: 0.9904 - val_loss: 0.4441 - val_accuracy: 0.8618 - val_f1: 0.8417 - val_auc: 0.9189\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0966 - accuracy: 0.9740 - f1: 0.9352 - auc: 0.9912 - val_loss: 0.4522 - val_accuracy: 0.8400 - val_f1: 0.8316 - val_auc: 0.9200\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0783 - accuracy: 0.9830 - f1: 0.9531 - auc: 0.9933 - val_loss: 0.4578 - val_accuracy: 0.8545 - val_f1: 0.8420 - val_auc: 0.9220\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0683 - accuracy: 0.9865 - f1: 0.9558 - auc: 0.9939 - val_loss: 0.5017 - val_accuracy: 0.8291 - val_f1: 0.8258 - val_auc: 0.9150\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 82.91%\n",
            "F1: 82.91%\n",
            "AUC: 91.50%\n",
            "Loss: 0.50%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KFOLD CROSS-VAL BASED ON: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
        "\n",
        "\n",
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser = tf.reshape(X_train, [-1, 1, 1024])\n",
        "\n",
        "Y1 = to_categorical(y_train, 2)\n",
        "Y1_reshaped = tf.reshape(Y1, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser.shape, Y1_reshaped.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser = tf.reshape(X_test, [-1, 1, 1024])\n",
        "\n",
        "Y2 = to_categorical(y_test, 2)\n",
        "Y2_reshaped = tf.reshape(Y2, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser.shape, Y2_reshaped.shape)\n",
        "\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(LSTM(100, input_shape=(1, 1024), return_sequences=True))\n",
        "  model.add(Dense(1024,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128,activation='sigmoid'))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR85E_BlWts4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b89000-c211-427d-8269-7c9f4dc986fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.43777212500572205 - Accuracy: 87.09090948104858 - F1: 84.66131091117859 - AUC: 92.25817918777466%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.4353945553302765 - Accuracy: 86.54545545578003 - F1: 84.46762561798096 - AUC: 92.16181635856628%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.5123358368873596 - Accuracy: 81.99999928474426 - F1: 81.3953161239624 - AUC: 90.70711135864258%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.43693333864212036 - Accuracy: 83.45454335212708 - F1: 82.2370171546936 - AUC: 91.65553450584412%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.4867892265319824 - Accuracy: 86.72727346420288 - F1: 85.38281321525574 - AUC: 91.9829785823822%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.49573126435279846 - Accuracy: 84.72727537155151 - F1: 83.9275062084198 - AUC: 92.11504459381104%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.43409085273742676 - Accuracy: 86.18181943893433 - F1: 84.49012637138367 - AUC: 92.30694770812988%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.4660540223121643 - Accuracy: 84.72727537155151 - F1: 83.96564722061157 - AUC: 92.0378565788269%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.4772505462169647 - Accuracy: 86.36363744735718 - F1: 85.24476289749146 - AUC: 92.30843782424927%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.5017415881156921 - Accuracy: 82.90908932685852 - F1: 82.90903568267822 - AUC: 91.5031373500824%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.4684093356132507\n",
            "> Accuracy: 85.07272779941559 (+- 1.698712012698129)\n",
            "> F1: 83.8681161403656 (+- 1.235840946342686)\n",
            "> AUC: 91.90370440483093 (+- 0.4734460384928126)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('final_model_sexist.h5')"
      ],
      "metadata": {
        "id": "7v7odukMkzKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVxSFf5TySpR"
      },
      "source": [
        "## **4. Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lyfinal_df = labeling(lyrics_embeddings, lyfinal_df)"
      ],
      "metadata": {
        "id": "Llzyd9P08tz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zxg1ExJNJg13",
        "outputId": "f551627e-5142-48b7-aa56-4801f33be3ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0            lyricstxtCant Feel My Face_The Weeknd.txt   \n",
              "1                    lyricstxtgrande_paolo vallesi.txt   \n",
              "3578         lyricstxtCant Feel My Face_The Weeknd.txt   \n",
              "2                    lyricstxtScatman_Scatman john.txt   \n",
              "17312  lyricstxtI Really Like You_Carly Rae Jepsen.txt   \n",
              "...                                                ...   \n",
              "17397          lyricstxtNobody told me_John Lennon.txt   \n",
              "17401                             lyricstxtNumb_U2.txt   \n",
              "17403         lyricstxtHave you seen her_MC hammer.txt   \n",
              "17404            lyricstxtHappy _Pharrell Williams.txt   \n",
              "17405                      lyricstxtMagic_Coldplay.txt   \n",
              "\n",
              "                                               paragraph  sexist_label  \\\n",
              "0      I can't feel my face when I'm with you (I can'...             1   \n",
              "1      Paolo: Yo soy quien, se dormía en las clases d...             1   \n",
              "3578   I can't feel my face when I'm with you\\nBut I ...             1   \n",
              "2      I'm the Scatman\\nSki-bi dibby dib yo da dub du...             1   \n",
              "17312  Who gave you eyes like that?\\nSaid you could k...             1   \n",
              "...                                                  ...           ...   \n",
              "17397  Everybody's smoking and no one's getting high\\...             0   \n",
              "17401  Don't struggle\\nDon't jerk\\nDon't collar\\nDon'...             0   \n",
              "17403  I see her face and I can't let go\\nShe's in my...             0   \n",
              "17404  (Because I'm happy)\\nClap along if you feel li...             0   \n",
              "17405  And I don't, and I don't, and I don't, and I d...             0   \n",
              "\n",
              "       label_racialized  label_racialized probability  probability_racialized  \\\n",
              "0                     0                      0.569428                0.392769   \n",
              "1                     1                      0.498606                0.498606   \n",
              "3578                  0                      0.994051                0.004910   \n",
              "2                     0                      0.754303                0.199873   \n",
              "17312                 0                      0.865534                0.110881   \n",
              "...                 ...                           ...                     ...   \n",
              "17397                 0                      0.854194                0.112793   \n",
              "17401                 0                      0.793198                0.163980   \n",
              "17403                 0                      0.705960                0.243503   \n",
              "17404                 0                      0.744704                0.211503   \n",
              "17405                 0                      0.747309                0.207083   \n",
              "\n",
              "       probability_NOT_racialised  sexist_label probability  \\\n",
              "0                        0.569428                  0.997119   \n",
              "1                        0.450495                  0.997040   \n",
              "3578                     0.994051                  0.996978   \n",
              "2                        0.754303                  0.996891   \n",
              "17312                    0.865534                  0.996621   \n",
              "...                           ...                       ...   \n",
              "17397                    0.854194                  0.996889   \n",
              "17401                    0.793198                  0.996888   \n",
              "17403                    0.705960                  0.996885   \n",
              "17404                    0.744704                  0.996867   \n",
              "17405                    0.747309                  0.996841   \n",
              "\n",
              "       probability_sexist  probability_NOT_sexist  \n",
              "0                0.997119                0.003082  \n",
              "1                0.997040                0.003022  \n",
              "3578             0.996978                0.003009  \n",
              "2                0.996891                0.003088  \n",
              "17312            0.996621                0.003286  \n",
              "...                   ...                     ...  \n",
              "17397            0.003313                0.996889  \n",
              "17401            0.003306                0.996888  \n",
              "17403            0.003299                0.996885  \n",
              "17404            0.003258                0.996867  \n",
              "17405            0.003217                0.996841  \n",
              "\n",
              "[17407 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e395751c-9b58-4350-97d6-0f1347b19f53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>sexist_label</th>\n",
              "      <th>label_racialized</th>\n",
              "      <th>label_racialized probability</th>\n",
              "      <th>probability_racialized</th>\n",
              "      <th>probability_NOT_racialised</th>\n",
              "      <th>sexist_label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtCant Feel My Face_The Weeknd.txt</td>\n",
              "      <td>I can't feel my face when I'm with you (I can'...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569428</td>\n",
              "      <td>0.392769</td>\n",
              "      <td>0.569428</td>\n",
              "      <td>0.997119</td>\n",
              "      <td>0.997119</td>\n",
              "      <td>0.003082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtgrande_paolo vallesi.txt</td>\n",
              "      <td>Paolo: Yo soy quien, se dormía en las clases d...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.498606</td>\n",
              "      <td>0.498606</td>\n",
              "      <td>0.450495</td>\n",
              "      <td>0.997040</td>\n",
              "      <td>0.997040</td>\n",
              "      <td>0.003022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3578</th>\n",
              "      <td>lyricstxtCant Feel My Face_The Weeknd.txt</td>\n",
              "      <td>I can't feel my face when I'm with you\\nBut I ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994051</td>\n",
              "      <td>0.004910</td>\n",
              "      <td>0.994051</td>\n",
              "      <td>0.996978</td>\n",
              "      <td>0.996978</td>\n",
              "      <td>0.003009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtScatman_Scatman john.txt</td>\n",
              "      <td>I'm the Scatman\\nSki-bi dibby dib yo da dub du...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.754303</td>\n",
              "      <td>0.199873</td>\n",
              "      <td>0.754303</td>\n",
              "      <td>0.996891</td>\n",
              "      <td>0.996891</td>\n",
              "      <td>0.003088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17312</th>\n",
              "      <td>lyricstxtI Really Like You_Carly Rae Jepsen.txt</td>\n",
              "      <td>Who gave you eyes like that?\\nSaid you could k...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.865534</td>\n",
              "      <td>0.110881</td>\n",
              "      <td>0.865534</td>\n",
              "      <td>0.996621</td>\n",
              "      <td>0.996621</td>\n",
              "      <td>0.003286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17397</th>\n",
              "      <td>lyricstxtNobody told me_John Lennon.txt</td>\n",
              "      <td>Everybody's smoking and no one's getting high\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.854194</td>\n",
              "      <td>0.112793</td>\n",
              "      <td>0.854194</td>\n",
              "      <td>0.996889</td>\n",
              "      <td>0.003313</td>\n",
              "      <td>0.996889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17401</th>\n",
              "      <td>lyricstxtNumb_U2.txt</td>\n",
              "      <td>Don't struggle\\nDon't jerk\\nDon't collar\\nDon'...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.793198</td>\n",
              "      <td>0.163980</td>\n",
              "      <td>0.793198</td>\n",
              "      <td>0.996888</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.996888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17403</th>\n",
              "      <td>lyricstxtHave you seen her_MC hammer.txt</td>\n",
              "      <td>I see her face and I can't let go\\nShe's in my...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.705960</td>\n",
              "      <td>0.243503</td>\n",
              "      <td>0.705960</td>\n",
              "      <td>0.996885</td>\n",
              "      <td>0.003299</td>\n",
              "      <td>0.996885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17404</th>\n",
              "      <td>lyricstxtHappy _Pharrell Williams.txt</td>\n",
              "      <td>(Because I'm happy)\\nClap along if you feel li...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.744704</td>\n",
              "      <td>0.211503</td>\n",
              "      <td>0.744704</td>\n",
              "      <td>0.996867</td>\n",
              "      <td>0.003258</td>\n",
              "      <td>0.996867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17405</th>\n",
              "      <td>lyricstxtMagic_Coldplay.txt</td>\n",
              "      <td>And I don't, and I don't, and I don't, and I d...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.747309</td>\n",
              "      <td>0.207083</td>\n",
              "      <td>0.747309</td>\n",
              "      <td>0.996841</td>\n",
              "      <td>0.003217</td>\n",
              "      <td>0.996841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17407 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e395751c-9b58-4350-97d6-0f1347b19f53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e395751c-9b58-4350-97d6-0f1347b19f53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e395751c-9b58-4350-97d6-0f1347b19f53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "final_df = lyfinal_df.sort_values('probability_sexist', ascending=False)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXa4M0RdLLI6"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('DEF_labeled_df.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}