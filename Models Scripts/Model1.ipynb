{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM Trained with Lyrics from the years 60s, 70s, 2020 and 2021**\n",
        "\n"
      ],
      "metadata": {
        "id": "04q8uyqKdVWM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQoOE5Ec24L"
      },
      "source": [
        "## **0.File Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMqTVkmgGSk"
      },
      "source": [
        "### **0.1 Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DoSHPrgEfJ",
        "outputId": "3abc107f-b518-4617-dee2-c51b49761d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laserembeddings\n",
            "  Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.21.6)\n",
            "Collecting transliterate==1.10.2\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.11.0+cu113)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 19.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=5ab4cd9ffd7ab1a504b830d105ae07af701648f0081f64cf33474f8ed4fce73c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: mock, transliterate, subword-nmt, sacremoses, laserembeddings\n",
            "Successfully installed laserembeddings-1.1.2 mock-4.0.3 sacremoses-0.0.35 subword-nmt-0.3.8 transliterate-1.10.2\n",
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ]
        }
      ],
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzrJE1c_gP0i"
      },
      "source": [
        "### **0.2 Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-k-wVfCdBlc",
        "outputId": "35dd1a35-d84c-4626-eb22-dee2909ed220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "#Text Processing\n",
        "import string\n",
        "import re\n",
        "\n",
        "#Modeling\n",
        "#from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Reshaping datasets to tensors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "#for Colab file dealing\n",
        "import glob\n",
        "#You can mount your Google Drive files by running the following code snippet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # Now all files in: /content/gdrive/My Drive/location_of_the_file\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnKduo33J5RC"
      },
      "outputs": [],
      "source": [
        "#Laser\n",
        "from laserembeddings import Laser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0JtAv0glFX"
      },
      "source": [
        "### **0.3 Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.1 For Text Processing**"
      ],
      "metadata": {
        "id": "dmQJFQqzbNmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdZ97fBMgsW7"
      },
      "outputs": [],
      "source": [
        "def tweet_preprocessing(text_data):\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "            # hashtags -> words, URLs -> URL and mentions -> USER\n",
        "            text = re.sub('#', '', text)\n",
        "            text = re.sub('((www\\.[\\\\s]+)|(https?://[^\\\\s]+))', 'URL', text)\n",
        "            text = re.sub('@[A-Za-z0-9_-]+', 'USER', text)\n",
        "            text = re.sub('RT @[A-Za-z0-9_-]+:', 'USER', text)\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('\\!', ' ', text) # !\n",
        "            text = re.sub('\\?', ' ', text) # ?\n",
        "            text = re.sub('\\W', ' ', text) # symbols\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('[\\s]+', ' ', text) # spaces\n",
        "            text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text) # remove spaces between numbers\n",
        "            preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C8ayV2QpLmq"
      },
      "outputs": [],
      "source": [
        "def lyrics_preprocessing(text_data):\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "      text = str(text).strip()\n",
        "      text = re.sub('\\[', '', text)\n",
        "      text = re.sub('\\]', '', text)\n",
        "      text = re.sub('\\_', ' ', text) # _\n",
        "      text = re.sub('\\!', ' ', text) # !\n",
        "      text = re.sub('\\?', ' ', text) # ?\n",
        "      text = re.sub('\\W', ' ', text) # symbols\n",
        "      text = re.sub('\\-', ' ', text) # -\n",
        "      text = re.sub('[\\s]+', ' ', text) # spaces\n",
        "\n",
        "      text = re.sub(\"[\\[].*?\\]\", \"\", text)#delete everything between square brackets\n",
        "\n",
        "      # Get rid of Genius watermarks\n",
        "      text = re.sub(\"EmbedShare URLCopyEmbedCopy\", '', text) \n",
        "      text = re.sub(\"EmbedShareURLCopyEmbedCopy\", '', text) \n",
        "\n",
        "\n",
        "      preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8tmtMayqQK"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_preprocessed (Files, mypath, df):\n",
        "  #paragraphs \n",
        "  titles = []\n",
        "  paragraphs = []\n",
        "  for i in range(len(Files)):\n",
        "    f = open(mypath+'/'+Files[i], 'r')\n",
        "\n",
        "    data = f.read()\n",
        "    data_splited = data.split(\"\\n\\n\")\n",
        "    \n",
        "\n",
        "    for j in data_splited:\n",
        "      titles.append(Files[i])\n",
        "      unwanted = j.split(\"\\n\")\n",
        "      wanted = []\n",
        "      \n",
        "      if '[' in unwanted[0]:\n",
        "        wanted = unwanted[1:]\n",
        "        j = \"\\n\".join(wanted)\n",
        "\n",
        "      paragraphs.append(j)\n",
        "\n",
        "  df['title'] = titles\n",
        "  df['paragraph'] = paragraphs\n",
        "  \n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.2 For Model Evaluation**"
      ],
      "metadata": {
        "id": "gRmHd-oSbR06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 evaluation\n",
        "def f1(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"
      ],
      "metadata": {
        "id": "lri1ggxPbU4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.3 For Labeling**"
      ],
      "metadata": {
        "id": "DUEaiPy-bUJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def del_labeled(list_files, list_titles):\n",
        "  for fl in list_files:\n",
        "    if fl in list_titles:\n",
        "      list_files.remove(fl)\n",
        "  return list_files"
      ],
      "metadata": {
        "id": "FWEXtRAYb9kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labeling (l_embeddings, df):\n",
        "  Xnew = tf.reshape(l_embeddings, [-1, 1, 1024])\n",
        "\n",
        "  probs=model.predict(Xnew) \n",
        "  \n",
        "  #The first value of the prediction is for class 0 and the second for class 1 \n",
        "\n",
        "  ynew = []\n",
        "  probabilities = []\n",
        "  psxist = []\n",
        "  p_not_sxist = []\n",
        "  c=0\n",
        "  for item in probs:\n",
        "    if item[0][0]>item[0][1]:\n",
        "      y = 0\n",
        "      probability = item[0][0]  \n",
        "    else:\n",
        "      y = 1\n",
        "      probability = item[0][1]\n",
        "    p_not_sxist = np.append(p_not_sxist, item[0][0])\n",
        "    psxist = np.append(psxist, item[0][1])\n",
        "    c+=1\n",
        "    ynew = np.append(ynew, y)\n",
        "    probabilities = np.append(probabilities, probability)\n",
        "\n",
        "  df['label'] = ynew.astype('int')\n",
        "  df['label probability'] = probabilities\n",
        "  df['probability_sexist'] = psxist\n",
        "  df['probability_NOT_sexist'] = p_not_sxist\n",
        "  \n",
        "  df = df.sort_values('probability_sexist', ascending=False)\n",
        "  \n",
        "  return df "
      ],
      "metadata": {
        "id": "5NUHhzkZbdxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1t9ZT8Zc8Kg"
      },
      "source": [
        "## **1. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3S3-7TQly-g"
      },
      "outputs": [],
      "source": [
        "# Pharagraphs to train and test \n",
        "labeled_2021 = '/content/gdrive/My Drive/predicted_2021.csv' #365\n",
        "labeled_60s = '/content/gdrive/My Drive/predicted_60s.csv' #665\n",
        "\n",
        "l2021_df = pd.read_csv(labeled_2021)\n",
        "l60s_df = pd.read_csv(labeled_60s)\n",
        "\n",
        "#dataframe to be used\n",
        "tdf = pd.concat([l2021_df, l60s_df])\n",
        "tdf = tdf.dropna(subset=['true_label (0,1 or NA)'])\n",
        "tdf = tdf.replace([1.0, 0.0],[1,0])\n",
        "tdf = tdf[(tdf['true_label (0,1 or NA)'] != 'NAP')]\n",
        "pd.to_numeric(tdf['true_label (0,1 or NA)'], downcast = 'integer')\n",
        "tdf['true_label (0,1 or NA)']= pd.to_numeric(tdf['true_label (0,1 or NA)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Lyrics to be Labeled**"
      ],
      "metadata": {
        "id": "gwtIIw-vhFin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lyrics to be labeled \n",
        "mypath80s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1980-1989'\n",
        "mypath90s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1990-1999'\n",
        "mypath00s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2000-2009'\n",
        "mypath10s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2010-2019'\n",
        "mypath21s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2020-2021'\n",
        "\n",
        "\n",
        "mypaths = [mypath80s, mypath90s, mypath00s, mypath10s, mypath21s]\n",
        "\n",
        "Files80s = [f for f in listdir(mypath80s) if isfile(join(mypath80s, f))]\n",
        "Files90s = [f for f in listdir(mypath90s) if isfile(join(mypath90s, f))]\n",
        "Files00s = [f for f in listdir(mypath00s) if isfile(join(mypath00s, f))]\n",
        "Files10s = [f for f in listdir(mypath10s) if isfile(join(mypath10s, f))]\n",
        "Files21s = [f for f in listdir(mypath21s) if isfile(join(mypath21s, f))]\n",
        "\n",
        "\n",
        "#Eliminate songs that are already labeled\n",
        "titles = tdf['title'].tolist()\n",
        "\n",
        "\n",
        "\n",
        "Files21s = del_labeled(Files21s, titles)\n",
        "\n",
        "Files = [Files80s, Files90s, Files00s, Files10s, Files21s]\n",
        "\n",
        "\n",
        "cols=['title', 'paragraph', 'label', 'decade']\n",
        "lyrics_df = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "i = 0\n",
        "lyrics_df_list = []\n",
        "decade = 1980\n",
        "for path in mypaths: \n",
        "  new_ly_df = pd.DataFrame(columns=cols)\n",
        "  lyrics_df = get_paragraphs_preprocessed(Files[i], path, new_ly_df)\n",
        "  lyrics_df['decade'] = decade\n",
        "  decade+=10\n",
        "  lyrics_df_list.append(lyrics_df)\n",
        "  i+=1\n",
        "\n",
        "lyrics_df = pd.concat(lyrics_df_list)\n",
        "\n",
        "lyrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Nh8TzO6RhkSV",
        "outputId": "203989d7-cf6f-44b9-a4db-87c7a476e3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     title  \\\n",
              "0               lyricstxtSin amor_Ivan.txt   \n",
              "1               lyricstxtSin amor_Ivan.txt   \n",
              "2               lyricstxtSin amor_Ivan.txt   \n",
              "3               lyricstxtSin amor_Ivan.txt   \n",
              "4               lyricstxtSin amor_Ivan.txt   \n",
              "..                                     ...   \n",
              "813  lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "814  lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "815  lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "816  lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "817  lyricstxtYo x Ti Tu x Mi_ROSALçA.txt   \n",
              "\n",
              "                                             paragraph label  decade  \n",
              "0    Me bebo la penúltima cerveza\\nSin respirar\\nMe...   NaN    1980  \n",
              "1    No aguanto en casa solo\\nSin nada que hacer\\nH...   NaN    1980  \n",
              "2    Sin, sin, sin amor\\nMe siento libre pero algo ...   NaN    1980  \n",
              "3    Sin, sin, sin amor\\nMe siento libre pero algo ...   NaN    1980  \n",
              "4    Sin, sin, sin amor\\nMe siento libre pero algo ...   NaN    1980  \n",
              "..                                                 ...   ...     ...  \n",
              "813  Colgando del cuello los juguete' (Del cuello l...   NaN    2020  \n",
              "814  Somos dos cantantes como los de ante'\\nEl resp...   NaN    2020  \n",
              "815  (Woh-oh, oh-oh)\\nY yo por ti, tú por mí, ¿quié...   NaN    2020  \n",
              "816  Somos dos cantantes como los de ante'\\nEl resp...   NaN    2020  \n",
              "817  La Rosalía\\nMira, ¿quién lo diría (¿Qué?), que...   NaN    2020  \n",
              "\n",
              "[18942 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e2eb1dc-97b8-4264-b5f9-7c925a4fdfae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>decade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxtSin amor_Ivan.txt</td>\n",
              "      <td>Me bebo la penúltima cerveza\\nSin respirar\\nMe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxtSin amor_Ivan.txt</td>\n",
              "      <td>No aguanto en casa solo\\nSin nada que hacer\\nH...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxtSin amor_Ivan.txt</td>\n",
              "      <td>Sin, sin, sin amor\\nMe siento libre pero algo ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxtSin amor_Ivan.txt</td>\n",
              "      <td>Sin, sin, sin amor\\nMe siento libre pero algo ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxtSin amor_Ivan.txt</td>\n",
              "      <td>Sin, sin, sin amor\\nMe siento libre pero algo ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Colgando del cuello los juguete' (Del cuello l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Somos dos cantantes como los de ante'\\nEl resp...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>(Woh-oh, oh-oh)\\nY yo por ti, tú por mí, ¿quié...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>Somos dos cantantes como los de ante'\\nEl resp...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>lyricstxtYo x Ti Tu x Mi_ROSALçA.txt</td>\n",
              "      <td>La Rosalía\\nMira, ¿quién lo diría (¿Qué?), que...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18942 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e2eb1dc-97b8-4264-b5f9-7c925a4fdfae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e2eb1dc-97b8-4264-b5f9-7c925a4fdfae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e2eb1dc-97b8-4264-b5f9-7c925a4fdfae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5jif2KuyI91"
      },
      "source": [
        "## **3.LSTM Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 Data Preparation**"
      ],
      "metadata": {
        "id": "dSFl8IzNhRRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laser = Laser() # importing class for using embeddings extraction"
      ],
      "metadata": {
        "id": "JN2___mqiEgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#processed dataframe\n",
        "X_tobe_processed = tdf['paragraph']\n",
        "\n",
        "X_processed = lyrics_preprocessing(X_tobe_processed)\n",
        "X_embeddings = laser.embed_sentences(X_processed, lang = 'es')\n",
        "\n",
        "y = tdf['true_label (0,1 or NA)']"
      ],
      "metadata": {
        "id": "QuT6FBsWhysp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjlqlw3ffEib"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtgGcWYsyPFl"
      },
      "source": [
        "### **3.2 Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Oh78kMTEVME",
        "outputId": "4f5fc7ed-0fc0-4972-9f78-671ef382b24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (690, 1, 1024) (690, 1, 2)\n",
            "Test data shapes: (340, 1, 1024) (340, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 8s 117ms/step - loss: 0.6653 - accuracy: 0.6203 - f1: 0.5241 - auc: 0.6212 - val_loss: 0.6707 - val_accuracy: 0.6029 - val_f1: 0.5344 - val_auc: 0.7246\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6577 - accuracy: 0.6203 - f1: 0.5351 - auc: 0.6846 - val_loss: 0.6570 - val_accuracy: 0.6029 - val_f1: 0.5341 - val_auc: 0.7817\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6337 - accuracy: 0.6203 - f1: 0.5422 - auc: 0.8017 - val_loss: 0.6198 - val_accuracy: 0.6029 - val_f1: 0.5535 - val_auc: 0.7933\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5649 - accuracy: 0.6957 - f1: 0.5799 - auc: 0.8352 - val_loss: 0.5274 - val_accuracy: 0.7765 - val_f1: 0.6082 - val_auc: 0.8660\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.8536 - f1: 0.6603 - auc: 0.9193 - val_loss: 0.4333 - val_accuracy: 0.8118 - val_f1: 0.7028 - val_auc: 0.8881\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3486 - accuracy: 0.8667 - f1: 0.7562 - auc: 0.9326 - val_loss: 0.3611 - val_accuracy: 0.8529 - val_f1: 0.7693 - val_auc: 0.9207\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2976 - accuracy: 0.8783 - f1: 0.8114 - auc: 0.9466 - val_loss: 0.3419 - val_accuracy: 0.8471 - val_f1: 0.8028 - val_auc: 0.9287\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2578 - accuracy: 0.8986 - f1: 0.8418 - auc: 0.9605 - val_loss: 0.3884 - val_accuracy: 0.8412 - val_f1: 0.8019 - val_auc: 0.9160\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2477 - accuracy: 0.8913 - f1: 0.8501 - auc: 0.9646 - val_loss: 0.3344 - val_accuracy: 0.8382 - val_f1: 0.8187 - val_auc: 0.9353\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2046 - accuracy: 0.9159 - f1: 0.8665 - auc: 0.9760 - val_loss: 0.3101 - val_accuracy: 0.8676 - val_f1: 0.8271 - val_auc: 0.9430\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1772 - accuracy: 0.9362 - f1: 0.8789 - auc: 0.9827 - val_loss: 0.3371 - val_accuracy: 0.8500 - val_f1: 0.8214 - val_auc: 0.9359\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1487 - accuracy: 0.9464 - f1: 0.8942 - auc: 0.9890 - val_loss: 0.3040 - val_accuracy: 0.8647 - val_f1: 0.8384 - val_auc: 0.9469\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1375 - accuracy: 0.9536 - f1: 0.9026 - auc: 0.9902 - val_loss: 0.3038 - val_accuracy: 0.8735 - val_f1: 0.8466 - val_auc: 0.9492\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1085 - accuracy: 0.9652 - f1: 0.9224 - auc: 0.9942 - val_loss: 0.3126 - val_accuracy: 0.8676 - val_f1: 0.8504 - val_auc: 0.9499\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0866 - accuracy: 0.9768 - f1: 0.9348 - auc: 0.9966 - val_loss: 0.3183 - val_accuracy: 0.8853 - val_f1: 0.8586 - val_auc: 0.9491\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9855 - f1: 0.9460 - auc: 0.9980 - val_loss: 0.3274 - val_accuracy: 0.8824 - val_f1: 0.8624 - val_auc: 0.9509\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0599 - accuracy: 0.9812 - f1: 0.9545 - auc: 0.9985 - val_loss: 0.3404 - val_accuracy: 0.8765 - val_f1: 0.8644 - val_auc: 0.9509\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0563 - accuracy: 0.9870 - f1: 0.9569 - auc: 0.9988 - val_loss: 0.4204 - val_accuracy: 0.8529 - val_f1: 0.8466 - val_auc: 0.9330\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0449 - accuracy: 0.9899 - f1: 0.9656 - auc: 0.9991 - val_loss: 0.4168 - val_accuracy: 0.8676 - val_f1: 0.8535 - val_auc: 0.9356\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9928 - f1: 0.9705 - auc: 0.9996 - val_loss: 0.3823 - val_accuracy: 0.8794 - val_f1: 0.8712 - val_auc: 0.9497\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 87.94%\n",
            "F1: 86.80%\n",
            "AUC: 94.97%\n",
            "Loss: 0.38%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 125ms/step - loss: 0.6665 - accuracy: 0.6203 - f1: 0.5188 - auc: 0.6312 - val_loss: 0.6707 - val_accuracy: 0.6029 - val_f1: 0.5302 - val_auc: 0.7418\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6595 - accuracy: 0.6203 - f1: 0.5390 - auc: 0.6946 - val_loss: 0.6621 - val_accuracy: 0.6029 - val_f1: 0.5404 - val_auc: 0.7818\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6358 - accuracy: 0.6203 - f1: 0.5487 - auc: 0.8076 - val_loss: 0.6213 - val_accuracy: 0.6029 - val_f1: 0.5560 - val_auc: 0.7956\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5679 - accuracy: 0.6710 - f1: 0.5826 - auc: 0.8254 - val_loss: 0.5283 - val_accuracy: 0.7618 - val_f1: 0.6104 - val_auc: 0.8560\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4431 - accuracy: 0.8522 - f1: 0.6641 - auc: 0.9202 - val_loss: 0.4097 - val_accuracy: 0.8412 - val_f1: 0.6989 - val_auc: 0.9185\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3423 - accuracy: 0.8783 - f1: 0.7595 - auc: 0.9348 - val_loss: 0.3540 - val_accuracy: 0.8441 - val_f1: 0.7724 - val_auc: 0.9239\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2902 - accuracy: 0.8841 - f1: 0.8172 - auc: 0.9501 - val_loss: 0.3446 - val_accuracy: 0.8441 - val_f1: 0.8043 - val_auc: 0.9278\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2760 - accuracy: 0.8884 - f1: 0.8398 - auc: 0.9549 - val_loss: 0.3515 - val_accuracy: 0.8471 - val_f1: 0.8119 - val_auc: 0.9284\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2348 - accuracy: 0.9043 - f1: 0.8563 - auc: 0.9680 - val_loss: 0.3458 - val_accuracy: 0.8412 - val_f1: 0.8142 - val_auc: 0.9314\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2293 - accuracy: 0.9072 - f1: 0.8540 - auc: 0.9694 - val_loss: 0.3167 - val_accuracy: 0.8676 - val_f1: 0.8212 - val_auc: 0.9400\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1841 - accuracy: 0.9319 - f1: 0.8773 - auc: 0.9811 - val_loss: 0.3099 - val_accuracy: 0.8647 - val_f1: 0.8268 - val_auc: 0.9440\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1662 - accuracy: 0.9319 - f1: 0.8860 - auc: 0.9857 - val_loss: 0.3626 - val_accuracy: 0.8324 - val_f1: 0.8161 - val_auc: 0.9306\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1584 - accuracy: 0.9319 - f1: 0.8911 - auc: 0.9865 - val_loss: 0.3031 - val_accuracy: 0.8647 - val_f1: 0.8402 - val_auc: 0.9480\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1223 - accuracy: 0.9623 - f1: 0.9134 - auc: 0.9918 - val_loss: 0.3060 - val_accuracy: 0.8706 - val_f1: 0.8469 - val_auc: 0.9489\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1081 - accuracy: 0.9681 - f1: 0.9231 - auc: 0.9933 - val_loss: 0.3243 - val_accuracy: 0.8706 - val_f1: 0.8458 - val_auc: 0.9477\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.9710 - f1: 0.9352 - auc: 0.9957 - val_loss: 0.3413 - val_accuracy: 0.8706 - val_f1: 0.8462 - val_auc: 0.9454\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0734 - accuracy: 0.9826 - f1: 0.9465 - auc: 0.9970 - val_loss: 0.3598 - val_accuracy: 0.8618 - val_f1: 0.8468 - val_auc: 0.9429\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0620 - accuracy: 0.9826 - f1: 0.9554 - auc: 0.9978 - val_loss: 0.3355 - val_accuracy: 0.8794 - val_f1: 0.8645 - val_auc: 0.9511\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0465 - accuracy: 0.9913 - f1: 0.9644 - auc: 0.9989 - val_loss: 0.3479 - val_accuracy: 0.8765 - val_f1: 0.8659 - val_auc: 0.9509\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0387 - accuracy: 0.9971 - f1: 0.9699 - auc: 0.9991 - val_loss: 0.3634 - val_accuracy: 0.8735 - val_f1: 0.8643 - val_auc: 0.9509\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 87.35%\n",
            "F1: 86.24%\n",
            "AUC: 95.09%\n",
            "Loss: 0.36%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 120ms/step - loss: 0.8088 - accuracy: 0.3797 - f1: 0.5336 - auc: 0.3633 - val_loss: 0.7244 - val_accuracy: 0.3971 - val_f1: 0.5423 - val_auc: 0.3707\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5507 - f1: 0.5310 - auc: 0.5725 - val_loss: 0.6882 - val_accuracy: 0.6029 - val_f1: 0.5102 - val_auc: 0.6302\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6757 - accuracy: 0.6203 - f1: 0.5199 - auc: 0.6247 - val_loss: 0.6716 - val_accuracy: 0.6029 - val_f1: 0.5359 - val_auc: 0.6690\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6595 - accuracy: 0.6203 - f1: 0.5435 - auc: 0.6777 - val_loss: 0.6638 - val_accuracy: 0.6029 - val_f1: 0.5445 - val_auc: 0.7306\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6483 - accuracy: 0.6203 - f1: 0.5459 - auc: 0.7493 - val_loss: 0.6482 - val_accuracy: 0.6029 - val_f1: 0.5411 - val_auc: 0.7817\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6221 - accuracy: 0.6203 - f1: 0.5495 - auc: 0.8048 - val_loss: 0.6135 - val_accuracy: 0.6029 - val_f1: 0.5563 - val_auc: 0.7965\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5656 - accuracy: 0.6217 - f1: 0.5843 - auc: 0.8198 - val_loss: 0.5483 - val_accuracy: 0.6265 - val_f1: 0.6085 - val_auc: 0.8027\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4786 - accuracy: 0.7812 - f1: 0.6473 - auc: 0.8741 - val_loss: 0.4547 - val_accuracy: 0.8353 - val_f1: 0.6734 - val_auc: 0.8879\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3793 - accuracy: 0.8580 - f1: 0.7211 - auc: 0.9267 - val_loss: 0.3855 - val_accuracy: 0.8353 - val_f1: 0.7276 - val_auc: 0.9186\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3224 - accuracy: 0.8768 - f1: 0.7781 - auc: 0.9397 - val_loss: 0.3517 - val_accuracy: 0.8500 - val_f1: 0.7884 - val_auc: 0.9238\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 0.8899 - f1: 0.8264 - auc: 0.9525 - val_loss: 0.3449 - val_accuracy: 0.8500 - val_f1: 0.8076 - val_auc: 0.9289\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2486 - accuracy: 0.9058 - f1: 0.8493 - auc: 0.9635 - val_loss: 0.3412 - val_accuracy: 0.8471 - val_f1: 0.8136 - val_auc: 0.9328\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2302 - accuracy: 0.9145 - f1: 0.8583 - auc: 0.9699 - val_loss: 0.3221 - val_accuracy: 0.8618 - val_f1: 0.8215 - val_auc: 0.9394\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1963 - accuracy: 0.9319 - f1: 0.8712 - auc: 0.9793 - val_loss: 0.3200 - val_accuracy: 0.8676 - val_f1: 0.8249 - val_auc: 0.9421\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1723 - accuracy: 0.9362 - f1: 0.8844 - auc: 0.9836 - val_loss: 0.3160 - val_accuracy: 0.8618 - val_f1: 0.8294 - val_auc: 0.9441\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1586 - accuracy: 0.9493 - f1: 0.8922 - auc: 0.9864 - val_loss: 0.3151 - val_accuracy: 0.8647 - val_f1: 0.8352 - val_auc: 0.9452\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1268 - accuracy: 0.9652 - f1: 0.9096 - auc: 0.9918 - val_loss: 0.3192 - val_accuracy: 0.8765 - val_f1: 0.8436 - val_auc: 0.9451\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1179 - accuracy: 0.9609 - f1: 0.9185 - auc: 0.9920 - val_loss: 0.3235 - val_accuracy: 0.8676 - val_f1: 0.8473 - val_auc: 0.9470\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0921 - accuracy: 0.9754 - f1: 0.9345 - auc: 0.9955 - val_loss: 0.3536 - val_accuracy: 0.8794 - val_f1: 0.8505 - val_auc: 0.9377\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1039 - accuracy: 0.9681 - f1: 0.9291 - auc: 0.9941 - val_loss: 0.3361 - val_accuracy: 0.8765 - val_f1: 0.8588 - val_auc: 0.9482\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 87.65%\n",
            "F1: 85.39%\n",
            "AUC: 94.82%\n",
            "Loss: 0.34%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 117ms/step - loss: 0.6946 - accuracy: 0.6203 - f1: 0.4632 - auc: 0.6147 - val_loss: 0.6740 - val_accuracy: 0.6029 - val_f1: 0.5063 - val_auc: 0.6350\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6635 - accuracy: 0.6203 - f1: 0.5323 - auc: 0.6453 - val_loss: 0.6709 - val_accuracy: 0.6029 - val_f1: 0.5472 - val_auc: 0.7294\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6561 - accuracy: 0.6203 - f1: 0.5479 - auc: 0.7154 - val_loss: 0.6559 - val_accuracy: 0.6029 - val_f1: 0.5424 - val_auc: 0.7913\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6308 - accuracy: 0.6203 - f1: 0.5445 - auc: 0.7972 - val_loss: 0.6168 - val_accuracy: 0.6029 - val_f1: 0.5567 - val_auc: 0.7963\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5728 - accuracy: 0.6333 - f1: 0.5872 - auc: 0.8119 - val_loss: 0.5420 - val_accuracy: 0.7206 - val_f1: 0.6082 - val_auc: 0.8274\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4650 - accuracy: 0.8377 - f1: 0.6532 - auc: 0.9091 - val_loss: 0.4408 - val_accuracy: 0.8088 - val_f1: 0.6949 - val_auc: 0.8865\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3528 - accuracy: 0.8754 - f1: 0.7454 - auc: 0.9360 - val_loss: 0.3807 - val_accuracy: 0.8235 - val_f1: 0.7624 - val_auc: 0.9102\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3076 - accuracy: 0.8826 - f1: 0.8086 - auc: 0.9416 - val_loss: 0.3483 - val_accuracy: 0.8412 - val_f1: 0.8004 - val_auc: 0.9264\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2691 - accuracy: 0.8942 - f1: 0.8389 - auc: 0.9568 - val_loss: 0.3426 - val_accuracy: 0.8471 - val_f1: 0.8133 - val_auc: 0.9307\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2489 - accuracy: 0.9043 - f1: 0.8498 - auc: 0.9622 - val_loss: 0.3410 - val_accuracy: 0.8559 - val_f1: 0.8133 - val_auc: 0.9312\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2127 - accuracy: 0.9275 - f1: 0.8658 - auc: 0.9733 - val_loss: 0.3278 - val_accuracy: 0.8500 - val_f1: 0.8198 - val_auc: 0.9380\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1982 - accuracy: 0.9217 - f1: 0.8713 - auc: 0.9776 - val_loss: 0.3459 - val_accuracy: 0.8324 - val_f1: 0.8164 - val_auc: 0.9330\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1781 - accuracy: 0.9304 - f1: 0.8809 - auc: 0.9820 - val_loss: 0.3245 - val_accuracy: 0.8765 - val_f1: 0.8308 - val_auc: 0.9391\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1764 - accuracy: 0.9362 - f1: 0.8861 - auc: 0.9816 - val_loss: 0.3284 - val_accuracy: 0.8676 - val_f1: 0.8364 - val_auc: 0.9394\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1480 - accuracy: 0.9449 - f1: 0.9012 - auc: 0.9879 - val_loss: 0.3498 - val_accuracy: 0.8500 - val_f1: 0.8307 - val_auc: 0.9366\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9667 - f1: 0.9195 - auc: 0.9933 - val_loss: 0.3210 - val_accuracy: 0.8735 - val_f1: 0.8485 - val_auc: 0.9471\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0993 - accuracy: 0.9681 - f1: 0.9300 - auc: 0.9946 - val_loss: 0.3238 - val_accuracy: 0.8735 - val_f1: 0.8540 - val_auc: 0.9485\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9797 - f1: 0.9403 - auc: 0.9964 - val_loss: 0.3374 - val_accuracy: 0.8618 - val_f1: 0.8508 - val_auc: 0.9477\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0762 - accuracy: 0.9826 - f1: 0.9449 - auc: 0.9969 - val_loss: 0.3694 - val_accuracy: 0.8500 - val_f1: 0.8435 - val_auc: 0.9414\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.9870 - f1: 0.9548 - auc: 0.9987 - val_loss: 0.3537 - val_accuracy: 0.8765 - val_f1: 0.8623 - val_auc: 0.9474\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 87.65%\n",
            "F1: 85.77%\n",
            "AUC: 94.74%\n",
            "Loss: 0.35%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 118ms/step - loss: 0.6892 - accuracy: 0.5333 - f1: 0.4899 - auc: 0.5589 - val_loss: 0.6721 - val_accuracy: 0.6029 - val_f1: 0.5118 - val_auc: 0.6683\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6627 - accuracy: 0.6203 - f1: 0.5295 - auc: 0.6640 - val_loss: 0.6697 - val_accuracy: 0.6029 - val_f1: 0.5416 - val_auc: 0.7661\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6509 - accuracy: 0.6203 - f1: 0.5473 - auc: 0.7871 - val_loss: 0.6492 - val_accuracy: 0.6029 - val_f1: 0.5470 - val_auc: 0.7920\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6172 - accuracy: 0.6203 - f1: 0.5613 - auc: 0.7988 - val_loss: 0.6042 - val_accuracy: 0.6029 - val_f1: 0.5843 - val_auc: 0.8002\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5318 - accuracy: 0.7000 - f1: 0.6143 - auc: 0.8336 - val_loss: 0.4915 - val_accuracy: 0.8235 - val_f1: 0.6399 - val_auc: 0.8846\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4134 - accuracy: 0.8522 - f1: 0.6968 - auc: 0.9165 - val_loss: 0.3912 - val_accuracy: 0.8412 - val_f1: 0.7244 - val_auc: 0.9192\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3250 - accuracy: 0.8797 - f1: 0.7745 - auc: 0.9417 - val_loss: 0.3612 - val_accuracy: 0.8441 - val_f1: 0.7845 - val_auc: 0.9206\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.8928 - f1: 0.8246 - auc: 0.9495 - val_loss: 0.3395 - val_accuracy: 0.8618 - val_f1: 0.8095 - val_auc: 0.9307\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2550 - accuracy: 0.9000 - f1: 0.8477 - auc: 0.9621 - val_loss: 0.3336 - val_accuracy: 0.8559 - val_f1: 0.8183 - val_auc: 0.9356\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2234 - accuracy: 0.9087 - f1: 0.8613 - auc: 0.9711 - val_loss: 0.3157 - val_accuracy: 0.8735 - val_f1: 0.8252 - val_auc: 0.9408\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2013 - accuracy: 0.9261 - f1: 0.8714 - auc: 0.9761 - val_loss: 0.3230 - val_accuracy: 0.8765 - val_f1: 0.8233 - val_auc: 0.9378\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1833 - accuracy: 0.9333 - f1: 0.8769 - auc: 0.9819 - val_loss: 0.3164 - val_accuracy: 0.8559 - val_f1: 0.8286 - val_auc: 0.9438\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1495 - accuracy: 0.9435 - f1: 0.8953 - auc: 0.9889 - val_loss: 0.3318 - val_accuracy: 0.8588 - val_f1: 0.8291 - val_auc: 0.9418\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1509 - accuracy: 0.9478 - f1: 0.9001 - auc: 0.9868 - val_loss: 0.3574 - val_accuracy: 0.8382 - val_f1: 0.8268 - val_auc: 0.9363\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1149 - accuracy: 0.9652 - f1: 0.9209 - auc: 0.9915 - val_loss: 0.3131 - val_accuracy: 0.8706 - val_f1: 0.8503 - val_auc: 0.9490\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0886 - accuracy: 0.9768 - f1: 0.9365 - auc: 0.9955 - val_loss: 0.3209 - val_accuracy: 0.8676 - val_f1: 0.8553 - val_auc: 0.9500\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0751 - accuracy: 0.9797 - f1: 0.9460 - auc: 0.9969 - val_loss: 0.3475 - val_accuracy: 0.8618 - val_f1: 0.8507 - val_auc: 0.9460\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0627 - accuracy: 0.9913 - f1: 0.9545 - auc: 0.9976 - val_loss: 0.3412 - val_accuracy: 0.8706 - val_f1: 0.8652 - val_auc: 0.9490\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0491 - accuracy: 0.9928 - f1: 0.9637 - auc: 0.9983 - val_loss: 0.3599 - val_accuracy: 0.8706 - val_f1: 0.8622 - val_auc: 0.9490\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9942 - f1: 0.9694 - auc: 0.9988 - val_loss: 0.3678 - val_accuracy: 0.8765 - val_f1: 0.8690 - val_auc: 0.9489\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 87.65%\n",
            "F1: 86.42%\n",
            "AUC: 94.89%\n",
            "Loss: 0.37%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 109ms/step - loss: 0.7102 - accuracy: 0.6203 - f1: 0.4543 - auc: 0.6222 - val_loss: 0.6797 - val_accuracy: 0.6029 - val_f1: 0.4997 - val_auc: 0.6282\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.6203 - f1: 0.5313 - auc: 0.6294 - val_loss: 0.6717 - val_accuracy: 0.6029 - val_f1: 0.5510 - val_auc: 0.6895\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6557 - accuracy: 0.6203 - f1: 0.5472 - auc: 0.7064 - val_loss: 0.6542 - val_accuracy: 0.6029 - val_f1: 0.5393 - val_auc: 0.7776\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.6203 - f1: 0.5443 - auc: 0.8001 - val_loss: 0.6237 - val_accuracy: 0.6029 - val_f1: 0.5506 - val_auc: 0.7917\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5753 - accuracy: 0.6681 - f1: 0.5732 - auc: 0.8254 - val_loss: 0.5454 - val_accuracy: 0.7676 - val_f1: 0.5972 - val_auc: 0.8471\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4736 - accuracy: 0.8232 - f1: 0.6458 - auc: 0.9010 - val_loss: 0.4376 - val_accuracy: 0.8324 - val_f1: 0.6762 - val_auc: 0.9146\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3706 - accuracy: 0.8609 - f1: 0.7308 - auc: 0.9308 - val_loss: 0.3716 - val_accuracy: 0.8353 - val_f1: 0.7515 - val_auc: 0.9177\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3092 - accuracy: 0.8696 - f1: 0.7925 - auc: 0.9446 - val_loss: 0.3677 - val_accuracy: 0.8441 - val_f1: 0.7874 - val_auc: 0.9173\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2783 - accuracy: 0.8913 - f1: 0.8281 - auc: 0.9549 - val_loss: 0.3332 - val_accuracy: 0.8559 - val_f1: 0.8090 - val_auc: 0.9324\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 0.9029 - f1: 0.8497 - auc: 0.9653 - val_loss: 0.3330 - val_accuracy: 0.8529 - val_f1: 0.8178 - val_auc: 0.9350\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2114 - accuracy: 0.9072 - f1: 0.8629 - auc: 0.9750 - val_loss: 0.3116 - val_accuracy: 0.8706 - val_f1: 0.8248 - val_auc: 0.9424\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1894 - accuracy: 0.9203 - f1: 0.8729 - auc: 0.9803 - val_loss: 0.3111 - val_accuracy: 0.8618 - val_f1: 0.8273 - val_auc: 0.9439\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1585 - accuracy: 0.9362 - f1: 0.8877 - auc: 0.9873 - val_loss: 0.3080 - val_accuracy: 0.8588 - val_f1: 0.8331 - val_auc: 0.9455\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1402 - accuracy: 0.9536 - f1: 0.8998 - auc: 0.9901 - val_loss: 0.2983 - val_accuracy: 0.8706 - val_f1: 0.8440 - val_auc: 0.9494\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1360 - accuracy: 0.9522 - f1: 0.9049 - auc: 0.9905 - val_loss: 0.3305 - val_accuracy: 0.8618 - val_f1: 0.8385 - val_auc: 0.9425\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1230 - accuracy: 0.9580 - f1: 0.9140 - auc: 0.9922 - val_loss: 0.3862 - val_accuracy: 0.8353 - val_f1: 0.8283 - val_auc: 0.9306\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1095 - accuracy: 0.9652 - f1: 0.9261 - auc: 0.9934 - val_loss: 0.3201 - val_accuracy: 0.8706 - val_f1: 0.8532 - val_auc: 0.9487\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9754 - f1: 0.9345 - auc: 0.9955 - val_loss: 0.3478 - val_accuracy: 0.8765 - val_f1: 0.8535 - val_auc: 0.9423\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9768 - f1: 0.9425 - auc: 0.9961 - val_loss: 0.3347 - val_accuracy: 0.8735 - val_f1: 0.8598 - val_auc: 0.9481\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0575 - accuracy: 0.9870 - f1: 0.9584 - auc: 0.9983 - val_loss: 0.3524 - val_accuracy: 0.8706 - val_f1: 0.8593 - val_auc: 0.9469\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 87.06%\n",
            "F1: 85.69%\n",
            "AUC: 94.69%\n",
            "Loss: 0.35%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 175ms/step - loss: 0.6782 - accuracy: 0.5884 - f1: 0.5164 - auc: 0.6215 - val_loss: 0.6709 - val_accuracy: 0.6029 - val_f1: 0.5280 - val_auc: 0.6686\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6622 - accuracy: 0.6203 - f1: 0.5377 - auc: 0.6531 - val_loss: 0.6701 - val_accuracy: 0.6029 - val_f1: 0.5411 - val_auc: 0.7854\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6464 - accuracy: 0.6203 - f1: 0.5435 - auc: 0.7507 - val_loss: 0.6395 - val_accuracy: 0.6029 - val_f1: 0.5456 - val_auc: 0.7918\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5958 - accuracy: 0.6217 - f1: 0.5676 - auc: 0.8143 - val_loss: 0.5658 - val_accuracy: 0.6529 - val_f1: 0.5867 - val_auc: 0.8049\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4863 - accuracy: 0.7942 - f1: 0.6329 - auc: 0.8920 - val_loss: 0.4408 - val_accuracy: 0.8353 - val_f1: 0.6743 - val_auc: 0.9079\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3685 - accuracy: 0.8638 - f1: 0.7351 - auc: 0.9271 - val_loss: 0.3746 - val_accuracy: 0.8441 - val_f1: 0.7531 - val_auc: 0.9160\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3149 - accuracy: 0.8797 - f1: 0.8017 - auc: 0.9399 - val_loss: 0.3596 - val_accuracy: 0.8441 - val_f1: 0.7986 - val_auc: 0.9210\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2704 - accuracy: 0.8884 - f1: 0.8373 - auc: 0.9565 - val_loss: 0.3591 - val_accuracy: 0.8382 - val_f1: 0.8084 - val_auc: 0.9250\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2598 - accuracy: 0.8957 - f1: 0.8454 - auc: 0.9600 - val_loss: 0.3222 - val_accuracy: 0.8588 - val_f1: 0.8200 - val_auc: 0.9373\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2194 - accuracy: 0.9072 - f1: 0.8611 - auc: 0.9724 - val_loss: 0.3128 - val_accuracy: 0.8706 - val_f1: 0.8233 - val_auc: 0.9410\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9246 - f1: 0.8729 - auc: 0.9803 - val_loss: 0.3131 - val_accuracy: 0.8618 - val_f1: 0.8262 - val_auc: 0.9430\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1716 - accuracy: 0.9275 - f1: 0.8825 - auc: 0.9842 - val_loss: 0.3126 - val_accuracy: 0.8647 - val_f1: 0.8315 - val_auc: 0.9446\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1509 - accuracy: 0.9449 - f1: 0.8959 - auc: 0.9878 - val_loss: 0.3209 - val_accuracy: 0.8588 - val_f1: 0.8352 - val_auc: 0.9440\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1368 - accuracy: 0.9536 - f1: 0.9060 - auc: 0.9897 - val_loss: 0.3423 - val_accuracy: 0.8471 - val_f1: 0.8330 - val_auc: 0.9401\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1198 - accuracy: 0.9609 - f1: 0.9174 - auc: 0.9919 - val_loss: 0.3505 - val_accuracy: 0.8471 - val_f1: 0.8376 - val_auc: 0.9409\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.9739 - f1: 0.9362 - auc: 0.9965 - val_loss: 0.3304 - val_accuracy: 0.8647 - val_f1: 0.8528 - val_auc: 0.9477\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0749 - accuracy: 0.9783 - f1: 0.9450 - auc: 0.9974 - val_loss: 0.3358 - val_accuracy: 0.8824 - val_f1: 0.8620 - val_auc: 0.9482\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0579 - accuracy: 0.9870 - f1: 0.9553 - auc: 0.9987 - val_loss: 0.3482 - val_accuracy: 0.8794 - val_f1: 0.8636 - val_auc: 0.9488\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0459 - accuracy: 0.9884 - f1: 0.9636 - auc: 0.9993 - val_loss: 0.3611 - val_accuracy: 0.8794 - val_f1: 0.8652 - val_auc: 0.9487\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0389 - accuracy: 0.9928 - f1: 0.9686 - auc: 0.9996 - val_loss: 0.3766 - val_accuracy: 0.8824 - val_f1: 0.8682 - val_auc: 0.9467\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 88.24%\n",
            "F1: 86.22%\n",
            "AUC: 94.67%\n",
            "Loss: 0.38%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 120ms/step - loss: 0.7784 - accuracy: 0.3797 - f1: 0.4459 - auc: 0.3751 - val_loss: 0.7046 - val_accuracy: 0.3971 - val_f1: 0.4722 - val_auc: 0.3601\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5870 - f1: 0.5029 - auc: 0.5964 - val_loss: 0.6805 - val_accuracy: 0.6029 - val_f1: 0.5376 - val_auc: 0.6279\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6666 - accuracy: 0.6203 - f1: 0.5439 - auc: 0.6413 - val_loss: 0.6693 - val_accuracy: 0.6029 - val_f1: 0.5397 - val_auc: 0.7217\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6526 - accuracy: 0.6203 - f1: 0.5385 - auc: 0.7487 - val_loss: 0.6560 - val_accuracy: 0.6029 - val_f1: 0.5322 - val_auc: 0.7928\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6346 - accuracy: 0.6203 - f1: 0.5403 - auc: 0.8126 - val_loss: 0.6307 - val_accuracy: 0.6029 - val_f1: 0.5452 - val_auc: 0.7991\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5915 - accuracy: 0.6203 - f1: 0.5667 - auc: 0.8211 - val_loss: 0.5789 - val_accuracy: 0.6029 - val_f1: 0.5936 - val_auc: 0.8012\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5137 - accuracy: 0.6681 - f1: 0.6296 - auc: 0.8270 - val_loss: 0.4904 - val_accuracy: 0.7853 - val_f1: 0.6551 - val_auc: 0.8538\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4189 - accuracy: 0.8623 - f1: 0.6916 - auc: 0.9177 - val_loss: 0.4279 - val_accuracy: 0.8147 - val_f1: 0.7262 - val_auc: 0.8857\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8623 - f1: 0.7691 - auc: 0.9326 - val_loss: 0.3619 - val_accuracy: 0.8471 - val_f1: 0.7685 - val_auc: 0.9218\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2885 - accuracy: 0.8913 - f1: 0.8146 - auc: 0.9497 - val_loss: 0.3519 - val_accuracy: 0.8471 - val_f1: 0.8042 - val_auc: 0.9264\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2736 - accuracy: 0.8899 - f1: 0.8368 - auc: 0.9563 - val_loss: 0.3558 - val_accuracy: 0.8441 - val_f1: 0.8119 - val_auc: 0.9282\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2445 - accuracy: 0.9058 - f1: 0.8547 - auc: 0.9664 - val_loss: 0.3368 - val_accuracy: 0.8559 - val_f1: 0.8179 - val_auc: 0.9339\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2235 - accuracy: 0.9130 - f1: 0.8616 - auc: 0.9713 - val_loss: 0.3359 - val_accuracy: 0.8471 - val_f1: 0.8191 - val_auc: 0.9367\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9275 - f1: 0.8739 - auc: 0.9791 - val_loss: 0.3163 - val_accuracy: 0.8647 - val_f1: 0.8270 - val_auc: 0.9424\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9290 - f1: 0.8793 - auc: 0.9815 - val_loss: 0.3447 - val_accuracy: 0.8500 - val_f1: 0.8218 - val_auc: 0.9367\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1541 - accuracy: 0.9536 - f1: 0.8961 - auc: 0.9857 - val_loss: 0.3247 - val_accuracy: 0.8676 - val_f1: 0.8351 - val_auc: 0.9436\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1425 - accuracy: 0.9565 - f1: 0.9062 - auc: 0.9867 - val_loss: 0.3216 - val_accuracy: 0.8735 - val_f1: 0.8466 - val_auc: 0.9443\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1174 - accuracy: 0.9638 - f1: 0.9211 - auc: 0.9921 - val_loss: 0.3231 - val_accuracy: 0.8735 - val_f1: 0.8488 - val_auc: 0.9471\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 0.9739 - f1: 0.9333 - auc: 0.9939 - val_loss: 0.3376 - val_accuracy: 0.8618 - val_f1: 0.8481 - val_auc: 0.9454\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.9826 - f1: 0.9411 - auc: 0.9963 - val_loss: 0.3336 - val_accuracy: 0.8824 - val_f1: 0.8603 - val_auc: 0.9474\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 88.24%\n",
            "F1: 85.46%\n",
            "AUC: 94.74%\n",
            "Loss: 0.33%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 118ms/step - loss: 0.6658 - accuracy: 0.6203 - f1: 0.5146 - auc: 0.6466 - val_loss: 0.6714 - val_accuracy: 0.6029 - val_f1: 0.5304 - val_auc: 0.6664\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6583 - accuracy: 0.6203 - f1: 0.5405 - auc: 0.7315 - val_loss: 0.6610 - val_accuracy: 0.6029 - val_f1: 0.5430 - val_auc: 0.7868\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6326 - accuracy: 0.6203 - f1: 0.5521 - auc: 0.8052 - val_loss: 0.6158 - val_accuracy: 0.6029 - val_f1: 0.5605 - val_auc: 0.7967\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5555 - accuracy: 0.6899 - f1: 0.5910 - auc: 0.8369 - val_loss: 0.5144 - val_accuracy: 0.8118 - val_f1: 0.6169 - val_auc: 0.8805\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4308 - accuracy: 0.8435 - f1: 0.6740 - auc: 0.9227 - val_loss: 0.4016 - val_accuracy: 0.8265 - val_f1: 0.7187 - val_auc: 0.9086\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.8609 - f1: 0.7709 - auc: 0.9374 - val_loss: 0.3505 - val_accuracy: 0.8471 - val_f1: 0.7860 - val_auc: 0.9236\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2848 - accuracy: 0.8870 - f1: 0.8269 - auc: 0.9508 - val_loss: 0.3446 - val_accuracy: 0.8441 - val_f1: 0.8029 - val_auc: 0.9284\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2789 - accuracy: 0.8855 - f1: 0.8392 - auc: 0.9532 - val_loss: 0.3240 - val_accuracy: 0.8559 - val_f1: 0.8189 - val_auc: 0.9368\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2403 - accuracy: 0.9058 - f1: 0.8558 - auc: 0.9647 - val_loss: 0.3442 - val_accuracy: 0.8382 - val_f1: 0.8147 - val_auc: 0.9321\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2108 - accuracy: 0.9174 - f1: 0.8653 - auc: 0.9745 - val_loss: 0.3068 - val_accuracy: 0.8735 - val_f1: 0.8255 - val_auc: 0.9439\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1873 - accuracy: 0.9275 - f1: 0.8758 - auc: 0.9805 - val_loss: 0.3015 - val_accuracy: 0.8706 - val_f1: 0.8298 - val_auc: 0.9455\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1706 - accuracy: 0.9319 - f1: 0.8834 - auc: 0.9844 - val_loss: 0.3007 - val_accuracy: 0.8618 - val_f1: 0.8350 - val_auc: 0.9471\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1474 - accuracy: 0.9391 - f1: 0.8986 - auc: 0.9881 - val_loss: 0.3314 - val_accuracy: 0.8618 - val_f1: 0.8310 - val_auc: 0.9405\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1300 - accuracy: 0.9565 - f1: 0.9102 - auc: 0.9911 - val_loss: 0.3359 - val_accuracy: 0.8647 - val_f1: 0.8354 - val_auc: 0.9414\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1084 - accuracy: 0.9623 - f1: 0.9218 - auc: 0.9939 - val_loss: 0.3075 - val_accuracy: 0.8765 - val_f1: 0.8527 - val_auc: 0.9508\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0865 - accuracy: 0.9739 - f1: 0.9363 - auc: 0.9964 - val_loss: 0.3142 - val_accuracy: 0.8794 - val_f1: 0.8578 - val_auc: 0.9505\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0770 - accuracy: 0.9826 - f1: 0.9433 - auc: 0.9974 - val_loss: 0.3194 - val_accuracy: 0.8735 - val_f1: 0.8602 - val_auc: 0.9524\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0589 - accuracy: 0.9884 - f1: 0.9561 - auc: 0.9980 - val_loss: 0.3604 - val_accuracy: 0.8735 - val_f1: 0.8512 - val_auc: 0.9450\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0545 - accuracy: 0.9870 - f1: 0.9585 - auc: 0.9987 - val_loss: 0.3590 - val_accuracy: 0.8676 - val_f1: 0.8577 - val_auc: 0.9478\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0389 - accuracy: 0.9942 - f1: 0.9703 - auc: 0.9992 - val_loss: 0.3604 - val_accuracy: 0.8706 - val_f1: 0.8629 - val_auc: 0.9504\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 87.06%\n",
            "F1: 86.20%\n",
            "AUC: 95.04%\n",
            "Loss: 0.36%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 3s 116ms/step - loss: 0.7546 - accuracy: 0.6203 - f1: 0.3978 - auc: 0.5498 - val_loss: 0.6991 - val_accuracy: 0.6029 - val_f1: 0.4567 - val_auc: 0.6040\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.6203 - f1: 0.5088 - auc: 0.6295 - val_loss: 0.6849 - val_accuracy: 0.6029 - val_f1: 0.5557 - val_auc: 0.6437\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6681 - accuracy: 0.6203 - f1: 0.5492 - auc: 0.6439 - val_loss: 0.6667 - val_accuracy: 0.6029 - val_f1: 0.5324 - val_auc: 0.7346\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6539 - accuracy: 0.6203 - f1: 0.5273 - auc: 0.7395 - val_loss: 0.6553 - val_accuracy: 0.6029 - val_f1: 0.5240 - val_auc: 0.7947\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6322 - accuracy: 0.6203 - f1: 0.5353 - auc: 0.8125 - val_loss: 0.6253 - val_accuracy: 0.6029 - val_f1: 0.5498 - val_auc: 0.7990\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5824 - accuracy: 0.6246 - f1: 0.5759 - auc: 0.8131 - val_loss: 0.5573 - val_accuracy: 0.6471 - val_f1: 0.5983 - val_auc: 0.8057\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.7739 - f1: 0.6386 - auc: 0.8741 - val_loss: 0.4587 - val_accuracy: 0.8088 - val_f1: 0.6748 - val_auc: 0.8883\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3863 - accuracy: 0.8580 - f1: 0.7248 - auc: 0.9223 - val_loss: 0.3760 - val_accuracy: 0.8412 - val_f1: 0.7407 - val_auc: 0.9213\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3224 - accuracy: 0.8768 - f1: 0.7859 - auc: 0.9382 - val_loss: 0.3479 - val_accuracy: 0.8471 - val_f1: 0.7865 - val_auc: 0.9248\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2903 - accuracy: 0.8841 - f1: 0.8184 - auc: 0.9483 - val_loss: 0.3508 - val_accuracy: 0.8529 - val_f1: 0.8012 - val_auc: 0.9260\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2536 - accuracy: 0.9058 - f1: 0.8434 - auc: 0.9615 - val_loss: 0.3300 - val_accuracy: 0.8500 - val_f1: 0.8127 - val_auc: 0.9342\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2356 - accuracy: 0.9058 - f1: 0.8545 - auc: 0.9666 - val_loss: 0.3450 - val_accuracy: 0.8500 - val_f1: 0.8134 - val_auc: 0.9313\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2069 - accuracy: 0.9159 - f1: 0.8654 - auc: 0.9761 - val_loss: 0.3129 - val_accuracy: 0.8647 - val_f1: 0.8246 - val_auc: 0.9427\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1825 - accuracy: 0.9362 - f1: 0.8776 - auc: 0.9815 - val_loss: 0.3109 - val_accuracy: 0.8647 - val_f1: 0.8278 - val_auc: 0.9442\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.9435 - f1: 0.8897 - auc: 0.9861 - val_loss: 0.3102 - val_accuracy: 0.8706 - val_f1: 0.8364 - val_auc: 0.9445\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.9536 - f1: 0.8982 - auc: 0.9882 - val_loss: 0.3214 - val_accuracy: 0.8529 - val_f1: 0.8352 - val_auc: 0.9447\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1521 - accuracy: 0.9406 - f1: 0.8991 - auc: 0.9868 - val_loss: 0.4182 - val_accuracy: 0.8235 - val_f1: 0.8114 - val_auc: 0.9204\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1294 - accuracy: 0.9464 - f1: 0.9103 - auc: 0.9914 - val_loss: 0.3156 - val_accuracy: 0.8824 - val_f1: 0.8542 - val_auc: 0.9478\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0946 - accuracy: 0.9739 - f1: 0.9319 - auc: 0.9955 - val_loss: 0.3197 - val_accuracy: 0.8706 - val_f1: 0.8577 - val_auc: 0.9496\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0868 - accuracy: 0.9783 - f1: 0.9392 - auc: 0.9960 - val_loss: 0.3382 - val_accuracy: 0.8618 - val_f1: 0.8506 - val_auc: 0.9474\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 86.18%\n",
            "F1: 84.80%\n",
            "AUC: 94.74%\n",
            "Loss: 0.34%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# KFOLD CROSS-VAL BASED ON: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
        "\n",
        "\n",
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser = tf.reshape(X_train, [-1, 1, 1024])\n",
        "\n",
        "Y1 = to_categorical(y_train, 2)\n",
        "Y1_reshaped = tf.reshape(Y1, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser.shape, Y1_reshaped.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser = tf.reshape(X_test, [-1, 1, 1024])\n",
        "\n",
        "Y2 = to_categorical(y_test, 2)\n",
        "Y2_reshaped = tf.reshape(Y2, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser.shape, Y2_reshaped.shape)\n",
        "\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(LSTM(100, input_shape=(1, 1024), return_sequences=True))\n",
        "  model.add(Dense(1024,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128,activation='sigmoid'))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR85E_BlWts4",
        "outputId": "dfb645a1-7504-49e3-cec1-11f44d569b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.3822953701019287 - Accuracy: 87.94117569923401 - F1: 86.7958664894104 - AUC: 94.97491121292114%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.36340418457984924 - Accuracy: 87.35294342041016 - F1: 86.23794913291931 - AUC: 95.08649706840515%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.3360816240310669 - Accuracy: 87.64705657958984 - F1: 85.38581728935242 - AUC: 94.82179880142212%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.35372620820999146 - Accuracy: 87.64705657958984 - F1: 85.76995730400085 - AUC: 94.73832249641418%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.36780378222465515 - Accuracy: 87.64705657958984 - F1: 86.41788363456726 - AUC: 94.8853850364685%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.3523869812488556 - Accuracy: 87.05882430076599 - F1: 85.6859028339386 - AUC: 94.69334483146667%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.37663745880126953 - Accuracy: 88.23529481887817 - F1: 86.21904850006104 - AUC: 94.6656584739685%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.3335804343223572 - Accuracy: 88.23529481887817 - F1: 85.46090722084045 - AUC: 94.74480748176575%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.36040446162223816 - Accuracy: 87.05882430076599 - F1: 86.20060086250305 - AUC: 95.03632187843323%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.3382062017917633 - Accuracy: 86.17647290229797 - F1: 84.80005264282227 - AUC: 94.74048614501953%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.35645267069339753\n",
            "> Accuracy: 87.5 (+- 0.5918996082847351)\n",
            "> F1: 85.89739859104156 (+- 0.5573952107243649)\n",
            "> AUC: 94.83875334262848 (+- 0.14180455120603927)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVxSFf5TySpR"
      },
      "source": [
        "## **4. Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "Zxg1ExJNJg13",
        "outputId": "34ed7be3-b7a8-4602-99ea-3a9f2a8605a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  title  \\\n",
              "312                          lyricstxtRelacion_Sech.txt   \n",
              "2676  lyricstxtScream and Shout_will.i.am Britney Sp...   \n",
              "85                  lyricstxtCon Calma_Daddy Yankee.txt   \n",
              "808      lyricstxtAdicto with Anuel AA  Ozuna_Tainy.txt   \n",
              "6145                  lyricstxtSi Se Da_Myke Towers.txt   \n",
              "...                                                 ...   \n",
              "2571                     lyricstxten navidad_rosana.txt   \n",
              "2145             lyricstxtHeaven for everyone_Queen.txt   \n",
              "3249            lyricstxtOne Love to Give_Stephanie.txt   \n",
              "2399    lyricstxtstreets of love_the rolling stones.txt   \n",
              "975               lyricstxtAnalyse _The Cranberries.txt   \n",
              "\n",
              "                                              paragraph  label  decade  \\\n",
              "312   Ella siempre estaba cuando tú no estabas\\nFue ...      1    2020   \n",
              "2676  Hi! I’m Tunechi – I give the girls my room key...      1    2010   \n",
              "85    Con calma, yo quiero ver como ella lo menea\\nM...      1    2020   \n",
              "808   (¡Ozuna!)\\nSoy adicto a tu' parte'\\nMe hiciste...      1    2020   \n",
              "6145  (Pri, yah, yah, yah, ¡Farru!)\\nY si se da, bab...      1    2010   \n",
              "...                                                 ...    ...     ...   \n",
              "2571  Para que todos los días sean navidad\\nPara que...      0    1990   \n",
              "2145  This could be heaven\\nThis could be heaven\\nTh...      0    1990   \n",
              "3249  One love to give\\nOne song to sing\\nTwo hearts...      0    1980   \n",
              "2399  And I, I walk the streets of love\\nAnd they're...      0    2000   \n",
              "975   La ah ah ah ah ah ah ah\\nLa ah ah ah ah ah ah\\...      0    2000   \n",
              "\n",
              "      label probability  probability_sexist  probability_NOT_sexist  \n",
              "312            0.990960            0.990960                0.007631  \n",
              "2676           0.990256            0.990256                0.008354  \n",
              "85             0.990128            0.990128                0.008479  \n",
              "808            0.990053            0.990053                0.008563  \n",
              "6145           0.989980            0.989980                0.008639  \n",
              "...                 ...                 ...                     ...  \n",
              "2571           0.995805            0.004170                0.995805  \n",
              "2145           0.995818            0.004159                0.995818  \n",
              "3249           0.995886            0.004100                0.995886  \n",
              "2399           0.995900            0.004096                0.995900  \n",
              "975            0.995916            0.004086                0.995916  \n",
              "\n",
              "[750 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65e3183d-e387-42a0-a331-4b599eb870ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "      <th>decade</th>\n",
              "      <th>label probability</th>\n",
              "      <th>probability_sexist</th>\n",
              "      <th>probability_NOT_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>lyricstxtRelacion_Sech.txt</td>\n",
              "      <td>Ella siempre estaba cuando tú no estabas\\nFue ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>0.990960</td>\n",
              "      <td>0.990960</td>\n",
              "      <td>0.007631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2676</th>\n",
              "      <td>lyricstxtScream and Shout_will.i.am Britney Sp...</td>\n",
              "      <td>Hi! I’m Tunechi – I give the girls my room key...</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>0.990256</td>\n",
              "      <td>0.990256</td>\n",
              "      <td>0.008354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>lyricstxtCon Calma_Daddy Yankee.txt</td>\n",
              "      <td>Con calma, yo quiero ver como ella lo menea\\nM...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>0.990128</td>\n",
              "      <td>0.990128</td>\n",
              "      <td>0.008479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>lyricstxtAdicto with Anuel AA  Ozuna_Tainy.txt</td>\n",
              "      <td>(¡Ozuna!)\\nSoy adicto a tu' parte'\\nMe hiciste...</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>0.990053</td>\n",
              "      <td>0.990053</td>\n",
              "      <td>0.008563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6145</th>\n",
              "      <td>lyricstxtSi Se Da_Myke Towers.txt</td>\n",
              "      <td>(Pri, yah, yah, yah, ¡Farru!)\\nY si se da, bab...</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>0.989980</td>\n",
              "      <td>0.989980</td>\n",
              "      <td>0.008639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2571</th>\n",
              "      <td>lyricstxten navidad_rosana.txt</td>\n",
              "      <td>Para que todos los días sean navidad\\nPara que...</td>\n",
              "      <td>0</td>\n",
              "      <td>1990</td>\n",
              "      <td>0.995805</td>\n",
              "      <td>0.004170</td>\n",
              "      <td>0.995805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2145</th>\n",
              "      <td>lyricstxtHeaven for everyone_Queen.txt</td>\n",
              "      <td>This could be heaven\\nThis could be heaven\\nTh...</td>\n",
              "      <td>0</td>\n",
              "      <td>1990</td>\n",
              "      <td>0.995818</td>\n",
              "      <td>0.004159</td>\n",
              "      <td>0.995818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>lyricstxtOne Love to Give_Stephanie.txt</td>\n",
              "      <td>One love to give\\nOne song to sing\\nTwo hearts...</td>\n",
              "      <td>0</td>\n",
              "      <td>1980</td>\n",
              "      <td>0.995886</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.995886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2399</th>\n",
              "      <td>lyricstxtstreets of love_the rolling stones.txt</td>\n",
              "      <td>And I, I walk the streets of love\\nAnd they're...</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.995900</td>\n",
              "      <td>0.004096</td>\n",
              "      <td>0.995900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>lyricstxtAnalyse _The Cranberries.txt</td>\n",
              "      <td>La ah ah ah ah ah ah ah\\nLa ah ah ah ah ah ah\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.995916</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>0.995916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>750 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65e3183d-e387-42a0-a331-4b599eb870ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65e3183d-e387-42a0-a331-4b599eb870ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65e3183d-e387-42a0-a331-4b599eb870ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "decades = [1980,1990, 2000, 2010, 2020]\n",
        "sample_sorted_decades = []\n",
        "for decade in decades:\n",
        "  \n",
        "  decade_df = lyrics_df[lyrics_df['decade'] ==decade]\n",
        "  decade_df['paragraph'] = decade_df['paragraph'].astype(str)\n",
        "  decade_df = decade_df[decade_df['paragraph'] != '']\n",
        "  #decade_df['paragraph'] = decade_df['paragraph'].replace(\"EmbedShare URLCopyEmbedCopy\", \"\", inplace=True) #SEGUEIX SENSE ANAR?!\n",
        "\n",
        "  decade_df_processed = lyrics_preprocessing(decade_df['paragraph'])\n",
        "  decade_df_embeddings = laser.embed_sentences(decade_df_processed, lang = 'es')\n",
        "  decade_df = labeling(decade_df_embeddings, decade_df)\n",
        "  \n",
        "  #get 50 from top, 50 middle, 50 low\n",
        "  \n",
        "  sample1, sample2, sample3 = np.array_split(decade_df, 3)\n",
        "\n",
        "  sample1 = sample1.sample(n=50)\n",
        "  sample2 = sample2.sample(n=50)\n",
        "  sample3 = sample3.sample(n=50)\n",
        "\n",
        "  samples =[sample1, sample2, sample3]\n",
        "  decade_df = pd.concat(samples)\n",
        "\n",
        "  sample_sorted_decades.append(decade_df)\n",
        "\n",
        "\n",
        "final_df = pd.concat(sample_sorted_decades)\n",
        "final_df = final_df.sort_values('probability_sexist', ascending=False)\n",
        "\n",
        "\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXa4M0RdLLI6"
      },
      "outputs": [],
      "source": [
        "#final_df.to_csv('lyrics_Predicted_Round2.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}