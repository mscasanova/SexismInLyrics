{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM Trained with set of tweets and lyrics from existing datasets**\n"
      ],
      "metadata": {
        "id": "s1NpJRE9d4rO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQoOE5Ec24L"
      },
      "source": [
        "## **0.File Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMqTVkmgGSk"
      },
      "source": [
        "### **0.1 Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DoSHPrgEfJ",
        "outputId": "d8199d96-507a-4003-fea9-ca26b9019473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laserembeddings\n",
            "  Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.0.1.post2 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.11.0+cu113)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting transliterate==1.10.2\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting subword-nmt<0.4.0,>=0.3.6\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from laserembeddings) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=dc3a87e7839414970951dabcea67a6e554c42bbcd1bb136f6327bf0dff11b909\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: mock, transliterate, subword-nmt, sacremoses, laserembeddings\n",
            "Successfully installed laserembeddings-1.1.2 mock-4.0.3 sacremoses-0.0.35 subword-nmt-0.3.8 transliterate-1.10.2\n",
            "Downloading models into /usr/local/lib/python3.7/dist-packages/laserembeddings/data\n",
            "\n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n",
            "✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n",
            "\n",
            "✨ You're all set!\n"
          ]
        }
      ],
      "source": [
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzrJE1c_gP0i"
      },
      "source": [
        "### **0.2 Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-k-wVfCdBlc",
        "outputId": "fc4e1a64-70b4-41fb-e9f3-a4a4964db24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "#Text Processing\n",
        "import string\n",
        "import re\n",
        "\n",
        "#Modeling\n",
        "#from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# Reshaping datasets to tensors\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "#for Colab file dealing\n",
        "import glob\n",
        "#You can mount your Google Drive files by running the following code snippet\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # Now all files in: /content/gdrive/My Drive/location_of_the_file\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnKduo33J5RC"
      },
      "outputs": [],
      "source": [
        "#Laser\n",
        "from laserembeddings import Laser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0JtAv0glFX"
      },
      "source": [
        "### **0.3 Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.1 For Text Processing**"
      ],
      "metadata": {
        "id": "VTEo-SD-ah6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdZ97fBMgsW7"
      },
      "outputs": [],
      "source": [
        "def tweet_preprocessing(text_data):\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "            # hashtags -> words, URLs -> URL and mentions -> USER\n",
        "            text = re.sub('#', '', text)\n",
        "            text = re.sub('((www\\.[\\\\s]+)|(https?://[^\\\\s]+))', 'URL', text)\n",
        "            text = re.sub('@[A-Za-z0-9_-]+', 'USER', text)\n",
        "            text = re.sub('RT @[A-Za-z0-9_-]+:', 'USER', text)\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('\\!', ' ', text) # !\n",
        "            text = re.sub('\\?', ' ', text) # ?\n",
        "            text = re.sub('\\W', ' ', text) # symbols\n",
        "            text = re.sub('\\_', ' ', text) # _\n",
        "            text = re.sub('[\\s]+', ' ', text) # spaces\n",
        "            text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text) # remove spaces between numbers\n",
        "            preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C8ayV2QpLmq"
      },
      "outputs": [],
      "source": [
        "def lyrics_preprocessing(text_data):\n",
        "    preprocessed_texts = []\n",
        "    for text in text_data:\n",
        "      text = str(text).strip()\n",
        "\n",
        "      text = re.sub('\\[', '', text)\n",
        "      text = re.sub('\\]', '', text)\n",
        "      text = re.sub('\\_', ' ', text) # _\n",
        "      text = re.sub('\\!', ' ', text) # !\n",
        "      text = re.sub('\\?', ' ', text) # ?\n",
        "      text = re.sub('\\W', ' ', text) # symbols\n",
        "      text = re.sub('\\-', ' ', text) # -\n",
        "      text = re.sub('[\\s]+', ' ', text) # spaces\n",
        "\n",
        "      text = re.sub(\"[\\[].*?\\]\", \"\", text)#delete everything between square brackets\n",
        "\n",
        "      # Get rid of Genius watermarks\n",
        "      text = re.sub(\"EmbedShare URLCopyEmbedCopy\", '', text) \n",
        "      text = re.sub(\"EmbedShareURLCopyEmbedCopy\", '', text) \n",
        "\n",
        "\n",
        "      preprocessed_texts.append(text)\n",
        "\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8tmtMayqQK"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_preprocessed (Files, mypath, df):\n",
        "  \n",
        "  #paragraphs \n",
        "  titles = []\n",
        "  paragraphs = []\n",
        "  for i in range(len(Files)):\n",
        "    f = open(mypath+'/'+Files[i], 'r')\n",
        "\n",
        "    data = f.read()\n",
        "    data_splited = data.split(\"\\n\\n\")\n",
        "    \n",
        "\n",
        "    for j in data_splited:\n",
        "      titles.append(Files[i])\n",
        "      unwanted = j.split(\"\\n\")\n",
        "      wanted = []\n",
        "      \n",
        "      if '[' in unwanted[0]:\n",
        "        wanted = unwanted[1:]\n",
        "        j = \"\\n\".join(wanted)\n",
        "\n",
        "      paragraphs.append(j)\n",
        "\n",
        "  df['title'] = titles\n",
        "  df['paragraph'] = paragraphs\n",
        "  \n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.2 For Model Evaluation**"
      ],
      "metadata": {
        "id": "H-6Xomivan4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxwHMBHulqBA"
      },
      "outputs": [],
      "source": [
        "# f1 evaluation\n",
        "def f1(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **0.3.3 For Labeling**"
      ],
      "metadata": {
        "id": "hN6thv9vawu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phytHscSJwh-"
      },
      "outputs": [],
      "source": [
        "def labeling (l_embeddings, df):\n",
        "  Xnew = tf.reshape(l_embeddings, [-1, 1, 1024])\n",
        "\n",
        "  probs=model.predict(Xnew) \n",
        "  \n",
        "  #The first value of the prediction is for class 0 and the second for class 1 \n",
        "\n",
        "  ynew = []\n",
        "  probabilities = []\n",
        "  psxist = []\n",
        "  p_not_sxist = []\n",
        "  c=0\n",
        "  for item in probs:\n",
        "    if item[0][0]>item[0][1]:\n",
        "      y = 0\n",
        "      probability = item[0][0]  \n",
        "    else:\n",
        "      y = 1\n",
        "      probability = item[0][1]\n",
        "    p_not_sxist = np.append(p_not_sxist, item[0][0])\n",
        "    psxist = np.append(psxist, item[0][1])\n",
        "    c+=1\n",
        "    ynew = np.append(ynew, y)\n",
        "    probabilities = np.append(probabilities, probability)\n",
        "\n",
        "  df['label'] = ynew.astype('int')\n",
        "  df['label probability'] = probabilities\n",
        "  df['probability_sexist'] = psxist\n",
        "  df['probability_NOT_sexist'] = p_not_sxist\n",
        "  \n",
        "  df = df.sort_values('probability_sexist', ascending=False)\n",
        "  \n",
        "  return df \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1t9ZT8Zc8Kg"
      },
      "source": [
        "## **1. Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KzVf7_Qzf1_I",
        "outputId": "bcecae24-3711-4bfc-bf1c-2e4d1ca36640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               text  \\\n",
              "0               0  Red One Sugababes Girls bring the fun of life ...   \n",
              "1               1  I guess it was yourself you were involved with...   \n",
              "2               2  Bill collectors at my door What can you do for...   \n",
              "3               3  I ain't cooking all day (I ain't your mama!) I...   \n",
              "4               4  All hands on deck All in front all in the back...   \n",
              "...           ...                                                ...   \n",
              "21772        3595  \"Experimentos que surgen en la ociosidad de la...   \n",
              "21773        3596  Mucho feminismo pero la Pedroche en tetas. Por...   \n",
              "21774        3597  hermana estaba contando a madrastra que un gom...   \n",
              "21775        3598  @AdrianFtm24 @s0ymia Mucho feminismo, pero mir...   \n",
              "21776        3599  @sotosinmas A muchísimos hombres no les gustan...   \n",
              "\n",
              "            Class language dataset       Category      highlight  \n",
              "0          sexism       en  lyrics  Not specified  Not specified  \n",
              "1          sexism       en  lyrics  Not specified  Not specified  \n",
              "2          sexism       en  lyrics  Not specified  Not specified  \n",
              "3          sexism       en  lyrics  Not specified  Not specified  \n",
              "4          sexism       en  lyrics  Not specified  Not specified  \n",
              "...           ...      ...     ...            ...            ...  \n",
              "21772  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "21773      sexism       es   MeTwo  Not specified  Not specified  \n",
              "21774  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "21775      sexism       es   MeTwo  Not specified  Not specified  \n",
              "21776  not_sexism       es   MeTwo  Not specified  Not specified  \n",
              "\n",
              "[21777 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e26d3ce2-36e2-46a6-9216-d4fa4b6f6be0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>Class</th>\n",
              "      <th>language</th>\n",
              "      <th>dataset</th>\n",
              "      <th>Category</th>\n",
              "      <th>highlight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Red One Sugababes Girls bring the fun of life ...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I guess it was yourself you were involved with...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Bill collectors at my door What can you do for...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I ain't cooking all day (I ain't your mama!) I...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>All hands on deck All in front all in the back...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>en</td>\n",
              "      <td>lyrics</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21772</th>\n",
              "      <td>3595</td>\n",
              "      <td>\"Experimentos que surgen en la ociosidad de la...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21773</th>\n",
              "      <td>3596</td>\n",
              "      <td>Mucho feminismo pero la Pedroche en tetas. Por...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21774</th>\n",
              "      <td>3597</td>\n",
              "      <td>hermana estaba contando a madrastra que un gom...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21775</th>\n",
              "      <td>3598</td>\n",
              "      <td>@AdrianFtm24 @s0ymia Mucho feminismo, pero mir...</td>\n",
              "      <td>sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21776</th>\n",
              "      <td>3599</td>\n",
              "      <td>@sotosinmas A muchísimos hombres no les gustan...</td>\n",
              "      <td>not_sexism</td>\n",
              "      <td>es</td>\n",
              "      <td>MeTwo</td>\n",
              "      <td>Not specified</td>\n",
              "      <td>Not specified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21777 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e26d3ce2-36e2-46a6-9216-d4fa4b6f6be0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e26d3ce2-36e2-46a6-9216-d4fa4b6f6be0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e26d3ce2-36e2-46a6-9216-d4fa4b6f6be0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "training = '/content/gdrive/My Drive/training_dataset.csv'\n",
        "training = pd.read_csv(training)\n",
        "training_df = training.copy()\n",
        "training_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-9eFc_df5Un"
      },
      "source": [
        "## **2. Lyrics to be Labeled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m4iZd6HmYkZ"
      },
      "outputs": [],
      "source": [
        "mypath60s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1960-1969'\n",
        "mypath70s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/1970-1979'\n",
        "mypath21s = '/content/gdrive/MyDrive/2021 Music Lyrics [Laura Casanovas]/2020-2021'\n",
        "\n",
        "Files60s = [f for f in listdir(mypath60s) if isfile(join(mypath60s, f))]\n",
        "Files70s = [f for f in listdir(mypath70s) if isfile(join(mypath70s, f))]\n",
        "Files21s = [f for f in listdir(mypath21s) if isfile(join(mypath21s, f))]\n",
        "\n",
        "cols=['title', 'paragraph', 'label']\n",
        "\n",
        "lyrics_df = pd.DataFrame(columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QvKIJsZjzao8",
        "outputId": "01c353a7-5b5e-4ba4-e2e5-7a85ffe07969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                title  \\\n",
              "0                lyricstxt_Aitana.txt   \n",
              "1                lyricstxt_Aitana.txt   \n",
              "2                lyricstxt_Aitana.txt   \n",
              "3                lyricstxt_Aitana.txt   \n",
              "4                lyricstxt_Aitana.txt   \n",
              "...                               ...   \n",
              "1661  lyricstxtThe Business_Tisto.txt   \n",
              "1662  lyricstxtThe Business_Tisto.txt   \n",
              "1663  lyricstxtThe Business_Tisto.txt   \n",
              "1664  lyricstxtThe Business_Tisto.txt   \n",
              "1665  lyricstxtThe Business_Tisto.txt   \n",
              "\n",
              "                                              paragraph label  \n",
              "0                                                         NaN  \n",
              "1     Voy a salir no más fingir no más servir La noc...   NaN  \n",
              "2     Tira porque te toca a ti perder Que aquí ya se...   NaN  \n",
              "3     Pero si me toca toca tócame Yo decido el cuánd...   NaN  \n",
              "4     En un chico malo no no no Pa fuera lo malo no ...   NaN  \n",
              "...                                                 ...   ...  \n",
              "1661  Mama please don t worry bout me Cause I m abou...   NaN  \n",
              "1662  Let s get down let s get down to business Give...   NaN  \n",
              "1663  Back and forth back and forth with the bullshi...   NaN  \n",
              "1664  Let s get down let s get down to business Give...   NaN  \n",
              "1665                                      Ooh yeah yeah   NaN  \n",
              "\n",
              "[1666 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb42ceaf-8eff-496c-9924-1d2672e32d67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lyricstxt_Aitana.txt</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lyricstxt_Aitana.txt</td>\n",
              "      <td>Voy a salir no más fingir no más servir La noc...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lyricstxt_Aitana.txt</td>\n",
              "      <td>Tira porque te toca a ti perder Que aquí ya se...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lyricstxt_Aitana.txt</td>\n",
              "      <td>Pero si me toca toca tócame Yo decido el cuánd...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lyricstxt_Aitana.txt</td>\n",
              "      <td>En un chico malo no no no Pa fuera lo malo no ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>lyricstxtThe Business_Tisto.txt</td>\n",
              "      <td>Mama please don t worry bout me Cause I m abou...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>lyricstxtThe Business_Tisto.txt</td>\n",
              "      <td>Let s get down let s get down to business Give...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>lyricstxtThe Business_Tisto.txt</td>\n",
              "      <td>Back and forth back and forth with the bullshi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>lyricstxtThe Business_Tisto.txt</td>\n",
              "      <td>Let s get down let s get down to business Give...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>lyricstxtThe Business_Tisto.txt</td>\n",
              "      <td>Ooh yeah yeah</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb42ceaf-8eff-496c-9924-1d2672e32d67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb42ceaf-8eff-496c-9924-1d2672e32d67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb42ceaf-8eff-496c-9924-1d2672e32d67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "lyrics_df = get_paragraphs_preprocessed(Files21s, mypath21s, lyrics_df)\n",
        "lyrics_df['paragraph'] = lyrics_preprocessing(lyrics_df['paragraph'])\n",
        "lyrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M627jdgcxIO"
      },
      "source": [
        "## **3. LSTM Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eFWI2uqhc1n"
      },
      "source": [
        "### **3.1 Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7c-p3iRrAte"
      },
      "outputs": [],
      "source": [
        "laser = Laser() # importing class for using embeddings extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tf_gVS1chqp",
        "outputId": "112c7abd-ea43-4fb4-d73d-edbfd2a0dd69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "train_data = training_df[(training_df['dataset']=='exist')|(training_df['dataset']=='exist_test')|(training_df['dataset']=='MeTwo')]\n",
        "texts_tobe_processed_train = train_data['text']\n",
        "\n",
        "\n",
        "texts_processed_train = tweet_preprocessing(texts_tobe_processed_train)\n",
        "\n",
        "\n",
        "train_embeddings = laser.embed_sentences(texts_processed_train, lang = 'en') \n",
        "\n",
        "train_data[['Class']] = train_data[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "train_labels = train_data['Class']\n",
        "train_labels = train_labels.astype('int64')\n",
        "\n",
        "\n",
        "# test data\n",
        "\n",
        "#since I do not really know what '-1' means I will drop the 145 rows with value -1 for the testing part\n",
        "test_data = training_df[(training_df['dataset']=='lyrics')&(training_df['Class']!='-1')]\n",
        "\n",
        "texts_tobe_processed_test = test_data['text']\n",
        "\n",
        "texts_processed_test = tweet_preprocessing(texts_tobe_processed_test)\n",
        "\n",
        "    \n",
        "test_embeddings = laser.embed_sentences(texts_processed_test, lang = 'en')\n",
        "\n",
        "test_data[['Class']] = test_data[['Class']].replace(['sexism', 'not_sexism'],[1,0])\n",
        "test_labels = test_data['Class']\n",
        "test_labels = test_labels.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHuiwZNdo-rP"
      },
      "outputs": [],
      "source": [
        "lyrics_df['paragraph'] = lyrics_df['paragraph'].astype(str)\n",
        "lyrics_processed = lyrics_preprocessing(lyrics_df['paragraph'])\n",
        "lyrics_embeddings = laser.embed_sentences(lyrics_processed, lang = 'es')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5A6ReuPhjTn"
      },
      "source": [
        "### **3.2 Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO8lo74khUll",
        "outputId": "4982ad57-755d-43ab-a774-4edbaedb9b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shapes: (14678, 1, 1024) (14678, 1, 2)\n",
            "Test data shapes: (387, 1, 1024) (387, 1, 2)\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 11s 18ms/step - loss: 0.6652 - accuracy: 0.5826 - f1: 0.5240 - auc: 0.6251 - val_loss: 0.7449 - val_accuracy: 0.5736 - val_f1: 0.5433 - val_auc: 0.5959\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5934 - accuracy: 0.6820 - f1: 0.5934 - auc: 0.7477 - val_loss: 0.6389 - val_accuracy: 0.6253 - val_f1: 0.5591 - val_auc: 0.6900\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 10ms/step - loss: 0.5737 - accuracy: 0.6981 - f1: 0.6084 - auc: 0.7692 - val_loss: 0.8672 - val_accuracy: 0.5478 - val_f1: 0.5463 - val_auc: 0.5818\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5582 - accuracy: 0.7120 - f1: 0.6218 - auc: 0.7851 - val_loss: 0.7358 - val_accuracy: 0.5685 - val_f1: 0.5569 - val_auc: 0.6171\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5496 - accuracy: 0.7223 - f1: 0.6295 - auc: 0.7932 - val_loss: 0.6969 - val_accuracy: 0.5788 - val_f1: 0.5652 - val_auc: 0.6451\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 10ms/step - loss: 0.5412 - accuracy: 0.7262 - f1: 0.6352 - auc: 0.8005 - val_loss: 0.6927 - val_accuracy: 0.5762 - val_f1: 0.5641 - val_auc: 0.6431\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5326 - accuracy: 0.7288 - f1: 0.6411 - auc: 0.8072 - val_loss: 0.6997 - val_accuracy: 0.6434 - val_f1: 0.5948 - val_auc: 0.6828\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5244 - accuracy: 0.7348 - f1: 0.6478 - auc: 0.8141 - val_loss: 0.6726 - val_accuracy: 0.6124 - val_f1: 0.5811 - val_auc: 0.6794\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5178 - accuracy: 0.7387 - f1: 0.6519 - auc: 0.8194 - val_loss: 0.6289 - val_accuracy: 0.6873 - val_f1: 0.6206 - val_auc: 0.7461\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5144 - accuracy: 0.7404 - f1: 0.6553 - auc: 0.8217 - val_loss: 0.7661 - val_accuracy: 0.6047 - val_f1: 0.5948 - val_auc: 0.6666\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5023 - accuracy: 0.7482 - f1: 0.6645 - auc: 0.8321 - val_loss: 0.6301 - val_accuracy: 0.6925 - val_f1: 0.6363 - val_auc: 0.7570\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4985 - accuracy: 0.7488 - f1: 0.6675 - auc: 0.8346 - val_loss: 0.7904 - val_accuracy: 0.6253 - val_f1: 0.6192 - val_auc: 0.6941\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4927 - accuracy: 0.7526 - f1: 0.6717 - auc: 0.8386 - val_loss: 0.7982 - val_accuracy: 0.5995 - val_f1: 0.5925 - val_auc: 0.6577\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4859 - accuracy: 0.7553 - f1: 0.6759 - auc: 0.8441 - val_loss: 0.7694 - val_accuracy: 0.6563 - val_f1: 0.6296 - val_auc: 0.7089\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4744 - accuracy: 0.7619 - f1: 0.6857 - auc: 0.8527 - val_loss: 0.7181 - val_accuracy: 0.6460 - val_f1: 0.6249 - val_auc: 0.7150\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4683 - accuracy: 0.7669 - f1: 0.6900 - auc: 0.8567 - val_loss: 0.6145 - val_accuracy: 0.7106 - val_f1: 0.6487 - val_auc: 0.7745\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4595 - accuracy: 0.7752 - f1: 0.6971 - auc: 0.8631 - val_loss: 0.6701 - val_accuracy: 0.6925 - val_f1: 0.6446 - val_auc: 0.7483\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4521 - accuracy: 0.7835 - f1: 0.7025 - auc: 0.8684 - val_loss: 0.6324 - val_accuracy: 0.6822 - val_f1: 0.6368 - val_auc: 0.7577\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4505 - accuracy: 0.7827 - f1: 0.7041 - auc: 0.8690 - val_loss: 0.6696 - val_accuracy: 0.6873 - val_f1: 0.6237 - val_auc: 0.7322\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4366 - accuracy: 0.7920 - f1: 0.7135 - auc: 0.8785 - val_loss: 0.6945 - val_accuracy: 0.6951 - val_f1: 0.6468 - val_auc: 0.7451\n",
            "\n",
            "Score for fold 1: \n",
            "\n",
            "Accuracy: 69.51%\n",
            "F1: 65.10%\n",
            "AUC: 74.51%\n",
            "Loss: 0.69%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 5s 16ms/step - loss: 0.6507 - accuracy: 0.6051 - f1: 0.5388 - auc: 0.6538 - val_loss: 0.6618 - val_accuracy: 0.5943 - val_f1: 0.5534 - val_auc: 0.6555\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5821 - accuracy: 0.6923 - f1: 0.6018 - auc: 0.7601 - val_loss: 0.8068 - val_accuracy: 0.5478 - val_f1: 0.5458 - val_auc: 0.5894\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5664 - accuracy: 0.7068 - f1: 0.6140 - auc: 0.7763 - val_loss: 0.8334 - val_accuracy: 0.5478 - val_f1: 0.5470 - val_auc: 0.5890\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5555 - accuracy: 0.7190 - f1: 0.6234 - auc: 0.7877 - val_loss: 0.6412 - val_accuracy: 0.6357 - val_f1: 0.5799 - val_auc: 0.7014\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5543 - accuracy: 0.7163 - f1: 0.6266 - auc: 0.7881 - val_loss: 0.6806 - val_accuracy: 0.5814 - val_f1: 0.5658 - val_auc: 0.6544\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5410 - accuracy: 0.7268 - f1: 0.6351 - auc: 0.8007 - val_loss: 0.7377 - val_accuracy: 0.5995 - val_f1: 0.5900 - val_auc: 0.6662\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5388 - accuracy: 0.7254 - f1: 0.6378 - auc: 0.8024 - val_loss: 0.6458 - val_accuracy: 0.6460 - val_f1: 0.5918 - val_auc: 0.7082\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5275 - accuracy: 0.7315 - f1: 0.6445 - auc: 0.8111 - val_loss: 0.6932 - val_accuracy: 0.6408 - val_f1: 0.6022 - val_auc: 0.6936\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5184 - accuracy: 0.7390 - f1: 0.6525 - auc: 0.8195 - val_loss: 0.7076 - val_accuracy: 0.6124 - val_f1: 0.5925 - val_auc: 0.6751\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5169 - accuracy: 0.7370 - f1: 0.6534 - auc: 0.8197 - val_loss: 0.6882 - val_accuracy: 0.6124 - val_f1: 0.5866 - val_auc: 0.6743\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5085 - accuracy: 0.7423 - f1: 0.6592 - auc: 0.8267 - val_loss: 0.6820 - val_accuracy: 0.6537 - val_f1: 0.6107 - val_auc: 0.7104\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5025 - accuracy: 0.7465 - f1: 0.6642 - auc: 0.8316 - val_loss: 0.6186 - val_accuracy: 0.6873 - val_f1: 0.6085 - val_auc: 0.7473\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5016 - accuracy: 0.7429 - f1: 0.6651 - auc: 0.8312 - val_loss: 0.6546 - val_accuracy: 0.6925 - val_f1: 0.6400 - val_auc: 0.7481\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4864 - accuracy: 0.7549 - f1: 0.6749 - auc: 0.8434 - val_loss: 0.7156 - val_accuracy: 0.6770 - val_f1: 0.6426 - val_auc: 0.7336\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4794 - accuracy: 0.7601 - f1: 0.6821 - auc: 0.8483 - val_loss: 0.6607 - val_accuracy: 0.6925 - val_f1: 0.6415 - val_auc: 0.7494\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4681 - accuracy: 0.7690 - f1: 0.6888 - auc: 0.8570 - val_loss: 0.6707 - val_accuracy: 0.6744 - val_f1: 0.6408 - val_auc: 0.7461\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4650 - accuracy: 0.7727 - f1: 0.6911 - auc: 0.8594 - val_loss: 0.7620 - val_accuracy: 0.6822 - val_f1: 0.6487 - val_auc: 0.7306\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4567 - accuracy: 0.7763 - f1: 0.6972 - auc: 0.8645 - val_loss: 0.6659 - val_accuracy: 0.7028 - val_f1: 0.6689 - val_auc: 0.7733\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4571 - accuracy: 0.7725 - f1: 0.6992 - auc: 0.8636 - val_loss: 0.6555 - val_accuracy: 0.6822 - val_f1: 0.6451 - val_auc: 0.7548\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4432 - accuracy: 0.7862 - f1: 0.7066 - auc: 0.8737 - val_loss: 0.6443 - val_accuracy: 0.7132 - val_f1: 0.6685 - val_auc: 0.7786\n",
            "\n",
            "Score for fold 2: \n",
            "\n",
            "Accuracy: 71.32%\n",
            "F1: 66.73%\n",
            "AUC: 77.86%\n",
            "Loss: 0.64%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 5s 16ms/step - loss: 0.6566 - accuracy: 0.6022 - f1: 0.5346 - auc: 0.6447 - val_loss: 0.8092 - val_accuracy: 0.5271 - val_f1: 0.5336 - val_auc: 0.5679\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5942 - accuracy: 0.6812 - f1: 0.5925 - auc: 0.7459 - val_loss: 0.7652 - val_accuracy: 0.5659 - val_f1: 0.5449 - val_auc: 0.5907\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5708 - accuracy: 0.7010 - f1: 0.6120 - auc: 0.7723 - val_loss: 0.8796 - val_accuracy: 0.4832 - val_f1: 0.5320 - val_auc: 0.5672\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5577 - accuracy: 0.7130 - f1: 0.6211 - auc: 0.7851 - val_loss: 0.7136 - val_accuracy: 0.5814 - val_f1: 0.5651 - val_auc: 0.6358\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5502 - accuracy: 0.7190 - f1: 0.6280 - auc: 0.7923 - val_loss: 0.7081 - val_accuracy: 0.5814 - val_f1: 0.5765 - val_auc: 0.6547\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5403 - accuracy: 0.7278 - f1: 0.6367 - auc: 0.8010 - val_loss: 0.6761 - val_accuracy: 0.6202 - val_f1: 0.5766 - val_auc: 0.6706\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5359 - accuracy: 0.7284 - f1: 0.6386 - auc: 0.8046 - val_loss: 0.6845 - val_accuracy: 0.6227 - val_f1: 0.5943 - val_auc: 0.6859\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5267 - accuracy: 0.7328 - f1: 0.6456 - auc: 0.8118 - val_loss: 0.6810 - val_accuracy: 0.6305 - val_f1: 0.6021 - val_auc: 0.6975\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5189 - accuracy: 0.7374 - f1: 0.6514 - auc: 0.8182 - val_loss: 0.6172 - val_accuracy: 0.7003 - val_f1: 0.6133 - val_auc: 0.7462\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5097 - accuracy: 0.7417 - f1: 0.6583 - auc: 0.8259 - val_loss: 0.6460 - val_accuracy: 0.6899 - val_f1: 0.6278 - val_auc: 0.7404\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5022 - accuracy: 0.7467 - f1: 0.6648 - auc: 0.8317 - val_loss: 0.8307 - val_accuracy: 0.5917 - val_f1: 0.5859 - val_auc: 0.6442\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4998 - accuracy: 0.7467 - f1: 0.6661 - auc: 0.8334 - val_loss: 0.7119 - val_accuracy: 0.6408 - val_f1: 0.6170 - val_auc: 0.7057\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4935 - accuracy: 0.7504 - f1: 0.6710 - auc: 0.8382 - val_loss: 0.7149 - val_accuracy: 0.6589 - val_f1: 0.6350 - val_auc: 0.7254\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4820 - accuracy: 0.7605 - f1: 0.6792 - auc: 0.8470 - val_loss: 0.7120 - val_accuracy: 0.6486 - val_f1: 0.6239 - val_auc: 0.7151\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4838 - accuracy: 0.7571 - f1: 0.6792 - auc: 0.8453 - val_loss: 0.6602 - val_accuracy: 0.6951 - val_f1: 0.6513 - val_auc: 0.7571\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4723 - accuracy: 0.7660 - f1: 0.6859 - auc: 0.8537 - val_loss: 0.6879 - val_accuracy: 0.6770 - val_f1: 0.6557 - val_auc: 0.7548\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4669 - accuracy: 0.7705 - f1: 0.6905 - auc: 0.8577 - val_loss: 0.7754 - val_accuracy: 0.6563 - val_f1: 0.6419 - val_auc: 0.7226\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4617 - accuracy: 0.7731 - f1: 0.6957 - auc: 0.8616 - val_loss: 0.6455 - val_accuracy: 0.7054 - val_f1: 0.6481 - val_auc: 0.7603\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4593 - accuracy: 0.7729 - f1: 0.6966 - auc: 0.8626 - val_loss: 0.6134 - val_accuracy: 0.7054 - val_f1: 0.6284 - val_auc: 0.7629\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4444 - accuracy: 0.7877 - f1: 0.7075 - auc: 0.8732 - val_loss: 0.7597 - val_accuracy: 0.6667 - val_f1: 0.6459 - val_auc: 0.7312\n",
            "\n",
            "Score for fold 3: \n",
            "\n",
            "Accuracy: 66.67%\n",
            "F1: 65.60%\n",
            "AUC: 73.12%\n",
            "Loss: 0.76%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 6s 18ms/step - loss: 0.6605 - accuracy: 0.5926 - f1: 0.5328 - auc: 0.6358 - val_loss: 0.7115 - val_accuracy: 0.5840 - val_f1: 0.5447 - val_auc: 0.6114\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5864 - accuracy: 0.6901 - f1: 0.5967 - auc: 0.7552 - val_loss: 0.8845 - val_accuracy: 0.5323 - val_f1: 0.5395 - val_auc: 0.5716\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5665 - accuracy: 0.7081 - f1: 0.6147 - auc: 0.7764 - val_loss: 0.7066 - val_accuracy: 0.5762 - val_f1: 0.5651 - val_auc: 0.6416\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5569 - accuracy: 0.7143 - f1: 0.6240 - auc: 0.7858 - val_loss: 0.6113 - val_accuracy: 0.6899 - val_f1: 0.5759 - val_auc: 0.7381\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5478 - accuracy: 0.7217 - f1: 0.6295 - auc: 0.7947 - val_loss: 0.6731 - val_accuracy: 0.6227 - val_f1: 0.5779 - val_auc: 0.6795\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5416 - accuracy: 0.7250 - f1: 0.6362 - auc: 0.8003 - val_loss: 0.6283 - val_accuracy: 0.6641 - val_f1: 0.5843 - val_auc: 0.7208\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5379 - accuracy: 0.7249 - f1: 0.6381 - auc: 0.8031 - val_loss: 0.8108 - val_accuracy: 0.5840 - val_f1: 0.5684 - val_auc: 0.6199\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5252 - accuracy: 0.7347 - f1: 0.6464 - auc: 0.8137 - val_loss: 0.6730 - val_accuracy: 0.6331 - val_f1: 0.6024 - val_auc: 0.7019\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5185 - accuracy: 0.7360 - f1: 0.6522 - auc: 0.8188 - val_loss: 0.7505 - val_accuracy: 0.6279 - val_f1: 0.6148 - val_auc: 0.6952\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5113 - accuracy: 0.7397 - f1: 0.6586 - auc: 0.8249 - val_loss: 0.8004 - val_accuracy: 0.6124 - val_f1: 0.6004 - val_auc: 0.6682\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5006 - accuracy: 0.7455 - f1: 0.6644 - auc: 0.8326 - val_loss: 0.7428 - val_accuracy: 0.6331 - val_f1: 0.6191 - val_auc: 0.7016\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4945 - accuracy: 0.7496 - f1: 0.6701 - auc: 0.8378 - val_loss: 0.6614 - val_accuracy: 0.6822 - val_f1: 0.6454 - val_auc: 0.7516\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4921 - accuracy: 0.7536 - f1: 0.6721 - auc: 0.8390 - val_loss: 0.7035 - val_accuracy: 0.6486 - val_f1: 0.6196 - val_auc: 0.7121\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4798 - accuracy: 0.7605 - f1: 0.6813 - auc: 0.8483 - val_loss: 0.7123 - val_accuracy: 0.6537 - val_f1: 0.6246 - val_auc: 0.7170\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4714 - accuracy: 0.7660 - f1: 0.6867 - auc: 0.8547 - val_loss: 0.7118 - val_accuracy: 0.6537 - val_f1: 0.6356 - val_auc: 0.7285\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4685 - accuracy: 0.7696 - f1: 0.6899 - auc: 0.8564 - val_loss: 0.7019 - val_accuracy: 0.6744 - val_f1: 0.6494 - val_auc: 0.7465\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4610 - accuracy: 0.7766 - f1: 0.6947 - auc: 0.8620 - val_loss: 0.8395 - val_accuracy: 0.6537 - val_f1: 0.6357 - val_auc: 0.7080\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4561 - accuracy: 0.7798 - f1: 0.7000 - auc: 0.8660 - val_loss: 0.7094 - val_accuracy: 0.6460 - val_f1: 0.6175 - val_auc: 0.7090\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4484 - accuracy: 0.7833 - f1: 0.7047 - auc: 0.8706 - val_loss: 0.8638 - val_accuracy: 0.6357 - val_f1: 0.6276 - val_auc: 0.6959\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4312 - accuracy: 0.7947 - f1: 0.7160 - auc: 0.8815 - val_loss: 0.6943 - val_accuracy: 0.6977 - val_f1: 0.6613 - val_auc: 0.7595\n",
            "\n",
            "Score for fold 4: \n",
            "\n",
            "Accuracy: 69.77%\n",
            "F1: 66.48%\n",
            "AUC: 75.95%\n",
            "Loss: 0.69%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 5s 17ms/step - loss: 0.6628 - accuracy: 0.5871 - f1: 0.5272 - auc: 0.6305 - val_loss: 0.9960 - val_accuracy: 0.4625 - val_f1: 0.5127 - val_auc: 0.5445\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5935 - accuracy: 0.6872 - f1: 0.5922 - auc: 0.7463 - val_loss: 0.7745 - val_accuracy: 0.5685 - val_f1: 0.5482 - val_auc: 0.5955\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5673 - accuracy: 0.7053 - f1: 0.6127 - auc: 0.7752 - val_loss: 0.7355 - val_accuracy: 0.5917 - val_f1: 0.5656 - val_auc: 0.6302\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5583 - accuracy: 0.7139 - f1: 0.6230 - auc: 0.7845 - val_loss: 0.6830 - val_accuracy: 0.5711 - val_f1: 0.5534 - val_auc: 0.6357\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5472 - accuracy: 0.7226 - f1: 0.6302 - auc: 0.7953 - val_loss: 0.6417 - val_accuracy: 0.6331 - val_f1: 0.5740 - val_auc: 0.6996\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5406 - accuracy: 0.7251 - f1: 0.6359 - auc: 0.8009 - val_loss: 0.7340 - val_accuracy: 0.5762 - val_f1: 0.5675 - val_auc: 0.6314\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5335 - accuracy: 0.7316 - f1: 0.6413 - auc: 0.8068 - val_loss: 0.7453 - val_accuracy: 0.5840 - val_f1: 0.5819 - val_auc: 0.6530\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5278 - accuracy: 0.7300 - f1: 0.6457 - auc: 0.8109 - val_loss: 0.6458 - val_accuracy: 0.6563 - val_f1: 0.5938 - val_auc: 0.7122\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5238 - accuracy: 0.7378 - f1: 0.6485 - auc: 0.8154 - val_loss: 0.7115 - val_accuracy: 0.5943 - val_f1: 0.5779 - val_auc: 0.6539\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5145 - accuracy: 0.7402 - f1: 0.6551 - auc: 0.8222 - val_loss: 0.8466 - val_accuracy: 0.5840 - val_f1: 0.5939 - val_auc: 0.6565\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5082 - accuracy: 0.7400 - f1: 0.6594 - auc: 0.8263 - val_loss: 0.7540 - val_accuracy: 0.6124 - val_f1: 0.5982 - val_auc: 0.6729\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4981 - accuracy: 0.7515 - f1: 0.6673 - auc: 0.8352 - val_loss: 0.7956 - val_accuracy: 0.5969 - val_f1: 0.5915 - val_auc: 0.6555\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4936 - accuracy: 0.7517 - f1: 0.6706 - auc: 0.8383 - val_loss: 0.6806 - val_accuracy: 0.6486 - val_f1: 0.6093 - val_auc: 0.7106\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4947 - accuracy: 0.7450 - f1: 0.6699 - auc: 0.8358 - val_loss: 0.6695 - val_accuracy: 0.6744 - val_f1: 0.6400 - val_auc: 0.7444\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4798 - accuracy: 0.7595 - f1: 0.6801 - auc: 0.8485 - val_loss: 0.7255 - val_accuracy: 0.6486 - val_f1: 0.6182 - val_auc: 0.7060\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4716 - accuracy: 0.7666 - f1: 0.6862 - auc: 0.8538 - val_loss: 0.8827 - val_accuracy: 0.6150 - val_f1: 0.6120 - val_auc: 0.6771\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4673 - accuracy: 0.7677 - f1: 0.6893 - auc: 0.8568 - val_loss: 0.7825 - val_accuracy: 0.6486 - val_f1: 0.6278 - val_auc: 0.7069\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4585 - accuracy: 0.7743 - f1: 0.6958 - auc: 0.8628 - val_loss: 0.6933 - val_accuracy: 0.6357 - val_f1: 0.6159 - val_auc: 0.7115\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4497 - accuracy: 0.7791 - f1: 0.7022 - auc: 0.8688 - val_loss: 0.6501 - val_accuracy: 0.6977 - val_f1: 0.6375 - val_auc: 0.7569\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4587 - accuracy: 0.7753 - f1: 0.6985 - auc: 0.8631 - val_loss: 0.7083 - val_accuracy: 0.6873 - val_f1: 0.6474 - val_auc: 0.7447\n",
            "\n",
            "Score for fold 5: \n",
            "\n",
            "Accuracy: 68.73%\n",
            "F1: 65.45%\n",
            "AUC: 74.47%\n",
            "Loss: 0.71%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 5s 17ms/step - loss: 0.6596 - accuracy: 0.5972 - f1: 0.5300 - auc: 0.6375 - val_loss: 0.7856 - val_accuracy: 0.5401 - val_f1: 0.5364 - val_auc: 0.5783\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5906 - accuracy: 0.6836 - f1: 0.5947 - auc: 0.7507 - val_loss: 0.9157 - val_accuracy: 0.5090 - val_f1: 0.5288 - val_auc: 0.5580\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5735 - accuracy: 0.7011 - f1: 0.6103 - auc: 0.7698 - val_loss: 0.6810 - val_accuracy: 0.5840 - val_f1: 0.5650 - val_auc: 0.6582\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5615 - accuracy: 0.7122 - f1: 0.6189 - auc: 0.7817 - val_loss: 0.8309 - val_accuracy: 0.5194 - val_f1: 0.5370 - val_auc: 0.5740\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5545 - accuracy: 0.7181 - f1: 0.6253 - auc: 0.7887 - val_loss: 0.8263 - val_accuracy: 0.5633 - val_f1: 0.5505 - val_auc: 0.5907\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5418 - accuracy: 0.7233 - f1: 0.6358 - auc: 0.7995 - val_loss: 0.7821 - val_accuracy: 0.5530 - val_f1: 0.5487 - val_auc: 0.5913\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5331 - accuracy: 0.7270 - f1: 0.6395 - auc: 0.8065 - val_loss: 0.8008 - val_accuracy: 0.5891 - val_f1: 0.5825 - val_auc: 0.6434\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5250 - accuracy: 0.7323 - f1: 0.6467 - auc: 0.8135 - val_loss: 0.7562 - val_accuracy: 0.6072 - val_f1: 0.5972 - val_auc: 0.6718\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5155 - accuracy: 0.7409 - f1: 0.6543 - auc: 0.8215 - val_loss: 0.6718 - val_accuracy: 0.6279 - val_f1: 0.6077 - val_auc: 0.7088\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5098 - accuracy: 0.7429 - f1: 0.6588 - auc: 0.8256 - val_loss: 0.6529 - val_accuracy: 0.6796 - val_f1: 0.6304 - val_auc: 0.7412\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5012 - accuracy: 0.7440 - f1: 0.6640 - auc: 0.8312 - val_loss: 0.7064 - val_accuracy: 0.6486 - val_f1: 0.6215 - val_auc: 0.7129\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4973 - accuracy: 0.7481 - f1: 0.6681 - auc: 0.8348 - val_loss: 0.7573 - val_accuracy: 0.6124 - val_f1: 0.6033 - val_auc: 0.6787\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4862 - accuracy: 0.7557 - f1: 0.6748 - auc: 0.8434 - val_loss: 0.9856 - val_accuracy: 0.5943 - val_f1: 0.5938 - val_auc: 0.6448\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4800 - accuracy: 0.7587 - f1: 0.6804 - auc: 0.8477 - val_loss: 0.7194 - val_accuracy: 0.6641 - val_f1: 0.6363 - val_auc: 0.7272\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4790 - accuracy: 0.7584 - f1: 0.6822 - auc: 0.8481 - val_loss: 0.7629 - val_accuracy: 0.6202 - val_f1: 0.6146 - val_auc: 0.6927\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4788 - accuracy: 0.7625 - f1: 0.6818 - auc: 0.8486 - val_loss: 0.6381 - val_accuracy: 0.6977 - val_f1: 0.6508 - val_auc: 0.7654\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4638 - accuracy: 0.7674 - f1: 0.6924 - auc: 0.8586 - val_loss: 0.6180 - val_accuracy: 0.7106 - val_f1: 0.6465 - val_auc: 0.7706\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4555 - accuracy: 0.7733 - f1: 0.6975 - auc: 0.8647 - val_loss: 0.7173 - val_accuracy: 0.6641 - val_f1: 0.6391 - val_auc: 0.7332\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4436 - accuracy: 0.7786 - f1: 0.7065 - auc: 0.8724 - val_loss: 0.7341 - val_accuracy: 0.6770 - val_f1: 0.6525 - val_auc: 0.7431\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4373 - accuracy: 0.7853 - f1: 0.7106 - auc: 0.8765 - val_loss: 0.7107 - val_accuracy: 0.6899 - val_f1: 0.6515 - val_auc: 0.7473\n",
            "\n",
            "Score for fold 6: \n",
            "\n",
            "Accuracy: 68.99%\n",
            "F1: 65.60%\n",
            "AUC: 74.73%\n",
            "Loss: 0.71%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 6s 17ms/step - loss: 0.6613 - accuracy: 0.5897 - f1: 0.5284 - auc: 0.6321 - val_loss: 0.7552 - val_accuracy: 0.5581 - val_f1: 0.5428 - val_auc: 0.5915\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5841 - accuracy: 0.6914 - f1: 0.5993 - auc: 0.7572 - val_loss: 0.7018 - val_accuracy: 0.5995 - val_f1: 0.5649 - val_auc: 0.6454\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5702 - accuracy: 0.7049 - f1: 0.6123 - auc: 0.7729 - val_loss: 0.7622 - val_accuracy: 0.5685 - val_f1: 0.5494 - val_auc: 0.5987\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5552 - accuracy: 0.7196 - f1: 0.6246 - auc: 0.7876 - val_loss: 0.7486 - val_accuracy: 0.5736 - val_f1: 0.5646 - val_auc: 0.6246\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5526 - accuracy: 0.7162 - f1: 0.6258 - auc: 0.7898 - val_loss: 0.8271 - val_accuracy: 0.5762 - val_f1: 0.5618 - val_auc: 0.6076\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5397 - accuracy: 0.7280 - f1: 0.6365 - auc: 0.8023 - val_loss: 0.7245 - val_accuracy: 0.5814 - val_f1: 0.5786 - val_auc: 0.6557\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.5402 - accuracy: 0.7239 - f1: 0.6361 - auc: 0.8007 - val_loss: 0.8105 - val_accuracy: 0.5917 - val_f1: 0.5794 - val_auc: 0.6372\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5281 - accuracy: 0.7318 - f1: 0.6445 - auc: 0.8110 - val_loss: 0.6853 - val_accuracy: 0.6589 - val_f1: 0.6145 - val_auc: 0.7129\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 15ms/step - loss: 0.5239 - accuracy: 0.7316 - f1: 0.6488 - auc: 0.8140 - val_loss: 0.6199 - val_accuracy: 0.7003 - val_f1: 0.6104 - val_auc: 0.7461\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5170 - accuracy: 0.7353 - f1: 0.6529 - auc: 0.8199 - val_loss: 0.6191 - val_accuracy: 0.7054 - val_f1: 0.6058 - val_auc: 0.7473\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 14ms/step - loss: 0.5141 - accuracy: 0.7414 - f1: 0.6550 - auc: 0.8224 - val_loss: 0.7853 - val_accuracy: 0.6124 - val_f1: 0.6064 - val_auc: 0.6786\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5120 - accuracy: 0.7390 - f1: 0.6575 - auc: 0.8236 - val_loss: 0.6368 - val_accuracy: 0.6925 - val_f1: 0.6090 - val_auc: 0.7404\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4992 - accuracy: 0.7512 - f1: 0.6655 - auc: 0.8339 - val_loss: 0.6390 - val_accuracy: 0.6899 - val_f1: 0.6244 - val_auc: 0.7462\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4909 - accuracy: 0.7511 - f1: 0.6721 - auc: 0.8399 - val_loss: 0.8630 - val_accuracy: 0.6305 - val_f1: 0.6240 - val_auc: 0.6906\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4873 - accuracy: 0.7528 - f1: 0.6751 - auc: 0.8428 - val_loss: 0.6815 - val_accuracy: 0.7028 - val_f1: 0.6391 - val_auc: 0.7423\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4784 - accuracy: 0.7631 - f1: 0.6824 - auc: 0.8495 - val_loss: 0.6187 - val_accuracy: 0.7235 - val_f1: 0.6395 - val_auc: 0.7698\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4764 - accuracy: 0.7628 - f1: 0.6840 - auc: 0.8503 - val_loss: 0.7081 - val_accuracy: 0.6770 - val_f1: 0.6328 - val_auc: 0.7292\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4695 - accuracy: 0.7697 - f1: 0.6881 - auc: 0.8556 - val_loss: 0.6741 - val_accuracy: 0.7080 - val_f1: 0.6477 - val_auc: 0.7527\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4584 - accuracy: 0.7773 - f1: 0.6962 - auc: 0.8635 - val_loss: 0.7053 - val_accuracy: 0.6925 - val_f1: 0.6380 - val_auc: 0.7373\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4524 - accuracy: 0.7795 - f1: 0.7018 - auc: 0.8678 - val_loss: 0.7010 - val_accuracy: 0.7158 - val_f1: 0.6445 - val_auc: 0.7437\n",
            "\n",
            "Score for fold 7: \n",
            "\n",
            "Accuracy: 71.58%\n",
            "F1: 64.94%\n",
            "AUC: 74.37%\n",
            "Loss: 0.70%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 6s 19ms/step - loss: 0.6640 - accuracy: 0.5843 - f1: 0.5274 - auc: 0.6235 - val_loss: 0.6870 - val_accuracy: 0.6098 - val_f1: 0.5556 - val_auc: 0.6459\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5853 - accuracy: 0.6882 - f1: 0.5990 - auc: 0.7561 - val_loss: 0.6514 - val_accuracy: 0.6150 - val_f1: 0.5618 - val_auc: 0.6756\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5691 - accuracy: 0.7047 - f1: 0.6129 - auc: 0.7739 - val_loss: 0.6635 - val_accuracy: 0.5711 - val_f1: 0.5537 - val_auc: 0.6547\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5583 - accuracy: 0.7136 - f1: 0.6209 - auc: 0.7848 - val_loss: 0.7185 - val_accuracy: 0.5866 - val_f1: 0.5658 - val_auc: 0.6360\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5453 - accuracy: 0.7245 - f1: 0.6320 - auc: 0.7969 - val_loss: 0.6432 - val_accuracy: 0.6357 - val_f1: 0.5842 - val_auc: 0.7023\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5406 - accuracy: 0.7251 - f1: 0.6360 - auc: 0.8008 - val_loss: 0.6842 - val_accuracy: 0.6098 - val_f1: 0.5922 - val_auc: 0.6837\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5333 - accuracy: 0.7262 - f1: 0.6415 - auc: 0.8067 - val_loss: 0.6940 - val_accuracy: 0.6098 - val_f1: 0.5954 - val_auc: 0.6829\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5259 - accuracy: 0.7320 - f1: 0.6471 - auc: 0.8128 - val_loss: 0.7170 - val_accuracy: 0.5814 - val_f1: 0.5756 - val_auc: 0.6487\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5184 - accuracy: 0.7378 - f1: 0.6514 - auc: 0.8192 - val_loss: 0.6984 - val_accuracy: 0.6331 - val_f1: 0.6102 - val_auc: 0.7024\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5117 - accuracy: 0.7405 - f1: 0.6577 - auc: 0.8243 - val_loss: 0.7787 - val_accuracy: 0.5866 - val_f1: 0.5836 - val_auc: 0.6469\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5090 - accuracy: 0.7394 - f1: 0.6591 - auc: 0.8260 - val_loss: 0.7088 - val_accuracy: 0.6124 - val_f1: 0.5995 - val_auc: 0.6852\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5000 - accuracy: 0.7447 - f1: 0.6649 - auc: 0.8318 - val_loss: 0.7369 - val_accuracy: 0.6202 - val_f1: 0.6110 - val_auc: 0.6937\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 11ms/step - loss: 0.4915 - accuracy: 0.7524 - f1: 0.6720 - auc: 0.8394 - val_loss: 0.8157 - val_accuracy: 0.6176 - val_f1: 0.6025 - val_auc: 0.6717\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4841 - accuracy: 0.7539 - f1: 0.6782 - auc: 0.8449 - val_loss: 0.8499 - val_accuracy: 0.6176 - val_f1: 0.6034 - val_auc: 0.6667\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4799 - accuracy: 0.7583 - f1: 0.6805 - auc: 0.8476 - val_loss: 0.9410 - val_accuracy: 0.6124 - val_f1: 0.6051 - val_auc: 0.6629\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4788 - accuracy: 0.7571 - f1: 0.6829 - auc: 0.8485 - val_loss: 0.7942 - val_accuracy: 0.6176 - val_f1: 0.5995 - val_auc: 0.6678\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4686 - accuracy: 0.7650 - f1: 0.6876 - auc: 0.8551 - val_loss: 0.7194 - val_accuracy: 0.6718 - val_f1: 0.6292 - val_auc: 0.7200\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4578 - accuracy: 0.7733 - f1: 0.6966 - auc: 0.8631 - val_loss: 0.9381 - val_accuracy: 0.5659 - val_f1: 0.5907 - val_auc: 0.6475\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4487 - accuracy: 0.7801 - f1: 0.7028 - auc: 0.8691 - val_loss: 0.6810 - val_accuracy: 0.6899 - val_f1: 0.6497 - val_auc: 0.7513\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4448 - accuracy: 0.7825 - f1: 0.7051 - auc: 0.8718 - val_loss: 0.7022 - val_accuracy: 0.7054 - val_f1: 0.6538 - val_auc: 0.7504\n",
            "\n",
            "Score for fold 8: \n",
            "\n",
            "Accuracy: 70.54%\n",
            "F1: 65.47%\n",
            "AUC: 75.04%\n",
            "Loss: 0.70%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 5s 18ms/step - loss: 0.6675 - accuracy: 0.5847 - f1: 0.5245 - auc: 0.6196 - val_loss: 0.7271 - val_accuracy: 0.5194 - val_f1: 0.5308 - val_auc: 0.5794\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5893 - accuracy: 0.6851 - f1: 0.5947 - auc: 0.7516 - val_loss: 0.7932 - val_accuracy: 0.5581 - val_f1: 0.5493 - val_auc: 0.5960\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5706 - accuracy: 0.7032 - f1: 0.6116 - auc: 0.7723 - val_loss: 0.8700 - val_accuracy: 0.5401 - val_f1: 0.5437 - val_auc: 0.5859\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5577 - accuracy: 0.7128 - f1: 0.6228 - auc: 0.7854 - val_loss: 0.7038 - val_accuracy: 0.5814 - val_f1: 0.5626 - val_auc: 0.6365\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5509 - accuracy: 0.7216 - f1: 0.6278 - auc: 0.7923 - val_loss: 0.7073 - val_accuracy: 0.5762 - val_f1: 0.5632 - val_auc: 0.6359\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5439 - accuracy: 0.7233 - f1: 0.6334 - auc: 0.7983 - val_loss: 0.7573 - val_accuracy: 0.5788 - val_f1: 0.5685 - val_auc: 0.6301\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5346 - accuracy: 0.7307 - f1: 0.6401 - auc: 0.8059 - val_loss: 0.8118 - val_accuracy: 0.5814 - val_f1: 0.5702 - val_auc: 0.6240\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5292 - accuracy: 0.7300 - f1: 0.6464 - auc: 0.8106 - val_loss: 0.6509 - val_accuracy: 0.6408 - val_f1: 0.5946 - val_auc: 0.7094\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5222 - accuracy: 0.7348 - f1: 0.6487 - auc: 0.8165 - val_loss: 0.6263 - val_accuracy: 0.6848 - val_f1: 0.6018 - val_auc: 0.7342\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5107 - accuracy: 0.7433 - f1: 0.6572 - auc: 0.8254 - val_loss: 0.6858 - val_accuracy: 0.6382 - val_f1: 0.6118 - val_auc: 0.7093\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5113 - accuracy: 0.7388 - f1: 0.6577 - auc: 0.8243 - val_loss: 0.6824 - val_accuracy: 0.6227 - val_f1: 0.5988 - val_auc: 0.6970\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4980 - accuracy: 0.7470 - f1: 0.6678 - auc: 0.8350 - val_loss: 0.7222 - val_accuracy: 0.6357 - val_f1: 0.6119 - val_auc: 0.6981\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4964 - accuracy: 0.7480 - f1: 0.6684 - auc: 0.8355 - val_loss: 0.6727 - val_accuracy: 0.6718 - val_f1: 0.6280 - val_auc: 0.7327\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4880 - accuracy: 0.7523 - f1: 0.6746 - auc: 0.8419 - val_loss: 0.8064 - val_accuracy: 0.6279 - val_f1: 0.6170 - val_auc: 0.6894\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4849 - accuracy: 0.7548 - f1: 0.6764 - auc: 0.8433 - val_loss: 0.6189 - val_accuracy: 0.7028 - val_f1: 0.6370 - val_auc: 0.7658\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4736 - accuracy: 0.7619 - f1: 0.6852 - auc: 0.8519 - val_loss: 0.7287 - val_accuracy: 0.6615 - val_f1: 0.6282 - val_auc: 0.7166\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4653 - accuracy: 0.7672 - f1: 0.6912 - auc: 0.8580 - val_loss: 0.7988 - val_accuracy: 0.6357 - val_f1: 0.6199 - val_auc: 0.6939\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4623 - accuracy: 0.7686 - f1: 0.6938 - auc: 0.8601 - val_loss: 0.7732 - val_accuracy: 0.6486 - val_f1: 0.6174 - val_auc: 0.6964\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4499 - accuracy: 0.7754 - f1: 0.7008 - auc: 0.8679 - val_loss: 0.7685 - val_accuracy: 0.6744 - val_f1: 0.6444 - val_auc: 0.7284\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4415 - accuracy: 0.7826 - f1: 0.7091 - auc: 0.8741 - val_loss: 0.6751 - val_accuracy: 0.6899 - val_f1: 0.6455 - val_auc: 0.7508\n",
            "\n",
            "Score for fold 9: \n",
            "\n",
            "Accuracy: 68.99%\n",
            "F1: 65.15%\n",
            "AUC: 75.08%\n",
            "Loss: 0.68%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/20\n",
            "147/147 [==============================] - 6s 18ms/step - loss: 0.6583 - accuracy: 0.5971 - f1: 0.5312 - auc: 0.6400 - val_loss: 0.8786 - val_accuracy: 0.5116 - val_f1: 0.5320 - val_auc: 0.5664\n",
            "Epoch 2/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5915 - accuracy: 0.6821 - f1: 0.5935 - auc: 0.7485 - val_loss: 0.7529 - val_accuracy: 0.5659 - val_f1: 0.5493 - val_auc: 0.6005\n",
            "Epoch 3/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5681 - accuracy: 0.7043 - f1: 0.6122 - auc: 0.7749 - val_loss: 0.7707 - val_accuracy: 0.5633 - val_f1: 0.5510 - val_auc: 0.5990\n",
            "Epoch 4/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5630 - accuracy: 0.7074 - f1: 0.6180 - auc: 0.7795 - val_loss: 0.6171 - val_accuracy: 0.6693 - val_f1: 0.5709 - val_auc: 0.7284\n",
            "Epoch 5/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5563 - accuracy: 0.7097 - f1: 0.6239 - auc: 0.7862 - val_loss: 0.6389 - val_accuracy: 0.6512 - val_f1: 0.5744 - val_auc: 0.7034\n",
            "Epoch 6/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5436 - accuracy: 0.7239 - f1: 0.6330 - auc: 0.7980 - val_loss: 0.6645 - val_accuracy: 0.6072 - val_f1: 0.5629 - val_auc: 0.6672\n",
            "Epoch 7/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5389 - accuracy: 0.7226 - f1: 0.6367 - auc: 0.8018 - val_loss: 0.6654 - val_accuracy: 0.6305 - val_f1: 0.5850 - val_auc: 0.6937\n",
            "Epoch 8/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5301 - accuracy: 0.7285 - f1: 0.6439 - auc: 0.8094 - val_loss: 0.6965 - val_accuracy: 0.6253 - val_f1: 0.5969 - val_auc: 0.6898\n",
            "Epoch 9/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5192 - accuracy: 0.7345 - f1: 0.6512 - auc: 0.8180 - val_loss: 0.6384 - val_accuracy: 0.6899 - val_f1: 0.6157 - val_auc: 0.7358\n",
            "Epoch 10/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5142 - accuracy: 0.7395 - f1: 0.6543 - auc: 0.8218 - val_loss: 0.8348 - val_accuracy: 0.5814 - val_f1: 0.5813 - val_auc: 0.6367\n",
            "Epoch 11/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.5132 - accuracy: 0.7406 - f1: 0.6570 - auc: 0.8230 - val_loss: 0.6575 - val_accuracy: 0.6667 - val_f1: 0.6100 - val_auc: 0.7237\n",
            "Epoch 12/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.5054 - accuracy: 0.7426 - f1: 0.6618 - auc: 0.8292 - val_loss: 0.7589 - val_accuracy: 0.6279 - val_f1: 0.6079 - val_auc: 0.6845\n",
            "Epoch 13/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4986 - accuracy: 0.7504 - f1: 0.6675 - auc: 0.8346 - val_loss: 0.6156 - val_accuracy: 0.6899 - val_f1: 0.6156 - val_auc: 0.7562\n",
            "Epoch 14/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4990 - accuracy: 0.7440 - f1: 0.6660 - auc: 0.8333 - val_loss: 0.7907 - val_accuracy: 0.6382 - val_f1: 0.6228 - val_auc: 0.6977\n",
            "Epoch 15/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4833 - accuracy: 0.7592 - f1: 0.6787 - auc: 0.8460 - val_loss: 0.6862 - val_accuracy: 0.6667 - val_f1: 0.6278 - val_auc: 0.7303\n",
            "Epoch 16/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4748 - accuracy: 0.7639 - f1: 0.6846 - auc: 0.8523 - val_loss: 0.7257 - val_accuracy: 0.6693 - val_f1: 0.6420 - val_auc: 0.7326\n",
            "Epoch 17/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4703 - accuracy: 0.7653 - f1: 0.6893 - auc: 0.8548 - val_loss: 0.6727 - val_accuracy: 0.6796 - val_f1: 0.6322 - val_auc: 0.7379\n",
            "Epoch 18/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4633 - accuracy: 0.7727 - f1: 0.6914 - auc: 0.8602 - val_loss: 0.8818 - val_accuracy: 0.6279 - val_f1: 0.6230 - val_auc: 0.6893\n",
            "Epoch 19/20\n",
            "147/147 [==============================] - 2s 12ms/step - loss: 0.4528 - accuracy: 0.7797 - f1: 0.7019 - auc: 0.8677 - val_loss: 0.7602 - val_accuracy: 0.6537 - val_f1: 0.6238 - val_auc: 0.7062\n",
            "Epoch 20/20\n",
            "147/147 [==============================] - 2s 13ms/step - loss: 0.4507 - accuracy: 0.7795 - f1: 0.7027 - auc: 0.8689 - val_loss: 0.7265 - val_accuracy: 0.6822 - val_f1: 0.6480 - val_auc: 0.7399\n",
            "\n",
            "Score for fold 10: \n",
            "\n",
            "Accuracy: 68.22%\n",
            "F1: 64.84%\n",
            "AUC: 73.99%\n",
            "Loss: 0.73%\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# - - - - - TRAIN FEATURES - - - - -\n",
        "X1_laser = tf.reshape(train_embeddings, [-1, 1, 1024])\n",
        "\n",
        "Y1 = to_categorical(train_labels, 2)\n",
        "Y1_reshaped = tf.reshape(Y1, [-1, 1, 2])\n",
        "\n",
        "print('Train data shapes:',X1_laser.shape, Y1_reshaped.shape)\n",
        "\n",
        "# - - - - - TEST FEATURES - - - - -\n",
        "X2_laser = tf.reshape(test_embeddings, [-1, 1, 1024])\n",
        "\n",
        "Y2 = to_categorical(test_labels, 2)\n",
        "Y2_reshaped = tf.reshape(Y2, [-1, 1, 2])\n",
        "\n",
        "print('Test data shapes:', X2_laser.shape, Y2_reshaped.shape)\n",
        "\n",
        "\n",
        "inputs = np.concatenate((X1_laser, X2_laser), axis=0)\n",
        "targets = np.concatenate((Y1_reshaped, Y2_reshaped), axis=0)\n",
        "\n",
        "# Define per-fold score containers \n",
        "acc_per_fold = []\n",
        "f1_per_fold = []\n",
        "auc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "num_folds = 10\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(LSTM(100, input_shape=(1, 1024), return_sequences=True))\n",
        "  model.add(Dense(1024,activation='relu')) # MUST BE 2 hidden layers\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128,activation='sigmoid'))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'), f1, tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(X1_laser, Y1_reshaped, validation_data=(X2_laser, Y2_reshaped), epochs=20, batch_size=100)\n",
        "\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X2_laser, Y2_reshaped, verbose=0)\n",
        "  print(f'\\nScore for fold {fold_no}: \\n')\n",
        "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "  print(\"F1: %.2f%%\" % (scores[2]*100))\n",
        "  print(\"AUC: %.2f%%\" % (scores[3]*100))\n",
        "  print(\"Loss: %.2f%%\" % (scores[0]))\n",
        "  print('\\n------------------------------------------------------------------------\\n')\n",
        "    \n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  f1_per_fold.append(scores[2] * 100)\n",
        "  auc_per_fold.append(scores[3] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - F1: {f1_per_fold[i]} - AUC: {auc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (+- {np.std(auc_per_fold)})')\n",
        "\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDpcF26Ac8Gw",
        "outputId": "17a10405-ea69-4cb6-aa67-6069d6533bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.6945356130599976 - Accuracy: 69.50904130935669 - F1: 65.09531736373901 - AUC: 74.51408505439758%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.6442931294441223 - Accuracy: 71.3178277015686 - F1: 66.72589182853699 - AUC: 77.85956859588623%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.7596547603607178 - Accuracy: 66.66666865348816 - F1: 65.60471057891846 - AUC: 73.1179416179657%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.6943183541297913 - Accuracy: 69.76743936538696 - F1: 66.47533178329468 - AUC: 75.94595551490784%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.7083387970924377 - Accuracy: 68.73385310173035 - F1: 65.45156836509705 - AUC: 74.47134852409363%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.7106948494911194 - Accuracy: 68.99224519729614 - F1: 65.60243368148804 - AUC: 74.73276853561401%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.700975775718689 - Accuracy: 71.57622575759888 - F1: 64.93755578994751 - AUC: 74.36585426330566%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.7022293210029602 - Accuracy: 70.54263353347778 - F1: 65.47009348869324 - AUC: 75.04057288169861%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.6751435995101929 - Accuracy: 68.99224519729614 - F1: 65.14562964439392 - AUC: 75.07528066635132%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.7265048027038574 - Accuracy: 68.2170569896698 - F1: 64.84097838401794 - AUC: 73.988276720047%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Loss: 0.7016689002513885\n",
            "> Accuracy: 69.43152368068695 (+- 1.3965432813398237)\n",
            "> F1: 65.53495109081268 (+- 0.5921624293370702)\n",
            "> AUC: 74.91116523742676 (+- 1.206450517619856)\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpzJZlMz1waV"
      },
      "source": [
        "## **4.Labeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zg2cd5sKLKx"
      },
      "outputs": [],
      "source": [
        "lyrics_df = labeling(lyrics_embeddings, lyrics_df)\n",
        "#lyrics_df.to_csv('lyrics_Predicted_2021.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}